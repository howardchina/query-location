{"env_info": "sys.platform: linux\nPython: 3.8.10 (default, Jun  4 2021, 15:09:15) [GCC 7.5.0]\nCUDA available: True\nGPU 0,1,2,3: NVIDIA TITAN Xp\nCUDA_HOME: /usr/local/cuda\nNVCC: Cuda compilation tools, release 10.2, V10.2.89\nGCC: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609\nPyTorch: 1.7.0\nPyTorch compiling details: PyTorch built with:\n  - GCC 7.3\n  - C++ Version: 201402\n  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 10.2\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75\n  - CuDNN 7.6.5\n  - Magma 2.5.2\n  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n\nTorchVision: 0.8.1\nOpenCV: 4.5.3\nMMCV: 1.3.18\nMMCV Compiler: GCC 7.3\nMMCV CUDA Compiler: 10.2\nMMDetection: 2.12.0+170db93", "config": "dataset_type = 'AnatomyDataset'\ndata_root = '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi'\nsplit = 'split_1'\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\nalbu_train_transforms = [\n    dict(\n        type='OneOf',\n        transforms=[\n            dict(\n                type='Affine',\n                translate_percent=0.0,\n                rotate=90,\n                fit_output=True,\n                p=0.25),\n            dict(\n                type='Affine',\n                translate_percent=0.0,\n                rotate=180,\n                fit_output=True,\n                p=0.25),\n            dict(\n                type='Affine',\n                translate_percent=0.0,\n                rotate=270,\n                fit_output=True,\n                p=0.25)\n        ],\n        p=0.75)\n]\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n    dict(type='LoadAnatomy'),\n    dict(type='RandomFlip', flip_ratio=0.5),\n    dict(\n        type='Albu',\n        transforms=[\n            dict(\n                type='OneOf',\n                transforms=[\n                    dict(\n                        type='Affine',\n                        translate_percent=0.0,\n                        rotate=90,\n                        fit_output=True,\n                        p=0.25),\n                    dict(\n                        type='Affine',\n                        translate_percent=0.0,\n                        rotate=180,\n                        fit_output=True,\n                        p=0.25),\n                    dict(\n                        type='Affine',\n                        translate_percent=0.0,\n                        rotate=270,\n                        fit_output=True,\n                        p=0.25)\n                ],\n                p=0.75)\n        ],\n        bbox_params=dict(\n            type='BboxParams',\n            format='pascal_voc',\n            label_fields=['gt_labels'],\n            min_visibility=0.0,\n            filter_lost_elements=True),\n        keymap=dict(img='image', gt_masks='masks', gt_bboxes='bboxes'),\n        update_pad_shape=False,\n        skip_img_without_anno=True),\n    dict(\n        type='Resize',\n        img_scale=[(1333, 480), (1333, 512), (1333, 544), (1333, 576),\n                   (1333, 608), (1333, 640), (1333, 672), (1333, 704),\n                   (1333, 736), (1333, 768), (1333, 800)],\n        multiscale_mode='value',\n        keep_ratio=True),\n    dict(\n        type='Normalize',\n        mean=[123.675, 116.28, 103.53],\n        std=[58.395, 57.12, 57.375],\n        to_rgb=True),\n    dict(type='Pad', size_divisor=32),\n    dict(type='DefaultFormatBundle'),\n    dict(type='FormatAnatomyBundle'),\n    dict(\n        type='Collect',\n        keys=['img', 'anatomy', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnatomy'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(1333, 800),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='FormatAnatomyBundle'),\n            dict(type='Collect', keys=['img', 'anatomy'])\n        ])\n]\ndata = dict(\n    samples_per_gpu=2,\n    workers_per_gpu=2,\n    train=dict(\n        type='AnatomyDataset',\n        ann_file=\n        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/annotations/train_anno_crop_split_1.json',\n        img_prefix=\n        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/images/',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n            dict(type='LoadAnatomy'),\n            dict(type='RandomFlip', flip_ratio=0.5),\n            dict(\n                type='Albu',\n                transforms=[\n                    dict(\n                        type='OneOf',\n                        transforms=[\n                            dict(\n                                type='Affine',\n                                translate_percent=0.0,\n                                rotate=90,\n                                fit_output=True,\n                                p=0.25),\n                            dict(\n                                type='Affine',\n                                translate_percent=0.0,\n                                rotate=180,\n                                fit_output=True,\n                                p=0.25),\n                            dict(\n                                type='Affine',\n                                translate_percent=0.0,\n                                rotate=270,\n                                fit_output=True,\n                                p=0.25)\n                        ],\n                        p=0.75)\n                ],\n                bbox_params=dict(\n                    type='BboxParams',\n                    format='pascal_voc',\n                    label_fields=['gt_labels'],\n                    min_visibility=0.0,\n                    filter_lost_elements=True),\n                keymap=dict(img='image', gt_masks='masks', gt_bboxes='bboxes'),\n                update_pad_shape=False,\n                skip_img_without_anno=True),\n            dict(\n                type='Resize',\n                img_scale=[(1333, 480), (1333, 512), (1333, 544), (1333, 576),\n                           (1333, 608), (1333, 640), (1333, 672), (1333, 704),\n                           (1333, 736), (1333, 768), (1333, 800)],\n                multiscale_mode='value',\n                keep_ratio=True),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='DefaultFormatBundle'),\n            dict(type='FormatAnatomyBundle'),\n            dict(\n                type='Collect',\n                keys=['img', 'anatomy', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n        ],\n        classes=('lmym', 'GIST')),\n    val=dict(\n        type='AnatomyDataset',\n        ann_file=\n        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/annotations/val_anno_crop_split_1.json',\n        img_prefix=\n        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/images/',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnatomy'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(1333, 800),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='Pad', size_divisor=32),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='FormatAnatomyBundle'),\n                    dict(type='Collect', keys=['img', 'anatomy'])\n                ])\n        ],\n        classes=('lmym', 'GIST')),\n    test=dict(\n        type='AnatomyDataset',\n        ann_file=\n        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/annotations/val_anno_crop_split_1.json',\n        img_prefix=\n        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/images/',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnatomy'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(1333, 800),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='Pad', size_divisor=32),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='FormatAnatomyBundle'),\n                    dict(type='Collect', keys=['img', 'anatomy'])\n                ])\n        ],\n        classes=('lmym', 'GIST')))\nevaluation = dict(metric=['bbox', 'segm', 'glob'])\noptimizer = dict(type='AdamW', lr=2.5e-05, weight_decay=0.0001)\noptimizer_config = dict(grad_clip=dict(max_norm=1, norm_type=2))\nlr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=1000,\n    warmup_ratio=0.001,\n    step=[27, 33])\nrunner = dict(type='EpochBasedRunner', max_epochs=36)\ncheckpoint_config = dict(interval=1)\nlog_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\ncustom_hooks = [dict(type='NumClassCheckHook')]\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = 'work_dirs/pretrained/queryInst/queryinst_r101_300_queries-860dc5d5.pth'\nresume_from = None\nworkflow = [('train', 1)]\nnum_stages = 6\nnum_proposals = 300\nmodel = dict(\n    type='QueryGlob',\n    pretrained='torchvision://resnet101',\n    backbone=dict(\n        type='ResNet',\n        depth=101,\n        num_stages=4,\n        out_indices=(0, 1, 2, 3),\n        frozen_stages=1,\n        norm_cfg=dict(type='BN', requires_grad=True),\n        norm_eval=True,\n        style='pytorch'),\n    neck=dict(\n        type='FPN',\n        in_channels=[256, 512, 1024, 2048],\n        out_channels=256,\n        start_level=0,\n        add_extra_convs='on_input',\n        num_outs=4),\n    rpn_head=dict(\n        type='GlobalEmbeddingRPNHead',\n        num_proposals=300,\n        dim_global=7,\n        proposal_feature_channel=256),\n    roi_head=dict(\n        type='QueryGlobRoIHead',\n        num_stages=6,\n        stage_loss_weights=[1, 1, 1, 1, 1, 1],\n        proposal_feature_channel=256,\n        bbox_roi_extractor=dict(\n            type='SingleRoIExtractor',\n            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=2),\n            out_channels=256,\n            featmap_strides=[4, 8, 16, 32]),\n        mask_roi_extractor=dict(\n            type='SingleRoIExtractor',\n            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=2),\n            out_channels=256,\n            featmap_strides=[4, 8, 16, 32]),\n        bbox_head=[\n            dict(\n                type='GlobDIIHead',\n                num_classes=2,\n                num_ffn_fcs=2,\n                num_heads=8,\n                num_cls_fcs=2,\n                num_glb_fcs=2,\n                num_reg_fcs=3,\n                feedforward_channels=2048,\n                in_channels=256,\n                dropout=0.0,\n                ffn_act_cfg=dict(type='ReLU', inplace=True),\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=7,\n                    with_proj=True,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n                loss_cls=dict(\n                    type='FocalLoss',\n                    use_sigmoid=True,\n                    gamma=2.0,\n                    alpha=0.25,\n                    loss_weight=2.0),\n                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    clip_border=False,\n                    target_means=[0.0, 0.0, 0.0, 0.0],\n                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n            dict(\n                type='GlobDIIHead',\n                num_classes=2,\n                num_ffn_fcs=2,\n                num_heads=8,\n                num_cls_fcs=2,\n                num_glb_fcs=2,\n                num_reg_fcs=3,\n                feedforward_channels=2048,\n                in_channels=256,\n                dropout=0.0,\n                ffn_act_cfg=dict(type='ReLU', inplace=True),\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=7,\n                    with_proj=True,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n                loss_cls=dict(\n                    type='FocalLoss',\n                    use_sigmoid=True,\n                    gamma=2.0,\n                    alpha=0.25,\n                    loss_weight=2.0),\n                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    clip_border=False,\n                    target_means=[0.0, 0.0, 0.0, 0.0],\n                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n            dict(\n                type='GlobDIIHead',\n                num_classes=2,\n                num_ffn_fcs=2,\n                num_heads=8,\n                num_cls_fcs=2,\n                num_glb_fcs=2,\n                num_reg_fcs=3,\n                feedforward_channels=2048,\n                in_channels=256,\n                dropout=0.0,\n                ffn_act_cfg=dict(type='ReLU', inplace=True),\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=7,\n                    with_proj=True,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n                loss_cls=dict(\n                    type='FocalLoss',\n                    use_sigmoid=True,\n                    gamma=2.0,\n                    alpha=0.25,\n                    loss_weight=2.0),\n                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    clip_border=False,\n                    target_means=[0.0, 0.0, 0.0, 0.0],\n                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n            dict(\n                type='GlobDIIHead',\n                num_classes=2,\n                num_ffn_fcs=2,\n                num_heads=8,\n                num_cls_fcs=2,\n                num_glb_fcs=2,\n                num_reg_fcs=3,\n                feedforward_channels=2048,\n                in_channels=256,\n                dropout=0.0,\n                ffn_act_cfg=dict(type='ReLU', inplace=True),\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=7,\n                    with_proj=True,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n                loss_cls=dict(\n                    type='FocalLoss',\n                    use_sigmoid=True,\n                    gamma=2.0,\n                    alpha=0.25,\n                    loss_weight=2.0),\n                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    clip_border=False,\n                    target_means=[0.0, 0.0, 0.0, 0.0],\n                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n            dict(\n                type='GlobDIIHead',\n                num_classes=2,\n                num_ffn_fcs=2,\n                num_heads=8,\n                num_cls_fcs=2,\n                num_glb_fcs=2,\n                num_reg_fcs=3,\n                feedforward_channels=2048,\n                in_channels=256,\n                dropout=0.0,\n                ffn_act_cfg=dict(type='ReLU', inplace=True),\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=7,\n                    with_proj=True,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n                loss_cls=dict(\n                    type='FocalLoss',\n                    use_sigmoid=True,\n                    gamma=2.0,\n                    alpha=0.25,\n                    loss_weight=2.0),\n                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    clip_border=False,\n                    target_means=[0.0, 0.0, 0.0, 0.0],\n                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n            dict(\n                type='GlobDIIHead',\n                num_classes=2,\n                num_ffn_fcs=2,\n                num_heads=8,\n                num_cls_fcs=2,\n                num_glb_fcs=2,\n                num_reg_fcs=3,\n                feedforward_channels=2048,\n                in_channels=256,\n                dropout=0.0,\n                ffn_act_cfg=dict(type='ReLU', inplace=True),\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=7,\n                    with_proj=True,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n                loss_cls=dict(\n                    type='FocalLoss',\n                    use_sigmoid=True,\n                    gamma=2.0,\n                    alpha=0.25,\n                    loss_weight=2.0),\n                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    clip_border=False,\n                    target_means=[0.0, 0.0, 0.0, 0.0],\n                    target_stds=[0.5, 0.5, 1.0, 1.0]))\n        ],\n        mask_head=[\n            dict(\n                type='DynamicMaskHead',\n                num_classes=2,\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=14,\n                    with_proj=False,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                dropout=0.0,\n                num_convs=4,\n                roi_feat_size=14,\n                in_channels=256,\n                conv_kernel_size=3,\n                conv_out_channels=256,\n                class_agnostic=False,\n                norm_cfg=dict(type='BN'),\n                upsample_cfg=dict(type='deconv', scale_factor=2),\n                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n            dict(\n                type='DynamicMaskHead',\n                num_classes=2,\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=14,\n                    with_proj=False,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                dropout=0.0,\n                num_convs=4,\n                roi_feat_size=14,\n                in_channels=256,\n                conv_kernel_size=3,\n                conv_out_channels=256,\n                class_agnostic=False,\n                norm_cfg=dict(type='BN'),\n                upsample_cfg=dict(type='deconv', scale_factor=2),\n                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n            dict(\n                type='DynamicMaskHead',\n                num_classes=2,\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=14,\n                    with_proj=False,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                dropout=0.0,\n                num_convs=4,\n                roi_feat_size=14,\n                in_channels=256,\n                conv_kernel_size=3,\n                conv_out_channels=256,\n                class_agnostic=False,\n                norm_cfg=dict(type='BN'),\n                upsample_cfg=dict(type='deconv', scale_factor=2),\n                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n            dict(\n                type='DynamicMaskHead',\n                num_classes=2,\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=14,\n                    with_proj=False,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                dropout=0.0,\n                num_convs=4,\n                roi_feat_size=14,\n                in_channels=256,\n                conv_kernel_size=3,\n                conv_out_channels=256,\n                class_agnostic=False,\n                norm_cfg=dict(type='BN'),\n                upsample_cfg=dict(type='deconv', scale_factor=2),\n                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n            dict(\n                type='DynamicMaskHead',\n                num_classes=2,\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=14,\n                    with_proj=False,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                dropout=0.0,\n                num_convs=4,\n                roi_feat_size=14,\n                in_channels=256,\n                conv_kernel_size=3,\n                conv_out_channels=256,\n                class_agnostic=False,\n                norm_cfg=dict(type='BN'),\n                upsample_cfg=dict(type='deconv', scale_factor=2),\n                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n            dict(\n                type='DynamicMaskHead',\n                num_classes=2,\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=14,\n                    with_proj=False,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                dropout=0.0,\n                num_convs=4,\n                roi_feat_size=14,\n                in_channels=256,\n                conv_kernel_size=3,\n                conv_out_channels=256,\n                class_agnostic=False,\n                norm_cfg=dict(type='BN'),\n                upsample_cfg=dict(type='deconv', scale_factor=2),\n                loss_dice=dict(type='DiceLoss', loss_weight=8.0))\n        ]),\n    train_cfg=dict(\n        rpn=None,\n        rcnn=[\n            dict(\n                assigner=dict(\n                    type='HungarianAssigner',\n                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n                                  weight=2.0)),\n                sampler=dict(type='PseudoSampler'),\n                pos_weight=1,\n                mask_size=28,\n                debug=False),\n            dict(\n                assigner=dict(\n                    type='HungarianAssigner',\n                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n                                  weight=2.0)),\n                sampler=dict(type='PseudoSampler'),\n                pos_weight=1,\n                mask_size=28,\n                debug=False),\n            dict(\n                assigner=dict(\n                    type='HungarianAssigner',\n                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n                                  weight=2.0)),\n                sampler=dict(type='PseudoSampler'),\n                pos_weight=1,\n                mask_size=28,\n                debug=False),\n            dict(\n                assigner=dict(\n                    type='HungarianAssigner',\n                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n                                  weight=2.0)),\n                sampler=dict(type='PseudoSampler'),\n                pos_weight=1,\n                mask_size=28,\n                debug=False),\n            dict(\n                assigner=dict(\n                    type='HungarianAssigner',\n                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n                                  weight=2.0)),\n                sampler=dict(type='PseudoSampler'),\n                pos_weight=1,\n                mask_size=28,\n                debug=False),\n            dict(\n                assigner=dict(\n                    type='HungarianAssigner',\n                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n                                  weight=2.0)),\n                sampler=dict(type='PseudoSampler'),\n                pos_weight=1,\n                mask_size=28,\n                debug=False)\n        ]),\n    test_cfg=dict(\n        rpn=None,\n        rcnn=dict(\n            max_per_img=300,\n            mask_thr_binary=0.5,\n            nms=dict(type='nms', iou_threshold=0.7))))\ntotal_epochs = 36\nmin_values = (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)\nclasses = ('lmym', 'GIST')\ngpu_ids = range(0, 4)\nwork_dir = './work_dirs/queryglob_usdanno514roi_B_2_7_split1'\n", "seed": null, "exp_name": "queryglob_usdanno514roi_B_2_7_split1.py"}
{"mode": "train", "epoch": 1, "iter": 50, "lr": 0.0, "memory": 8373, "data_time": 0.22125, "stage0_loss_cls": 1.99059, "stage0_pos_acc": 47.5, "stage0_loss_bbox": 0.65021, "stage0_loss_iou": 1.02819, "stage0_loss_global": 0.84693, "stage0_loss_mask": 2.27829, "stage1_loss_cls": 2.68884, "stage1_pos_acc": 53.25, "stage1_loss_bbox": 0.56997, "stage1_loss_iou": 0.93488, "stage1_loss_global": 0.6079, "stage1_loss_mask": 2.38946, "stage2_loss_cls": 2.20929, "stage2_pos_acc": 54.5, "stage2_loss_bbox": 0.5871, "stage2_loss_iou": 0.92934, "stage2_loss_global": 0.84336, "stage2_loss_mask": 2.79706, "stage3_loss_cls": 2.65506, "stage3_pos_acc": 52.5, "stage3_loss_bbox": 0.57851, "stage3_loss_iou": 0.93698, "stage3_loss_global": 0.97135, "stage3_loss_mask": 4.39308, "stage4_loss_cls": 1.82536, "stage4_pos_acc": 52.75, "stage4_loss_bbox": 0.58698, "stage4_loss_iou": 0.93188, "stage4_loss_global": 0.97547, "stage4_loss_mask": 2.63051, "stage5_loss_cls": 1.94603, "stage5_pos_acc": 48.0, "stage5_loss_bbox": 0.59592, "stage5_loss_iou": 0.94121, "stage5_loss_global": 0.70128, "stage5_loss_mask": 3.18956, "loss": 45.2106, "grad_norm": 216.84623, "time": 1.39961}
{"mode": "train", "epoch": 2, "iter": 50, "lr": 0.0, "memory": 8373, "data_time": 0.21924, "stage0_loss_cls": 1.74437, "stage0_pos_acc": 48.75, "stage0_loss_bbox": 0.58452, "stage0_loss_iou": 0.92899, "stage0_loss_global": 0.69523, "stage0_loss_mask": 2.39063, "stage1_loss_cls": 2.369, "stage1_pos_acc": 51.0, "stage1_loss_bbox": 0.46194, "stage1_loss_iou": 0.77029, "stage1_loss_global": 0.54534, "stage1_loss_mask": 2.1801, "stage2_loss_cls": 1.76218, "stage2_pos_acc": 52.0, "stage2_loss_bbox": 0.45652, "stage2_loss_iou": 0.74924, "stage2_loss_global": 0.62601, "stage2_loss_mask": 2.48208, "stage3_loss_cls": 2.3981, "stage3_pos_acc": 51.75, "stage3_loss_bbox": 0.4271, "stage3_loss_iou": 0.71084, "stage3_loss_global": 0.67627, "stage3_loss_mask": 4.08216, "stage4_loss_cls": 1.71844, "stage4_pos_acc": 52.25, "stage4_loss_bbox": 0.42434, "stage4_loss_iou": 0.69581, "stage4_loss_global": 0.66736, "stage4_loss_mask": 2.2236, "stage5_loss_cls": 1.73076, "stage5_pos_acc": 51.25, "stage5_loss_bbox": 0.43107, "stage5_loss_iou": 0.70857, "stage5_loss_global": 0.59152, "stage5_loss_mask": 2.75637, "loss": 38.98874, "grad_norm": 188.92138, "time": 1.3804}
{"mode": "train", "epoch": 3, "iter": 50, "lr": 0.0, "memory": 8409, "data_time": 0.21847, "stage0_loss_cls": 1.46747, "stage0_pos_acc": 52.5, "stage0_loss_bbox": 0.51643, "stage0_loss_iou": 0.83873, "stage0_loss_global": 0.56915, "stage0_loss_mask": 2.2816, "stage1_loss_cls": 1.94036, "stage1_pos_acc": 58.0, "stage1_loss_bbox": 0.37713, "stage1_loss_iou": 0.6529, "stage1_loss_global": 0.51893, "stage1_loss_mask": 1.87856, "stage2_loss_cls": 1.40473, "stage2_pos_acc": 55.75, "stage2_loss_bbox": 0.36466, "stage2_loss_iou": 0.62869, "stage2_loss_global": 0.52421, "stage2_loss_mask": 2.10899, "stage3_loss_cls": 1.97285, "stage3_pos_acc": 52.0, "stage3_loss_bbox": 0.34626, "stage3_loss_iou": 0.6062, "stage3_loss_global": 0.53174, "stage3_loss_mask": 3.60737, "stage4_loss_cls": 1.45523, "stage4_pos_acc": 56.75, "stage4_loss_bbox": 0.33247, "stage4_loss_iou": 0.58597, "stage4_loss_global": 0.53204, "stage4_loss_mask": 1.84247, "stage5_loss_cls": 1.37535, "stage5_pos_acc": 64.0, "stage5_loss_bbox": 0.33574, "stage5_loss_iou": 0.5923, "stage5_loss_global": 0.5142, "stage5_loss_mask": 2.29972, "loss": 33.00245, "grad_norm": 167.53849, "time": 1.39102}
{"mode": "train", "epoch": 4, "iter": 50, "lr": 1e-05, "memory": 8409, "data_time": 0.22023, "stage0_loss_cls": 1.4022, "stage0_pos_acc": 52.5, "stage0_loss_bbox": 0.46744, "stage0_loss_iou": 0.79032, "stage0_loss_global": 0.51491, "stage0_loss_mask": 1.90368, "stage1_loss_cls": 1.50482, "stage1_pos_acc": 61.75, "stage1_loss_bbox": 0.31825, "stage1_loss_iou": 0.56466, "stage1_loss_global": 0.49993, "stage1_loss_mask": 1.48627, "stage2_loss_cls": 1.24325, "stage2_pos_acc": 58.0, "stage2_loss_bbox": 0.29671, "stage2_loss_iou": 0.52702, "stage2_loss_global": 0.48553, "stage2_loss_mask": 1.69702, "stage3_loss_cls": 1.44839, "stage3_pos_acc": 55.25, "stage3_loss_bbox": 0.29437, "stage3_loss_iou": 0.52736, "stage3_loss_global": 0.49511, "stage3_loss_mask": 3.00156, "stage4_loss_cls": 1.20999, "stage4_pos_acc": 62.75, "stage4_loss_bbox": 0.2805, "stage4_loss_iou": 0.50502, "stage4_loss_global": 0.49171, "stage4_loss_mask": 1.54608, "stage5_loss_cls": 1.14046, "stage5_pos_acc": 67.75, "stage5_loss_bbox": 0.2783, "stage5_loss_iou": 0.50243, "stage5_loss_global": 0.49375, "stage5_loss_mask": 1.90841, "loss": 27.82546, "grad_norm": 135.64094, "time": 1.39869}
{"mode": "train", "epoch": 5, "iter": 50, "lr": 1e-05, "memory": 8409, "data_time": 0.21604, "stage0_loss_cls": 1.34438, "stage0_pos_acc": 55.0, "stage0_loss_bbox": 0.45012, "stage0_loss_iou": 0.75812, "stage0_loss_global": 0.47825, "stage0_loss_mask": 1.76639, "stage1_loss_cls": 1.27147, "stage1_pos_acc": 67.25, "stage1_loss_bbox": 0.28517, "stage1_loss_iou": 0.51989, "stage1_loss_global": 0.47186, "stage1_loss_mask": 1.3047, "stage2_loss_cls": 1.09376, "stage2_pos_acc": 59.5, "stage2_loss_bbox": 0.2708, "stage2_loss_iou": 0.49216, "stage2_loss_global": 0.464, "stage2_loss_mask": 1.37767, "stage3_loss_cls": 1.08773, "stage3_pos_acc": 61.0, "stage3_loss_bbox": 0.27344, "stage3_loss_iou": 0.49385, "stage3_loss_global": 0.46794, "stage3_loss_mask": 2.5354, "stage4_loss_cls": 0.9462, "stage4_pos_acc": 72.5, "stage4_loss_bbox": 0.26357, "stage4_loss_iou": 0.4729, "stage4_loss_global": 0.46308, "stage4_loss_mask": 1.31357, "stage5_loss_cls": 0.88411, "stage5_pos_acc": 61.75, "stage5_loss_bbox": 0.26703, "stage5_loss_iou": 0.47648, "stage5_loss_global": 0.46127, "stage5_loss_mask": 1.54182, "loss": 24.29711, "grad_norm": 128.40422, "time": 1.37504}
{"mode": "train", "epoch": 6, "iter": 50, "lr": 1e-05, "memory": 8482, "data_time": 0.21859, "stage0_loss_cls": 1.30011, "stage0_pos_acc": 57.0, "stage0_loss_bbox": 0.4, "stage0_loss_iou": 0.69414, "stage0_loss_global": 0.48538, "stage0_loss_mask": 1.45439, "stage1_loss_cls": 1.11237, "stage1_pos_acc": 69.75, "stage1_loss_bbox": 0.24403, "stage1_loss_iou": 0.44925, "stage1_loss_global": 0.47866, "stage1_loss_mask": 1.05483, "stage2_loss_cls": 0.84252, "stage2_pos_acc": 60.0, "stage2_loss_bbox": 0.24727, "stage2_loss_iou": 0.44223, "stage2_loss_global": 0.47153, "stage2_loss_mask": 1.1345, "stage3_loss_cls": 0.81657, "stage3_pos_acc": 61.0, "stage3_loss_bbox": 0.24698, "stage3_loss_iou": 0.44274, "stage3_loss_global": 0.47877, "stage3_loss_mask": 2.1011, "stage4_loss_cls": 0.6691, "stage4_pos_acc": 64.75, "stage4_loss_bbox": 0.25795, "stage4_loss_iou": 0.45909, "stage4_loss_global": 0.48092, "stage4_loss_mask": 1.08261, "stage5_loss_cls": 0.63802, "stage5_pos_acc": 61.25, "stage5_loss_bbox": 0.26059, "stage5_loss_iou": 0.46356, "stage5_loss_global": 0.48615, "stage5_loss_mask": 1.22047, "loss": 20.91585, "grad_norm": 211.53049, "time": 1.39145}
{"mode": "train", "epoch": 7, "iter": 50, "lr": 1e-05, "memory": 8482, "data_time": 0.22462, "stage0_loss_cls": 1.20005, "stage0_pos_acc": 61.5, "stage0_loss_bbox": 0.38389, "stage0_loss_iou": 0.66518, "stage0_loss_global": 0.47714, "stage0_loss_mask": 1.23131, "stage1_loss_cls": 0.95887, "stage1_pos_acc": 72.75, "stage1_loss_bbox": 0.23489, "stage1_loss_iou": 0.42315, "stage1_loss_global": 0.46567, "stage1_loss_mask": 0.88713, "stage2_loss_cls": 0.71031, "stage2_pos_acc": 61.5, "stage2_loss_bbox": 0.2444, "stage2_loss_iou": 0.44198, "stage2_loss_global": 0.45645, "stage2_loss_mask": 0.96513, "stage3_loss_cls": 0.63805, "stage3_pos_acc": 59.0, "stage3_loss_bbox": 0.24689, "stage3_loss_iou": 0.4401, "stage3_loss_global": 0.45552, "stage3_loss_mask": 1.73536, "stage4_loss_cls": 0.55775, "stage4_pos_acc": 65.5, "stage4_loss_bbox": 0.24153, "stage4_loss_iou": 0.43158, "stage4_loss_global": 0.45875, "stage4_loss_mask": 0.91278, "stage5_loss_cls": 0.54604, "stage5_pos_acc": 64.0, "stage5_loss_bbox": 0.24243, "stage5_loss_iou": 0.42968, "stage5_loss_global": 0.45095, "stage5_loss_mask": 1.00897, "loss": 18.54192, "grad_norm": 149.36154, "time": 1.39129}
{"mode": "train", "epoch": 8, "iter": 50, "lr": 1e-05, "memory": 8601, "data_time": 0.21888, "stage0_loss_cls": 1.09955, "stage0_pos_acc": 61.75, "stage0_loss_bbox": 0.33925, "stage0_loss_iou": 0.61185, "stage0_loss_global": 0.47658, "stage0_loss_mask": 1.0929, "stage1_loss_cls": 0.85876, "stage1_pos_acc": 73.0, "stage1_loss_bbox": 0.22267, "stage1_loss_iou": 0.41125, "stage1_loss_global": 0.47251, "stage1_loss_mask": 0.80411, "stage2_loss_cls": 0.61832, "stage2_pos_acc": 58.0, "stage2_loss_bbox": 0.23773, "stage2_loss_iou": 0.43069, "stage2_loss_global": 0.47193, "stage2_loss_mask": 0.87554, "stage3_loss_cls": 0.54711, "stage3_pos_acc": 65.75, "stage3_loss_bbox": 0.23491, "stage3_loss_iou": 0.42823, "stage3_loss_global": 0.46529, "stage3_loss_mask": 1.41177, "stage4_loss_cls": 0.48951, "stage4_pos_acc": 68.75, "stage4_loss_bbox": 0.23303, "stage4_loss_iou": 0.42247, "stage4_loss_global": 0.46979, "stage4_loss_mask": 0.82241, "stage5_loss_cls": 0.48857, "stage5_pos_acc": 65.25, "stage5_loss_bbox": 0.23321, "stage5_loss_iou": 0.41982, "stage5_loss_global": 0.46797, "stage5_loss_mask": 0.88149, "loss": 17.03922, "grad_norm": 141.42068, "time": 1.3834}
{"mode": "train", "epoch": 9, "iter": 50, "lr": 1e-05, "memory": 8601, "data_time": 0.22082, "stage0_loss_cls": 0.9773, "stage0_pos_acc": 61.5, "stage0_loss_bbox": 0.31746, "stage0_loss_iou": 0.58089, "stage0_loss_global": 0.46393, "stage0_loss_mask": 0.95595, "stage1_loss_cls": 0.78153, "stage1_pos_acc": 67.5, "stage1_loss_bbox": 0.22558, "stage1_loss_iou": 0.41844, "stage1_loss_global": 0.45586, "stage1_loss_mask": 0.72177, "stage2_loss_cls": 0.58657, "stage2_pos_acc": 59.0, "stage2_loss_bbox": 0.22747, "stage2_loss_iou": 0.42379, "stage2_loss_global": 0.45248, "stage2_loss_mask": 0.76125, "stage3_loss_cls": 0.51662, "stage3_pos_acc": 66.25, "stage3_loss_bbox": 0.22526, "stage3_loss_iou": 0.41537, "stage3_loss_global": 0.4401, "stage3_loss_mask": 1.17045, "stage4_loss_cls": 0.47227, "stage4_pos_acc": 68.5, "stage4_loss_bbox": 0.22875, "stage4_loss_iou": 0.41609, "stage4_loss_global": 0.43859, "stage4_loss_mask": 0.74121, "stage5_loss_cls": 0.45125, "stage5_pos_acc": 69.0, "stage5_loss_bbox": 0.22973, "stage5_loss_iou": 0.41559, "stage5_loss_global": 0.43866, "stage5_loss_mask": 0.79155, "loss": 15.74174, "grad_norm": 215.9171, "time": 1.39285}
{"mode": "train", "epoch": 10, "iter": 50, "lr": 1e-05, "memory": 8601, "data_time": 0.22078, "stage0_loss_cls": 0.89763, "stage0_pos_acc": 69.0, "stage0_loss_bbox": 0.32621, "stage0_loss_iou": 0.59245, "stage0_loss_global": 0.46027, "stage0_loss_mask": 0.80718, "stage1_loss_cls": 0.74988, "stage1_pos_acc": 74.0, "stage1_loss_bbox": 0.21453, "stage1_loss_iou": 0.39623, "stage1_loss_global": 0.45305, "stage1_loss_mask": 0.64923, "stage2_loss_cls": 0.54666, "stage2_pos_acc": 61.75, "stage2_loss_bbox": 0.22231, "stage2_loss_iou": 0.40467, "stage2_loss_global": 0.44133, "stage2_loss_mask": 0.69368, "stage3_loss_cls": 0.45744, "stage3_pos_acc": 75.75, "stage3_loss_bbox": 0.22349, "stage3_loss_iou": 0.40233, "stage3_loss_global": 0.41672, "stage3_loss_mask": 0.99259, "stage4_loss_cls": 0.43342, "stage4_pos_acc": 77.75, "stage4_loss_bbox": 0.22629, "stage4_loss_iou": 0.40061, "stage4_loss_global": 0.41768, "stage4_loss_mask": 0.68102, "stage5_loss_cls": 0.41208, "stage5_pos_acc": 78.25, "stage5_loss_bbox": 0.22842, "stage5_loss_iou": 0.40519, "stage5_loss_global": 0.39514, "stage5_loss_mask": 0.72278, "loss": 14.67053, "grad_norm": 166.75132, "time": 1.36229}
{"mode": "train", "epoch": 11, "iter": 50, "lr": 1e-05, "memory": 8601, "data_time": 0.21654, "stage0_loss_cls": 0.86365, "stage0_pos_acc": 70.25, "stage0_loss_bbox": 0.302, "stage0_loss_iou": 0.55331, "stage0_loss_global": 0.4461, "stage0_loss_mask": 0.7594, "stage1_loss_cls": 0.67857, "stage1_pos_acc": 74.0, "stage1_loss_bbox": 0.2165, "stage1_loss_iou": 0.39498, "stage1_loss_global": 0.41416, "stage1_loss_mask": 0.62083, "stage2_loss_cls": 0.46739, "stage2_pos_acc": 71.75, "stage2_loss_bbox": 0.22438, "stage2_loss_iou": 0.40723, "stage2_loss_global": 0.37371, "stage2_loss_mask": 0.64794, "stage3_loss_cls": 0.39864, "stage3_pos_acc": 81.75, "stage3_loss_bbox": 0.2197, "stage3_loss_iou": 0.39944, "stage3_loss_global": 0.3375, "stage3_loss_mask": 0.85869, "stage4_loss_cls": 0.37204, "stage4_pos_acc": 81.25, "stage4_loss_bbox": 0.21897, "stage4_loss_iou": 0.39637, "stage4_loss_global": 0.33062, "stage4_loss_mask": 0.63123, "stage5_loss_cls": 0.36524, "stage5_pos_acc": 81.25, "stage5_loss_bbox": 0.22162, "stage5_loss_iou": 0.39826, "stage5_loss_global": 0.31836, "stage5_loss_mask": 0.65894, "loss": 13.49576, "grad_norm": 196.20703, "time": 1.35745}
{"mode": "train", "epoch": 12, "iter": 50, "lr": 2e-05, "memory": 8601, "data_time": 0.2175, "stage0_loss_cls": 0.8199, "stage0_pos_acc": 75.5, "stage0_loss_bbox": 0.31021, "stage0_loss_iou": 0.56027, "stage0_loss_global": 0.39548, "stage0_loss_mask": 0.71162, "stage1_loss_cls": 0.62374, "stage1_pos_acc": 77.25, "stage1_loss_bbox": 0.21155, "stage1_loss_iou": 0.3841, "stage1_loss_global": 0.33508, "stage1_loss_mask": 0.6104, "stage2_loss_cls": 0.41752, "stage2_pos_acc": 81.0, "stage2_loss_bbox": 0.2132, "stage2_loss_iou": 0.3859, "stage2_loss_global": 0.28042, "stage2_loss_mask": 0.61891, "stage3_loss_cls": 0.35864, "stage3_pos_acc": 83.25, "stage3_loss_bbox": 0.2156, "stage3_loss_iou": 0.38296, "stage3_loss_global": 0.25366, "stage3_loss_mask": 0.79629, "stage4_loss_cls": 0.33466, "stage4_pos_acc": 85.25, "stage4_loss_bbox": 0.21028, "stage4_loss_iou": 0.37745, "stage4_loss_global": 0.24924, "stage4_loss_mask": 0.6139, "stage5_loss_cls": 0.32029, "stage5_pos_acc": 84.75, "stage5_loss_bbox": 0.21302, "stage5_loss_iou": 0.3803, "stage5_loss_global": 0.24933, "stage5_loss_mask": 0.63296, "loss": 12.46688, "grad_norm": 264.55168, "time": 1.37732}
{"mode": "train", "epoch": 13, "iter": 50, "lr": 2e-05, "memory": 8601, "data_time": 0.21788, "stage0_loss_cls": 0.75742, "stage0_pos_acc": 80.75, "stage0_loss_bbox": 0.30908, "stage0_loss_iou": 0.55961, "stage0_loss_global": 0.29624, "stage0_loss_mask": 0.70184, "stage1_loss_cls": 0.55049, "stage1_pos_acc": 86.25, "stage1_loss_bbox": 0.22101, "stage1_loss_iou": 0.40285, "stage1_loss_global": 0.24622, "stage1_loss_mask": 0.59024, "stage2_loss_cls": 0.3729, "stage2_pos_acc": 87.5, "stage2_loss_bbox": 0.22098, "stage2_loss_iou": 0.40403, "stage2_loss_global": 0.22267, "stage2_loss_mask": 0.6061, "stage3_loss_cls": 0.31237, "stage3_pos_acc": 87.75, "stage3_loss_bbox": 0.22529, "stage3_loss_iou": 0.40623, "stage3_loss_global": 0.22387, "stage3_loss_mask": 0.74703, "stage4_loss_cls": 0.28655, "stage4_pos_acc": 88.5, "stage4_loss_bbox": 0.22299, "stage4_loss_iou": 0.39999, "stage4_loss_global": 0.22149, "stage4_loss_mask": 0.612, "stage5_loss_cls": 0.27081, "stage5_pos_acc": 89.75, "stage5_loss_bbox": 0.22308, "stage5_loss_iou": 0.39973, "stage5_loss_global": 0.21834, "stage5_loss_mask": 0.62657, "loss": 11.85801, "grad_norm": 250.3321, "time": 1.36865}
{"mode": "train", "epoch": 14, "iter": 50, "lr": 2e-05, "memory": 8601, "data_time": 0.21516, "stage0_loss_cls": 0.74606, "stage0_pos_acc": 86.5, "stage0_loss_bbox": 0.30319, "stage0_loss_iou": 0.55298, "stage0_loss_global": 0.22821, "stage0_loss_mask": 0.63359, "stage1_loss_cls": 0.51654, "stage1_pos_acc": 91.5, "stage1_loss_bbox": 0.21906, "stage1_loss_iou": 0.398, "stage1_loss_global": 0.19105, "stage1_loss_mask": 0.55599, "stage2_loss_cls": 0.32713, "stage2_pos_acc": 89.0, "stage2_loss_bbox": 0.21619, "stage2_loss_iou": 0.39494, "stage2_loss_global": 0.17639, "stage2_loss_mask": 0.56943, "stage3_loss_cls": 0.28051, "stage3_pos_acc": 90.75, "stage3_loss_bbox": 0.21519, "stage3_loss_iou": 0.38883, "stage3_loss_global": 0.17206, "stage3_loss_mask": 0.67737, "stage4_loss_cls": 0.26172, "stage4_pos_acc": 91.75, "stage4_loss_bbox": 0.21377, "stage4_loss_iou": 0.38514, "stage4_loss_global": 0.17317, "stage4_loss_mask": 0.56181, "stage5_loss_cls": 0.25022, "stage5_pos_acc": 90.25, "stage5_loss_bbox": 0.21957, "stage5_loss_iou": 0.39066, "stage5_loss_global": 0.17635, "stage5_loss_mask": 0.58047, "loss": 10.9756, "grad_norm": 184.83353, "time": 1.35119}
{"mode": "train", "epoch": 15, "iter": 50, "lr": 2e-05, "memory": 8601, "data_time": 0.22242, "stage0_loss_cls": 0.72661, "stage0_pos_acc": 82.5, "stage0_loss_bbox": 0.29736, "stage0_loss_iou": 0.54513, "stage0_loss_global": 0.20644, "stage0_loss_mask": 0.62367, "stage1_loss_cls": 0.5004, "stage1_pos_acc": 90.0, "stage1_loss_bbox": 0.21164, "stage1_loss_iou": 0.38373, "stage1_loss_global": 0.17622, "stage1_loss_mask": 0.56164, "stage2_loss_cls": 0.32976, "stage2_pos_acc": 90.0, "stage2_loss_bbox": 0.21473, "stage2_loss_iou": 0.38956, "stage2_loss_global": 0.17029, "stage2_loss_mask": 0.58366, "stage3_loss_cls": 0.27418, "stage3_pos_acc": 91.0, "stage3_loss_bbox": 0.22017, "stage3_loss_iou": 0.3962, "stage3_loss_global": 0.16787, "stage3_loss_mask": 0.65731, "stage4_loss_cls": 0.25135, "stage4_pos_acc": 90.25, "stage4_loss_bbox": 0.22087, "stage4_loss_iou": 0.39437, "stage4_loss_global": 0.16596, "stage4_loss_mask": 0.56309, "stage5_loss_cls": 0.24291, "stage5_pos_acc": 90.75, "stage5_loss_bbox": 0.22293, "stage5_loss_iou": 0.39654, "stage5_loss_global": 0.17029, "stage5_loss_mask": 0.57211, "loss": 10.83696, "grad_norm": 183.80471, "time": 1.3613}
{"mode": "train", "epoch": 16, "iter": 50, "lr": 2e-05, "memory": 8601, "data_time": 0.21103, "stage0_loss_cls": 0.70432, "stage0_pos_acc": 85.25, "stage0_loss_bbox": 0.31046, "stage0_loss_iou": 0.54894, "stage0_loss_global": 0.20222, "stage0_loss_mask": 0.63754, "stage1_loss_cls": 0.48434, "stage1_pos_acc": 88.0, "stage1_loss_bbox": 0.21773, "stage1_loss_iou": 0.39564, "stage1_loss_global": 0.18936, "stage1_loss_mask": 0.57149, "stage2_loss_cls": 0.34233, "stage2_pos_acc": 86.25, "stage2_loss_bbox": 0.2163, "stage2_loss_iou": 0.39109, "stage2_loss_global": 0.19138, "stage2_loss_mask": 0.57668, "stage3_loss_cls": 0.27911, "stage3_pos_acc": 88.25, "stage3_loss_bbox": 0.218, "stage3_loss_iou": 0.38908, "stage3_loss_global": 0.20055, "stage3_loss_mask": 0.64011, "stage4_loss_cls": 0.26786, "stage4_pos_acc": 88.25, "stage4_loss_bbox": 0.21572, "stage4_loss_iou": 0.38632, "stage4_loss_global": 0.21313, "stage4_loss_mask": 0.57329, "stage5_loss_cls": 0.24707, "stage5_pos_acc": 89.0, "stage5_loss_bbox": 0.21662, "stage5_loss_iou": 0.38887, "stage5_loss_global": 0.21539, "stage5_loss_mask": 0.58413, "loss": 11.01505, "grad_norm": 242.36159, "time": 1.35786}
{"mode": "train", "epoch": 17, "iter": 50, "lr": 2e-05, "memory": 8601, "data_time": 0.21896, "stage0_loss_cls": 0.64171, "stage0_pos_acc": 90.5, "stage0_loss_bbox": 0.32297, "stage0_loss_iou": 0.57877, "stage0_loss_global": 0.15004, "stage0_loss_mask": 0.63824, "stage1_loss_cls": 0.42915, "stage1_pos_acc": 93.25, "stage1_loss_bbox": 0.22216, "stage1_loss_iou": 0.39573, "stage1_loss_global": 0.13481, "stage1_loss_mask": 0.57643, "stage2_loss_cls": 0.27699, "stage2_pos_acc": 91.75, "stage2_loss_bbox": 0.21347, "stage2_loss_iou": 0.38526, "stage2_loss_global": 0.12782, "stage2_loss_mask": 0.58714, "stage3_loss_cls": 0.21744, "stage3_pos_acc": 92.25, "stage3_loss_bbox": 0.20988, "stage3_loss_iou": 0.3794, "stage3_loss_global": 0.13097, "stage3_loss_mask": 0.62069, "stage4_loss_cls": 0.20403, "stage4_pos_acc": 92.25, "stage4_loss_bbox": 0.21396, "stage4_loss_iou": 0.38056, "stage4_loss_global": 0.12775, "stage4_loss_mask": 0.56233, "stage5_loss_cls": 0.19876, "stage5_pos_acc": 92.5, "stage5_loss_bbox": 0.21453, "stage5_loss_iou": 0.38185, "stage5_loss_global": 0.12621, "stage5_loss_mask": 0.56711, "loss": 10.21619, "grad_norm": 299.24331, "time": 1.36464}
{"mode": "train", "epoch": 18, "iter": 50, "lr": 2e-05, "memory": 8601, "data_time": 0.21607, "stage0_loss_cls": 0.63081, "stage0_pos_acc": 89.0, "stage0_loss_bbox": 0.30347, "stage0_loss_iou": 0.53971, "stage0_loss_global": 0.20458, "stage0_loss_mask": 0.58776, "stage1_loss_cls": 0.40651, "stage1_pos_acc": 91.75, "stage1_loss_bbox": 0.22445, "stage1_loss_iou": 0.39854, "stage1_loss_global": 0.21155, "stage1_loss_mask": 0.54706, "stage2_loss_cls": 0.29164, "stage2_pos_acc": 91.0, "stage2_loss_bbox": 0.21463, "stage2_loss_iou": 0.38345, "stage2_loss_global": 0.21441, "stage2_loss_mask": 0.53517, "stage3_loss_cls": 0.24413, "stage3_pos_acc": 91.5, "stage3_loss_bbox": 0.21454, "stage3_loss_iou": 0.37753, "stage3_loss_global": 0.22176, "stage3_loss_mask": 0.56868, "stage4_loss_cls": 0.23287, "stage4_pos_acc": 90.25, "stage4_loss_bbox": 0.21324, "stage4_loss_iou": 0.37432, "stage4_loss_global": 0.21184, "stage4_loss_mask": 0.52747, "stage5_loss_cls": 0.23772, "stage5_pos_acc": 91.0, "stage5_loss_bbox": 0.20884, "stage5_loss_iou": 0.37073, "stage5_loss_global": 0.21549, "stage5_loss_mask": 0.53256, "loss": 10.44545, "grad_norm": 268.20803, "time": 1.36025}
{"mode": "train", "epoch": 19, "iter": 50, "lr": 2e-05, "memory": 8601, "data_time": 0.22069, "stage0_loss_cls": 0.59442, "stage0_pos_acc": 90.5, "stage0_loss_bbox": 0.31316, "stage0_loss_iou": 0.55734, "stage0_loss_global": 0.18254, "stage0_loss_mask": 0.61141, "stage1_loss_cls": 0.37311, "stage1_pos_acc": 93.25, "stage1_loss_bbox": 0.22412, "stage1_loss_iou": 0.40594, "stage1_loss_global": 0.17645, "stage1_loss_mask": 0.53724, "stage2_loss_cls": 0.24955, "stage2_pos_acc": 92.5, "stage2_loss_bbox": 0.20608, "stage2_loss_iou": 0.38212, "stage2_loss_global": 0.17425, "stage2_loss_mask": 0.54275, "stage3_loss_cls": 0.21013, "stage3_pos_acc": 93.5, "stage3_loss_bbox": 0.20388, "stage3_loss_iou": 0.37775, "stage3_loss_global": 0.17343, "stage3_loss_mask": 0.57055, "stage4_loss_cls": 0.19046, "stage4_pos_acc": 93.25, "stage4_loss_bbox": 0.20453, "stage4_loss_iou": 0.37787, "stage4_loss_global": 0.1658, "stage4_loss_mask": 0.51479, "stage5_loss_cls": 0.17693, "stage5_pos_acc": 92.25, "stage5_loss_bbox": 0.20913, "stage5_loss_iou": 0.38356, "stage5_loss_global": 0.16589, "stage5_loss_mask": 0.52838, "loss": 9.98357, "grad_norm": 288.18437, "time": 1.36226}
{"mode": "train", "epoch": 20, "iter": 50, "lr": 3e-05, "memory": 8601, "data_time": 0.22279, "stage0_loss_cls": 0.6092, "stage0_pos_acc": 88.5, "stage0_loss_bbox": 0.31825, "stage0_loss_iou": 0.57069, "stage0_loss_global": 0.22511, "stage0_loss_mask": 0.56725, "stage1_loss_cls": 0.4121, "stage1_pos_acc": 89.75, "stage1_loss_bbox": 0.22, "stage1_loss_iou": 0.38972, "stage1_loss_global": 0.22464, "stage1_loss_mask": 0.5161, "stage2_loss_cls": 0.27439, "stage2_pos_acc": 89.5, "stage2_loss_bbox": 0.2108, "stage2_loss_iou": 0.37698, "stage2_loss_global": 0.22619, "stage2_loss_mask": 0.5289, "stage3_loss_cls": 0.24041, "stage3_pos_acc": 91.25, "stage3_loss_bbox": 0.20952, "stage3_loss_iou": 0.37144, "stage3_loss_global": 0.23477, "stage3_loss_mask": 0.55708, "stage4_loss_cls": 0.2149, "stage4_pos_acc": 91.5, "stage4_loss_bbox": 0.21264, "stage4_loss_iou": 0.37366, "stage4_loss_global": 0.23661, "stage4_loss_mask": 0.52746, "stage5_loss_cls": 0.20522, "stage5_pos_acc": 92.25, "stage5_loss_bbox": 0.21356, "stage5_loss_iou": 0.37432, "stage5_loss_global": 0.24076, "stage5_loss_mask": 0.53257, "loss": 10.41522, "grad_norm": 431.04373, "time": 1.37805}
{"mode": "train", "epoch": 21, "iter": 50, "lr": 3e-05, "memory": 8601, "data_time": 0.21234, "stage0_loss_cls": 0.6195, "stage0_pos_acc": 90.25, "stage0_loss_bbox": 0.31821, "stage0_loss_iou": 0.56402, "stage0_loss_global": 0.17105, "stage0_loss_mask": 0.58336, "stage1_loss_cls": 0.38919, "stage1_pos_acc": 93.0, "stage1_loss_bbox": 0.22477, "stage1_loss_iou": 0.39881, "stage1_loss_global": 0.17069, "stage1_loss_mask": 0.5476, "stage2_loss_cls": 0.27931, "stage2_pos_acc": 92.5, "stage2_loss_bbox": 0.20931, "stage2_loss_iou": 0.38004, "stage2_loss_global": 0.16893, "stage2_loss_mask": 0.54147, "stage3_loss_cls": 0.22378, "stage3_pos_acc": 93.0, "stage3_loss_bbox": 0.21407, "stage3_loss_iou": 0.38279, "stage3_loss_global": 0.17152, "stage3_loss_mask": 0.56249, "stage4_loss_cls": 0.19869, "stage4_pos_acc": 92.75, "stage4_loss_bbox": 0.21585, "stage4_loss_iou": 0.38338, "stage4_loss_global": 0.17044, "stage4_loss_mask": 0.53191, "stage5_loss_cls": 0.19653, "stage5_pos_acc": 92.5, "stage5_loss_bbox": 0.21102, "stage5_loss_iou": 0.38243, "stage5_loss_global": 0.17528, "stage5_loss_mask": 0.5417, "loss": 10.12813, "grad_norm": 228.88836, "time": 1.37361}
{"mode": "train", "epoch": 22, "iter": 50, "lr": 3e-05, "memory": 8601, "data_time": 0.22108, "stage0_loss_cls": 0.6038, "stage0_pos_acc": 88.5, "stage0_loss_bbox": 0.3117, "stage0_loss_iou": 0.56295, "stage0_loss_global": 0.16676, "stage0_loss_mask": 0.55617, "stage1_loss_cls": 0.3654, "stage1_pos_acc": 91.25, "stage1_loss_bbox": 0.20738, "stage1_loss_iou": 0.37524, "stage1_loss_global": 0.16622, "stage1_loss_mask": 0.50567, "stage2_loss_cls": 0.26202, "stage2_pos_acc": 92.25, "stage2_loss_bbox": 0.1975, "stage2_loss_iou": 0.35916, "stage2_loss_global": 0.16129, "stage2_loss_mask": 0.52175, "stage3_loss_cls": 0.21275, "stage3_pos_acc": 91.75, "stage3_loss_bbox": 0.19629, "stage3_loss_iou": 0.3567, "stage3_loss_global": 0.16404, "stage3_loss_mask": 0.5401, "stage4_loss_cls": 0.17813, "stage4_pos_acc": 92.0, "stage4_loss_bbox": 0.19835, "stage4_loss_iou": 0.35774, "stage4_loss_global": 0.16445, "stage4_loss_mask": 0.51505, "stage5_loss_cls": 0.17264, "stage5_pos_acc": 93.25, "stage5_loss_bbox": 0.19789, "stage5_loss_iou": 0.35836, "stage5_loss_global": 0.1638, "stage5_loss_mask": 0.5184, "loss": 9.61771, "grad_norm": 277.68184, "time": 1.35661}
{"mode": "train", "epoch": 23, "iter": 50, "lr": 3e-05, "memory": 8601, "data_time": 0.21921, "stage0_loss_cls": 0.59749, "stage0_pos_acc": 90.5, "stage0_loss_bbox": 0.30825, "stage0_loss_iou": 0.56005, "stage0_loss_global": 0.13301, "stage0_loss_mask": 0.54556, "stage1_loss_cls": 0.3403, "stage1_pos_acc": 94.0, "stage1_loss_bbox": 0.21392, "stage1_loss_iou": 0.38844, "stage1_loss_global": 0.13504, "stage1_loss_mask": 0.50519, "stage2_loss_cls": 0.23402, "stage2_pos_acc": 94.75, "stage2_loss_bbox": 0.20585, "stage2_loss_iou": 0.37562, "stage2_loss_global": 0.13272, "stage2_loss_mask": 0.51539, "stage3_loss_cls": 0.17182, "stage3_pos_acc": 94.75, "stage3_loss_bbox": 0.20494, "stage3_loss_iou": 0.37379, "stage3_loss_global": 0.12487, "stage3_loss_mask": 0.52464, "stage4_loss_cls": 0.14703, "stage4_pos_acc": 95.0, "stage4_loss_bbox": 0.2059, "stage4_loss_iou": 0.37195, "stage4_loss_global": 0.13019, "stage4_loss_mask": 0.50223, "stage5_loss_cls": 0.14324, "stage5_pos_acc": 94.75, "stage5_loss_bbox": 0.20632, "stage5_loss_iou": 0.37138, "stage5_loss_global": 0.12634, "stage5_loss_mask": 0.50816, "loss": 9.30367, "grad_norm": 404.04699, "time": 1.35635}
{"mode": "train", "epoch": 24, "iter": 50, "lr": 3e-05, "memory": 8601, "data_time": 0.21567, "stage0_loss_cls": 0.61305, "stage0_pos_acc": 87.25, "stage0_loss_bbox": 0.30031, "stage0_loss_iou": 0.54252, "stage0_loss_global": 0.23985, "stage0_loss_mask": 0.5171, "stage1_loss_cls": 0.39852, "stage1_pos_acc": 88.0, "stage1_loss_bbox": 0.20961, "stage1_loss_iou": 0.37698, "stage1_loss_global": 0.23446, "stage1_loss_mask": 0.49395, "stage2_loss_cls": 0.29578, "stage2_pos_acc": 86.5, "stage2_loss_bbox": 0.20473, "stage2_loss_iou": 0.36743, "stage2_loss_global": 0.24473, "stage2_loss_mask": 0.50658, "stage3_loss_cls": 0.26562, "stage3_pos_acc": 87.75, "stage3_loss_bbox": 0.20451, "stage3_loss_iou": 0.36314, "stage3_loss_global": 0.25439, "stage3_loss_mask": 0.52213, "stage4_loss_cls": 0.24414, "stage4_pos_acc": 86.75, "stage4_loss_bbox": 0.2084, "stage4_loss_iou": 0.37104, "stage4_loss_global": 0.25575, "stage4_loss_mask": 0.51054, "stage5_loss_cls": 0.2366, "stage5_pos_acc": 87.0, "stage5_loss_bbox": 0.20816, "stage5_loss_iou": 0.36988, "stage5_loss_global": 0.26446, "stage5_loss_mask": 0.52217, "loss": 10.34653, "grad_norm": 303.51662, "time": 1.35688}
{"mode": "train", "epoch": 25, "iter": 50, "lr": 3e-05, "memory": 8601, "data_time": 0.21992, "stage0_loss_cls": 0.52218, "stage0_pos_acc": 91.75, "stage0_loss_bbox": 0.30847, "stage0_loss_iou": 0.55691, "stage0_loss_global": 0.12436, "stage0_loss_mask": 0.53325, "stage1_loss_cls": 0.33235, "stage1_pos_acc": 94.75, "stage1_loss_bbox": 0.20555, "stage1_loss_iou": 0.37181, "stage1_loss_global": 0.12016, "stage1_loss_mask": 0.51372, "stage2_loss_cls": 0.21574, "stage2_pos_acc": 95.0, "stage2_loss_bbox": 0.20027, "stage2_loss_iou": 0.36578, "stage2_loss_global": 0.1173, "stage2_loss_mask": 0.5162, "stage3_loss_cls": 0.16584, "stage3_pos_acc": 95.5, "stage3_loss_bbox": 0.19899, "stage3_loss_iou": 0.36137, "stage3_loss_global": 0.11859, "stage3_loss_mask": 0.5229, "stage4_loss_cls": 0.14867, "stage4_pos_acc": 95.75, "stage4_loss_bbox": 0.19975, "stage4_loss_iou": 0.36135, "stage4_loss_global": 0.11638, "stage4_loss_mask": 0.4986, "stage5_loss_cls": 0.14733, "stage5_pos_acc": 96.0, "stage5_loss_bbox": 0.19929, "stage5_loss_iou": 0.3622, "stage5_loss_global": 0.11527, "stage5_loss_mask": 0.49838, "loss": 9.01897, "grad_norm": 211.24825, "time": 1.35549}
{"mode": "train", "epoch": 26, "iter": 50, "lr": 3e-05, "memory": 8601, "data_time": 0.21831, "stage0_loss_cls": 0.50336, "stage0_pos_acc": 94.25, "stage0_loss_bbox": 0.32914, "stage0_loss_iou": 0.59299, "stage0_loss_global": 0.16551, "stage0_loss_mask": 0.52444, "stage1_loss_cls": 0.32391, "stage1_pos_acc": 92.75, "stage1_loss_bbox": 0.21268, "stage1_loss_iou": 0.38504, "stage1_loss_global": 0.16353, "stage1_loss_mask": 0.49261, "stage2_loss_cls": 0.20513, "stage2_pos_acc": 92.75, "stage2_loss_bbox": 0.20426, "stage2_loss_iou": 0.36784, "stage2_loss_global": 0.15967, "stage2_loss_mask": 0.49649, "stage3_loss_cls": 0.17128, "stage3_pos_acc": 92.75, "stage3_loss_bbox": 0.20533, "stage3_loss_iou": 0.36634, "stage3_loss_global": 0.15897, "stage3_loss_mask": 0.50523, "stage4_loss_cls": 0.16117, "stage4_pos_acc": 93.0, "stage4_loss_bbox": 0.20443, "stage4_loss_iou": 0.36553, "stage4_loss_global": 0.15442, "stage4_loss_mask": 0.48738, "stage5_loss_cls": 0.15913, "stage5_pos_acc": 94.0, "stage5_loss_bbox": 0.20236, "stage5_loss_iou": 0.36358, "stage5_loss_global": 0.15593, "stage5_loss_mask": 0.4879, "loss": 9.27558, "grad_norm": 283.47554, "time": 1.35694}
{"mode": "train", "epoch": 27, "iter": 50, "lr": 3e-05, "memory": 8601, "data_time": 0.22065, "stage0_loss_cls": 0.4936, "stage0_pos_acc": 94.25, "stage0_loss_bbox": 0.31813, "stage0_loss_iou": 0.55823, "stage0_loss_global": 0.11426, "stage0_loss_mask": 0.55333, "stage1_loss_cls": 0.31, "stage1_pos_acc": 95.5, "stage1_loss_bbox": 0.21613, "stage1_loss_iou": 0.38584, "stage1_loss_global": 0.11196, "stage1_loss_mask": 0.51715, "stage2_loss_cls": 0.21614, "stage2_pos_acc": 94.25, "stage2_loss_bbox": 0.20392, "stage2_loss_iou": 0.3697, "stage2_loss_global": 0.11267, "stage2_loss_mask": 0.52654, "stage3_loss_cls": 0.17877, "stage3_pos_acc": 96.25, "stage3_loss_bbox": 0.19754, "stage3_loss_iou": 0.36284, "stage3_loss_global": 0.11813, "stage3_loss_mask": 0.5189, "stage4_loss_cls": 0.15297, "stage4_pos_acc": 95.75, "stage4_loss_bbox": 0.19809, "stage4_loss_iou": 0.3631, "stage4_loss_global": 0.11482, "stage4_loss_mask": 0.49796, "stage5_loss_cls": 0.14626, "stage5_pos_acc": 96.5, "stage5_loss_bbox": 0.20193, "stage5_loss_iou": 0.3644, "stage5_loss_global": 0.11649, "stage5_loss_mask": 0.50436, "loss": 9.04415, "grad_norm": 236.95314, "time": 1.35493}
{"mode": "train", "epoch": 28, "iter": 50, "lr": 0.0, "memory": 8601, "data_time": 0.21448, "stage0_loss_cls": 0.46928, "stage0_pos_acc": 95.0, "stage0_loss_bbox": 0.28748, "stage0_loss_iou": 0.51543, "stage0_loss_global": 0.11567, "stage0_loss_mask": 0.5267, "stage1_loss_cls": 0.29418, "stage1_pos_acc": 95.0, "stage1_loss_bbox": 0.2013, "stage1_loss_iou": 0.36292, "stage1_loss_global": 0.11272, "stage1_loss_mask": 0.49783, "stage2_loss_cls": 0.2096, "stage2_pos_acc": 93.75, "stage2_loss_bbox": 0.19607, "stage2_loss_iou": 0.35812, "stage2_loss_global": 0.1086, "stage2_loss_mask": 0.49191, "stage3_loss_cls": 0.13902, "stage3_pos_acc": 94.75, "stage3_loss_bbox": 0.19692, "stage3_loss_iou": 0.35852, "stage3_loss_global": 0.10289, "stage3_loss_mask": 0.51007, "stage4_loss_cls": 0.13584, "stage4_pos_acc": 94.5, "stage4_loss_bbox": 0.19873, "stage4_loss_iou": 0.35786, "stage4_loss_global": 0.10235, "stage4_loss_mask": 0.49428, "stage5_loss_cls": 0.12018, "stage5_pos_acc": 94.5, "stage5_loss_bbox": 0.19886, "stage5_loss_iou": 0.35509, "stage5_loss_global": 0.10522, "stage5_loss_mask": 0.49694, "loss": 8.62058, "grad_norm": 170.20657, "time": 1.3552}
{"mode": "train", "epoch": 29, "iter": 50, "lr": 0.0, "memory": 8601, "data_time": 0.21801, "stage0_loss_cls": 0.45337, "stage0_pos_acc": 95.5, "stage0_loss_bbox": 0.26924, "stage0_loss_iou": 0.4952, "stage0_loss_global": 0.09456, "stage0_loss_mask": 0.48857, "stage1_loss_cls": 0.25883, "stage1_pos_acc": 96.25, "stage1_loss_bbox": 0.19527, "stage1_loss_iou": 0.3619, "stage1_loss_global": 0.08856, "stage1_loss_mask": 0.48824, "stage2_loss_cls": 0.15742, "stage2_pos_acc": 97.5, "stage2_loss_bbox": 0.18517, "stage2_loss_iou": 0.34365, "stage2_loss_global": 0.0783, "stage2_loss_mask": 0.48584, "stage3_loss_cls": 0.1141, "stage3_pos_acc": 97.0, "stage3_loss_bbox": 0.18446, "stage3_loss_iou": 0.34009, "stage3_loss_global": 0.07315, "stage3_loss_mask": 0.49212, "stage4_loss_cls": 0.09201, "stage4_pos_acc": 97.25, "stage4_loss_bbox": 0.1881, "stage4_loss_iou": 0.34258, "stage4_loss_global": 0.07132, "stage4_loss_mask": 0.46966, "stage5_loss_cls": 0.08119, "stage5_pos_acc": 97.5, "stage5_loss_bbox": 0.1879, "stage5_loss_iou": 0.34288, "stage5_loss_global": 0.06826, "stage5_loss_mask": 0.47529, "loss": 7.96723, "grad_norm": 481.98561, "time": 1.35866}
{"mode": "train", "epoch": 30, "iter": 50, "lr": 0.0, "memory": 8601, "data_time": 0.22192, "stage0_loss_cls": 0.43079, "stage0_pos_acc": 95.25, "stage0_loss_bbox": 0.26279, "stage0_loss_iou": 0.48391, "stage0_loss_global": 0.09058, "stage0_loss_mask": 0.48843, "stage1_loss_cls": 0.24434, "stage1_pos_acc": 96.25, "stage1_loss_bbox": 0.19837, "stage1_loss_iou": 0.35407, "stage1_loss_global": 0.08723, "stage1_loss_mask": 0.47835, "stage2_loss_cls": 0.13303, "stage2_pos_acc": 97.25, "stage2_loss_bbox": 0.18932, "stage2_loss_iou": 0.34368, "stage2_loss_global": 0.07315, "stage2_loss_mask": 0.48317, "stage3_loss_cls": 0.09651, "stage3_pos_acc": 98.0, "stage3_loss_bbox": 0.18771, "stage3_loss_iou": 0.33926, "stage3_loss_global": 0.07072, "stage3_loss_mask": 0.48556, "stage4_loss_cls": 0.08204, "stage4_pos_acc": 97.75, "stage4_loss_bbox": 0.18746, "stage4_loss_iou": 0.33713, "stage4_loss_global": 0.07014, "stage4_loss_mask": 0.47036, "stage5_loss_cls": 0.07906, "stage5_pos_acc": 97.5, "stage5_loss_bbox": 0.18641, "stage5_loss_iou": 0.33493, "stage5_loss_global": 0.06882, "stage5_loss_mask": 0.47098, "loss": 7.8083, "grad_norm": 317.30555, "time": 1.3702}
{"mode": "train", "epoch": 31, "iter": 50, "lr": 0.0, "memory": 8608, "data_time": 0.21716, "stage0_loss_cls": 0.42673, "stage0_pos_acc": 94.75, "stage0_loss_bbox": 0.26626, "stage0_loss_iou": 0.48671, "stage0_loss_global": 0.10537, "stage0_loss_mask": 0.49998, "stage1_loss_cls": 0.23644, "stage1_pos_acc": 96.25, "stage1_loss_bbox": 0.19083, "stage1_loss_iou": 0.35407, "stage1_loss_global": 0.10218, "stage1_loss_mask": 0.47749, "stage2_loss_cls": 0.1401, "stage2_pos_acc": 96.0, "stage2_loss_bbox": 0.18171, "stage2_loss_iou": 0.33587, "stage2_loss_global": 0.10248, "stage2_loss_mask": 0.47218, "stage3_loss_cls": 0.10895, "stage3_pos_acc": 96.25, "stage3_loss_bbox": 0.18011, "stage3_loss_iou": 0.33287, "stage3_loss_global": 0.10676, "stage3_loss_mask": 0.48058, "stage4_loss_cls": 0.09688, "stage4_pos_acc": 96.5, "stage4_loss_bbox": 0.1814, "stage4_loss_iou": 0.33444, "stage4_loss_global": 0.10809, "stage4_loss_mask": 0.46351, "stage5_loss_cls": 0.0961, "stage5_pos_acc": 96.5, "stage5_loss_bbox": 0.18031, "stage5_loss_iou": 0.33201, "stage5_loss_global": 0.10712, "stage5_loss_mask": 0.46802, "loss": 7.9555, "grad_norm": 205.03875, "time": 1.37456}
{"mode": "train", "epoch": 32, "iter": 50, "lr": 0.0, "memory": 8608, "data_time": 0.21751, "stage0_loss_cls": 0.39915, "stage0_pos_acc": 95.5, "stage0_loss_bbox": 0.26098, "stage0_loss_iou": 0.47746, "stage0_loss_global": 0.10306, "stage0_loss_mask": 0.49194, "stage1_loss_cls": 0.2373, "stage1_pos_acc": 96.75, "stage1_loss_bbox": 0.19524, "stage1_loss_iou": 0.35532, "stage1_loss_global": 0.09671, "stage1_loss_mask": 0.47942, "stage2_loss_cls": 0.13988, "stage2_pos_acc": 95.5, "stage2_loss_bbox": 0.18599, "stage2_loss_iou": 0.34382, "stage2_loss_global": 0.08543, "stage2_loss_mask": 0.48545, "stage3_loss_cls": 0.1045, "stage3_pos_acc": 96.25, "stage3_loss_bbox": 0.18295, "stage3_loss_iou": 0.33839, "stage3_loss_global": 0.08235, "stage3_loss_mask": 0.49696, "stage4_loss_cls": 0.07957, "stage4_pos_acc": 96.75, "stage4_loss_bbox": 0.18227, "stage4_loss_iou": 0.33634, "stage4_loss_global": 0.08439, "stage4_loss_mask": 0.47677, "stage5_loss_cls": 0.07258, "stage5_pos_acc": 97.0, "stage5_loss_bbox": 0.18106, "stage5_loss_iou": 0.33327, "stage5_loss_global": 0.07897, "stage5_loss_mask": 0.47861, "loss": 7.84611, "grad_norm": 375.32529, "time": 1.35838}
{"mode": "train", "epoch": 33, "iter": 50, "lr": 0.0, "memory": 8608, "data_time": 0.22268, "stage0_loss_cls": 0.38653, "stage0_pos_acc": 96.0, "stage0_loss_bbox": 0.25471, "stage0_loss_iou": 0.46483, "stage0_loss_global": 0.08822, "stage0_loss_mask": 0.49094, "stage1_loss_cls": 0.2251, "stage1_pos_acc": 96.25, "stage1_loss_bbox": 0.19862, "stage1_loss_iou": 0.35741, "stage1_loss_global": 0.0827, "stage1_loss_mask": 0.48138, "stage2_loss_cls": 0.13382, "stage2_pos_acc": 96.5, "stage2_loss_bbox": 0.19091, "stage2_loss_iou": 0.34739, "stage2_loss_global": 0.07399, "stage2_loss_mask": 0.4809, "stage3_loss_cls": 0.08479, "stage3_pos_acc": 97.25, "stage3_loss_bbox": 0.19005, "stage3_loss_iou": 0.3437, "stage3_loss_global": 0.07164, "stage3_loss_mask": 0.49682, "stage4_loss_cls": 0.07467, "stage4_pos_acc": 97.5, "stage4_loss_bbox": 0.18948, "stage4_loss_iou": 0.34309, "stage4_loss_global": 0.06824, "stage4_loss_mask": 0.47732, "stage5_loss_cls": 0.06638, "stage5_pos_acc": 96.75, "stage5_loss_bbox": 0.18997, "stage5_loss_iou": 0.34194, "stage5_loss_global": 0.06668, "stage5_loss_mask": 0.48232, "loss": 7.74452, "grad_norm": 199.10559, "time": 1.37785}
{"mode": "train", "epoch": 34, "iter": 50, "lr": 0.0, "memory": 8608, "data_time": 0.21632, "stage0_loss_cls": 0.38885, "stage0_pos_acc": 96.0, "stage0_loss_bbox": 0.26105, "stage0_loss_iou": 0.47583, "stage0_loss_global": 0.07735, "stage0_loss_mask": 0.50844, "stage1_loss_cls": 0.22296, "stage1_pos_acc": 96.5, "stage1_loss_bbox": 0.19882, "stage1_loss_iou": 0.35809, "stage1_loss_global": 0.07328, "stage1_loss_mask": 0.48935, "stage2_loss_cls": 0.13134, "stage2_pos_acc": 97.0, "stage2_loss_bbox": 0.1918, "stage2_loss_iou": 0.34454, "stage2_loss_global": 0.06448, "stage2_loss_mask": 0.47031, "stage3_loss_cls": 0.08833, "stage3_pos_acc": 96.75, "stage3_loss_bbox": 0.18916, "stage3_loss_iou": 0.34062, "stage3_loss_global": 0.06143, "stage3_loss_mask": 0.4843, "stage4_loss_cls": 0.07338, "stage4_pos_acc": 97.5, "stage4_loss_bbox": 0.19016, "stage4_loss_iou": 0.34068, "stage4_loss_global": 0.06081, "stage4_loss_mask": 0.45792, "stage5_loss_cls": 0.06967, "stage5_pos_acc": 97.25, "stage5_loss_bbox": 0.19014, "stage5_loss_iou": 0.34229, "stage5_loss_global": 0.05937, "stage5_loss_mask": 0.46542, "loss": 7.67016, "grad_norm": 161.91045, "time": 1.35934}
{"mode": "train", "epoch": 35, "iter": 50, "lr": 0.0, "memory": 8608, "data_time": 0.22118, "stage0_loss_cls": 0.37991, "stage0_pos_acc": 96.75, "stage0_loss_bbox": 0.24754, "stage0_loss_iou": 0.46412, "stage0_loss_global": 0.05334, "stage0_loss_mask": 0.48214, "stage1_loss_cls": 0.19173, "stage1_pos_acc": 98.25, "stage1_loss_bbox": 0.18657, "stage1_loss_iou": 0.35029, "stage1_loss_global": 0.04837, "stage1_loss_mask": 0.48534, "stage2_loss_cls": 0.10998, "stage2_pos_acc": 98.75, "stage2_loss_bbox": 0.18019, "stage2_loss_iou": 0.33576, "stage2_loss_global": 0.0443, "stage2_loss_mask": 0.47652, "stage3_loss_cls": 0.06468, "stage3_pos_acc": 98.75, "stage3_loss_bbox": 0.17864, "stage3_loss_iou": 0.33325, "stage3_loss_global": 0.04376, "stage3_loss_mask": 0.4912, "stage4_loss_cls": 0.04982, "stage4_pos_acc": 99.5, "stage4_loss_bbox": 0.17914, "stage4_loss_iou": 0.33382, "stage4_loss_global": 0.04175, "stage4_loss_mask": 0.46929, "stage5_loss_cls": 0.04737, "stage5_pos_acc": 98.75, "stage5_loss_bbox": 0.17678, "stage5_loss_iou": 0.32969, "stage5_loss_global": 0.03992, "stage5_loss_mask": 0.47301, "loss": 7.28823, "grad_norm": 112.22672, "time": 1.37029}
{"mode": "train", "epoch": 36, "iter": 50, "lr": 0.0, "memory": 8608, "data_time": 0.21592, "stage0_loss_cls": 0.37492, "stage0_pos_acc": 96.75, "stage0_loss_bbox": 0.25561, "stage0_loss_iou": 0.47017, "stage0_loss_global": 0.0664, "stage0_loss_mask": 0.48496, "stage1_loss_cls": 0.20792, "stage1_pos_acc": 97.5, "stage1_loss_bbox": 0.19226, "stage1_loss_iou": 0.35572, "stage1_loss_global": 0.06106, "stage1_loss_mask": 0.48166, "stage2_loss_cls": 0.11147, "stage2_pos_acc": 98.0, "stage2_loss_bbox": 0.18806, "stage2_loss_iou": 0.34761, "stage2_loss_global": 0.05086, "stage2_loss_mask": 0.48019, "stage3_loss_cls": 0.08143, "stage3_pos_acc": 98.0, "stage3_loss_bbox": 0.18793, "stage3_loss_iou": 0.34608, "stage3_loss_global": 0.04878, "stage3_loss_mask": 0.48651, "stage4_loss_cls": 0.06549, "stage4_pos_acc": 98.75, "stage4_loss_bbox": 0.19112, "stage4_loss_iou": 0.34723, "stage4_loss_global": 0.0449, "stage4_loss_mask": 0.47948, "stage5_loss_cls": 0.05536, "stage5_pos_acc": 98.5, "stage5_loss_bbox": 0.19396, "stage5_loss_iou": 0.35057, "stage5_loss_global": 0.042, "stage5_loss_mask": 0.48303, "loss": 7.53269, "grad_norm": 327.76625, "time": 1.3547}
