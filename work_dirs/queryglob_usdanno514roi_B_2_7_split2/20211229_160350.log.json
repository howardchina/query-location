{"env_info": "sys.platform: linux\nPython: 3.8.10 (default, Jun  4 2021, 15:09:15) [GCC 7.5.0]\nCUDA available: True\nGPU 0,1,2,3: NVIDIA TITAN Xp\nCUDA_HOME: /usr/local/cuda\nNVCC: Cuda compilation tools, release 10.2, V10.2.89\nGCC: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609\nPyTorch: 1.7.0\nPyTorch compiling details: PyTorch built with:\n  - GCC 7.3\n  - C++ Version: 201402\n  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 10.2\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75\n  - CuDNN 7.6.5\n  - Magma 2.5.2\n  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n\nTorchVision: 0.8.1\nOpenCV: 4.5.3\nMMCV: 1.3.18\nMMCV Compiler: GCC 7.3\nMMCV CUDA Compiler: 10.2\nMMDetection: 2.12.0+170db93", "config": "dataset_type = 'AnatomyDataset'\ndata_root = '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi'\nsplit = 'split_2'\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\nalbu_train_transforms = [\n    dict(\n        type='OneOf',\n        transforms=[\n            dict(\n                type='Affine',\n                translate_percent=0.0,\n                rotate=90,\n                fit_output=True,\n                p=0.25),\n            dict(\n                type='Affine',\n                translate_percent=0.0,\n                rotate=180,\n                fit_output=True,\n                p=0.25),\n            dict(\n                type='Affine',\n                translate_percent=0.0,\n                rotate=270,\n                fit_output=True,\n                p=0.25)\n        ],\n        p=0.75)\n]\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n    dict(type='LoadAnatomy'),\n    dict(type='RandomFlip', flip_ratio=0.5),\n    dict(\n        type='Albu',\n        transforms=[\n            dict(\n                type='OneOf',\n                transforms=[\n                    dict(\n                        type='Affine',\n                        translate_percent=0.0,\n                        rotate=90,\n                        fit_output=True,\n                        p=0.25),\n                    dict(\n                        type='Affine',\n                        translate_percent=0.0,\n                        rotate=180,\n                        fit_output=True,\n                        p=0.25),\n                    dict(\n                        type='Affine',\n                        translate_percent=0.0,\n                        rotate=270,\n                        fit_output=True,\n                        p=0.25)\n                ],\n                p=0.75)\n        ],\n        bbox_params=dict(\n            type='BboxParams',\n            format='pascal_voc',\n            label_fields=['gt_labels'],\n            min_visibility=0.0,\n            filter_lost_elements=True),\n        keymap=dict(img='image', gt_masks='masks', gt_bboxes='bboxes'),\n        update_pad_shape=False,\n        skip_img_without_anno=True),\n    dict(\n        type='Resize',\n        img_scale=[(1333, 480), (1333, 512), (1333, 544), (1333, 576),\n                   (1333, 608), (1333, 640), (1333, 672), (1333, 704),\n                   (1333, 736), (1333, 768), (1333, 800)],\n        multiscale_mode='value',\n        keep_ratio=True),\n    dict(\n        type='Normalize',\n        mean=[123.675, 116.28, 103.53],\n        std=[58.395, 57.12, 57.375],\n        to_rgb=True),\n    dict(type='Pad', size_divisor=32),\n    dict(type='DefaultFormatBundle'),\n    dict(type='FormatAnatomyBundle'),\n    dict(\n        type='Collect',\n        keys=['img', 'anatomy', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnatomy'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(1333, 800),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='FormatAnatomyBundle'),\n            dict(type='Collect', keys=['img', 'anatomy'])\n        ])\n]\ndata = dict(\n    samples_per_gpu=2,\n    workers_per_gpu=2,\n    train=dict(\n        type='AnatomyDataset',\n        ann_file=\n        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/annotations/train_anno_crop_split_2.json',\n        img_prefix=\n        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/images/',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n            dict(type='LoadAnatomy'),\n            dict(type='RandomFlip', flip_ratio=0.5),\n            dict(\n                type='Albu',\n                transforms=[\n                    dict(\n                        type='OneOf',\n                        transforms=[\n                            dict(\n                                type='Affine',\n                                translate_percent=0.0,\n                                rotate=90,\n                                fit_output=True,\n                                p=0.25),\n                            dict(\n                                type='Affine',\n                                translate_percent=0.0,\n                                rotate=180,\n                                fit_output=True,\n                                p=0.25),\n                            dict(\n                                type='Affine',\n                                translate_percent=0.0,\n                                rotate=270,\n                                fit_output=True,\n                                p=0.25)\n                        ],\n                        p=0.75)\n                ],\n                bbox_params=dict(\n                    type='BboxParams',\n                    format='pascal_voc',\n                    label_fields=['gt_labels'],\n                    min_visibility=0.0,\n                    filter_lost_elements=True),\n                keymap=dict(img='image', gt_masks='masks', gt_bboxes='bboxes'),\n                update_pad_shape=False,\n                skip_img_without_anno=True),\n            dict(\n                type='Resize',\n                img_scale=[(1333, 480), (1333, 512), (1333, 544), (1333, 576),\n                           (1333, 608), (1333, 640), (1333, 672), (1333, 704),\n                           (1333, 736), (1333, 768), (1333, 800)],\n                multiscale_mode='value',\n                keep_ratio=True),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='DefaultFormatBundle'),\n            dict(type='FormatAnatomyBundle'),\n            dict(\n                type='Collect',\n                keys=['img', 'anatomy', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n        ],\n        classes=('lmym', 'GIST')),\n    val=dict(\n        type='AnatomyDataset',\n        ann_file=\n        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/annotations/val_anno_crop_split_2.json',\n        img_prefix=\n        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/images/',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnatomy'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(1333, 800),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='Pad', size_divisor=32),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='FormatAnatomyBundle'),\n                    dict(type='Collect', keys=['img', 'anatomy'])\n                ])\n        ],\n        classes=('lmym', 'GIST')),\n    test=dict(\n        type='AnatomyDataset',\n        ann_file=\n        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/annotations/val_anno_crop_split_2.json',\n        img_prefix=\n        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/images/',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnatomy'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(1333, 800),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='Pad', size_divisor=32),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='FormatAnatomyBundle'),\n                    dict(type='Collect', keys=['img', 'anatomy'])\n                ])\n        ],\n        classes=('lmym', 'GIST')))\nevaluation = dict(metric=['bbox', 'segm', 'glob'])\noptimizer = dict(type='AdamW', lr=2.5e-05, weight_decay=0.0001)\noptimizer_config = dict(grad_clip=dict(max_norm=1, norm_type=2))\nlr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=1000,\n    warmup_ratio=0.001,\n    step=[27, 33])\nrunner = dict(type='EpochBasedRunner', max_epochs=36)\ncheckpoint_config = dict(interval=1)\nlog_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\ncustom_hooks = [dict(type='NumClassCheckHook')]\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = 'work_dirs/pretrained/queryInst/queryinst_r101_300_queries-860dc5d5.pth'\nresume_from = None\nworkflow = [('train', 1)]\nnum_stages = 6\nnum_proposals = 300\nmodel = dict(\n    type='QueryGlob',\n    pretrained='torchvision://resnet101',\n    backbone=dict(\n        type='ResNet',\n        depth=101,\n        num_stages=4,\n        out_indices=(0, 1, 2, 3),\n        frozen_stages=1,\n        norm_cfg=dict(type='BN', requires_grad=True),\n        norm_eval=True,\n        style='pytorch'),\n    neck=dict(\n        type='FPN',\n        in_channels=[256, 512, 1024, 2048],\n        out_channels=256,\n        start_level=0,\n        add_extra_convs='on_input',\n        num_outs=4),\n    rpn_head=dict(\n        type='GlobalEmbeddingRPNHead',\n        num_proposals=300,\n        dim_global=7,\n        proposal_feature_channel=256),\n    roi_head=dict(\n        type='QueryGlobRoIHead',\n        num_stages=6,\n        stage_loss_weights=[1, 1, 1, 1, 1, 1],\n        proposal_feature_channel=256,\n        bbox_roi_extractor=dict(\n            type='SingleRoIExtractor',\n            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=2),\n            out_channels=256,\n            featmap_strides=[4, 8, 16, 32]),\n        mask_roi_extractor=dict(\n            type='SingleRoIExtractor',\n            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=2),\n            out_channels=256,\n            featmap_strides=[4, 8, 16, 32]),\n        bbox_head=[\n            dict(\n                type='GlobDIIHead',\n                num_classes=2,\n                num_ffn_fcs=2,\n                num_heads=8,\n                num_cls_fcs=2,\n                num_glb_fcs=2,\n                num_reg_fcs=3,\n                feedforward_channels=2048,\n                in_channels=256,\n                dropout=0.0,\n                ffn_act_cfg=dict(type='ReLU', inplace=True),\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=7,\n                    with_proj=True,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n                loss_cls=dict(\n                    type='FocalLoss',\n                    use_sigmoid=True,\n                    gamma=2.0,\n                    alpha=0.25,\n                    loss_weight=2.0),\n                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    clip_border=False,\n                    target_means=[0.0, 0.0, 0.0, 0.0],\n                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n            dict(\n                type='GlobDIIHead',\n                num_classes=2,\n                num_ffn_fcs=2,\n                num_heads=8,\n                num_cls_fcs=2,\n                num_glb_fcs=2,\n                num_reg_fcs=3,\n                feedforward_channels=2048,\n                in_channels=256,\n                dropout=0.0,\n                ffn_act_cfg=dict(type='ReLU', inplace=True),\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=7,\n                    with_proj=True,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n                loss_cls=dict(\n                    type='FocalLoss',\n                    use_sigmoid=True,\n                    gamma=2.0,\n                    alpha=0.25,\n                    loss_weight=2.0),\n                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    clip_border=False,\n                    target_means=[0.0, 0.0, 0.0, 0.0],\n                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n            dict(\n                type='GlobDIIHead',\n                num_classes=2,\n                num_ffn_fcs=2,\n                num_heads=8,\n                num_cls_fcs=2,\n                num_glb_fcs=2,\n                num_reg_fcs=3,\n                feedforward_channels=2048,\n                in_channels=256,\n                dropout=0.0,\n                ffn_act_cfg=dict(type='ReLU', inplace=True),\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=7,\n                    with_proj=True,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n                loss_cls=dict(\n                    type='FocalLoss',\n                    use_sigmoid=True,\n                    gamma=2.0,\n                    alpha=0.25,\n                    loss_weight=2.0),\n                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    clip_border=False,\n                    target_means=[0.0, 0.0, 0.0, 0.0],\n                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n            dict(\n                type='GlobDIIHead',\n                num_classes=2,\n                num_ffn_fcs=2,\n                num_heads=8,\n                num_cls_fcs=2,\n                num_glb_fcs=2,\n                num_reg_fcs=3,\n                feedforward_channels=2048,\n                in_channels=256,\n                dropout=0.0,\n                ffn_act_cfg=dict(type='ReLU', inplace=True),\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=7,\n                    with_proj=True,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n                loss_cls=dict(\n                    type='FocalLoss',\n                    use_sigmoid=True,\n                    gamma=2.0,\n                    alpha=0.25,\n                    loss_weight=2.0),\n                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    clip_border=False,\n                    target_means=[0.0, 0.0, 0.0, 0.0],\n                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n            dict(\n                type='GlobDIIHead',\n                num_classes=2,\n                num_ffn_fcs=2,\n                num_heads=8,\n                num_cls_fcs=2,\n                num_glb_fcs=2,\n                num_reg_fcs=3,\n                feedforward_channels=2048,\n                in_channels=256,\n                dropout=0.0,\n                ffn_act_cfg=dict(type='ReLU', inplace=True),\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=7,\n                    with_proj=True,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n                loss_cls=dict(\n                    type='FocalLoss',\n                    use_sigmoid=True,\n                    gamma=2.0,\n                    alpha=0.25,\n                    loss_weight=2.0),\n                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    clip_border=False,\n                    target_means=[0.0, 0.0, 0.0, 0.0],\n                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n            dict(\n                type='GlobDIIHead',\n                num_classes=2,\n                num_ffn_fcs=2,\n                num_heads=8,\n                num_cls_fcs=2,\n                num_glb_fcs=2,\n                num_reg_fcs=3,\n                feedforward_channels=2048,\n                in_channels=256,\n                dropout=0.0,\n                ffn_act_cfg=dict(type='ReLU', inplace=True),\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=7,\n                    with_proj=True,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n                loss_cls=dict(\n                    type='FocalLoss',\n                    use_sigmoid=True,\n                    gamma=2.0,\n                    alpha=0.25,\n                    loss_weight=2.0),\n                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    clip_border=False,\n                    target_means=[0.0, 0.0, 0.0, 0.0],\n                    target_stds=[0.5, 0.5, 1.0, 1.0]))\n        ],\n        mask_head=[\n            dict(\n                type='DynamicMaskHead',\n                num_classes=2,\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=14,\n                    with_proj=False,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                dropout=0.0,\n                num_convs=4,\n                roi_feat_size=14,\n                in_channels=256,\n                conv_kernel_size=3,\n                conv_out_channels=256,\n                class_agnostic=False,\n                norm_cfg=dict(type='BN'),\n                upsample_cfg=dict(type='deconv', scale_factor=2),\n                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n            dict(\n                type='DynamicMaskHead',\n                num_classes=2,\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=14,\n                    with_proj=False,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                dropout=0.0,\n                num_convs=4,\n                roi_feat_size=14,\n                in_channels=256,\n                conv_kernel_size=3,\n                conv_out_channels=256,\n                class_agnostic=False,\n                norm_cfg=dict(type='BN'),\n                upsample_cfg=dict(type='deconv', scale_factor=2),\n                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n            dict(\n                type='DynamicMaskHead',\n                num_classes=2,\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=14,\n                    with_proj=False,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                dropout=0.0,\n                num_convs=4,\n                roi_feat_size=14,\n                in_channels=256,\n                conv_kernel_size=3,\n                conv_out_channels=256,\n                class_agnostic=False,\n                norm_cfg=dict(type='BN'),\n                upsample_cfg=dict(type='deconv', scale_factor=2),\n                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n            dict(\n                type='DynamicMaskHead',\n                num_classes=2,\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=14,\n                    with_proj=False,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                dropout=0.0,\n                num_convs=4,\n                roi_feat_size=14,\n                in_channels=256,\n                conv_kernel_size=3,\n                conv_out_channels=256,\n                class_agnostic=False,\n                norm_cfg=dict(type='BN'),\n                upsample_cfg=dict(type='deconv', scale_factor=2),\n                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n            dict(\n                type='DynamicMaskHead',\n                num_classes=2,\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=14,\n                    with_proj=False,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                dropout=0.0,\n                num_convs=4,\n                roi_feat_size=14,\n                in_channels=256,\n                conv_kernel_size=3,\n                conv_out_channels=256,\n                class_agnostic=False,\n                norm_cfg=dict(type='BN'),\n                upsample_cfg=dict(type='deconv', scale_factor=2),\n                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n            dict(\n                type='DynamicMaskHead',\n                num_classes=2,\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=14,\n                    with_proj=False,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                dropout=0.0,\n                num_convs=4,\n                roi_feat_size=14,\n                in_channels=256,\n                conv_kernel_size=3,\n                conv_out_channels=256,\n                class_agnostic=False,\n                norm_cfg=dict(type='BN'),\n                upsample_cfg=dict(type='deconv', scale_factor=2),\n                loss_dice=dict(type='DiceLoss', loss_weight=8.0))\n        ]),\n    train_cfg=dict(\n        rpn=None,\n        rcnn=[\n            dict(\n                assigner=dict(\n                    type='HungarianAssigner',\n                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n                                  weight=2.0)),\n                sampler=dict(type='PseudoSampler'),\n                pos_weight=1,\n                mask_size=28,\n                debug=False),\n            dict(\n                assigner=dict(\n                    type='HungarianAssigner',\n                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n                                  weight=2.0)),\n                sampler=dict(type='PseudoSampler'),\n                pos_weight=1,\n                mask_size=28,\n                debug=False),\n            dict(\n                assigner=dict(\n                    type='HungarianAssigner',\n                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n                                  weight=2.0)),\n                sampler=dict(type='PseudoSampler'),\n                pos_weight=1,\n                mask_size=28,\n                debug=False),\n            dict(\n                assigner=dict(\n                    type='HungarianAssigner',\n                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n                                  weight=2.0)),\n                sampler=dict(type='PseudoSampler'),\n                pos_weight=1,\n                mask_size=28,\n                debug=False),\n            dict(\n                assigner=dict(\n                    type='HungarianAssigner',\n                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n                                  weight=2.0)),\n                sampler=dict(type='PseudoSampler'),\n                pos_weight=1,\n                mask_size=28,\n                debug=False),\n            dict(\n                assigner=dict(\n                    type='HungarianAssigner',\n                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n                                  weight=2.0)),\n                sampler=dict(type='PseudoSampler'),\n                pos_weight=1,\n                mask_size=28,\n                debug=False)\n        ]),\n    test_cfg=dict(\n        rpn=None,\n        rcnn=dict(\n            max_per_img=300,\n            mask_thr_binary=0.5,\n            nms=dict(type='nms', iou_threshold=0.7))))\ntotal_epochs = 36\nmin_values = (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)\nclasses = ('lmym', 'GIST')\ngpu_ids = range(0, 4)\nwork_dir = './work_dirs/queryglob_usdanno514roi_B_2_7_split2'\n", "seed": null, "exp_name": "queryglob_usdanno514roi_B_2_7_split2.py"}
{"mode": "train", "epoch": 1, "iter": 50, "lr": 0.0, "memory": 8378, "data_time": 0.21532, "stage0_loss_cls": 2.0969, "stage0_pos_acc": 53.5, "stage0_loss_bbox": 0.63739, "stage0_loss_iou": 1.00675, "stage0_loss_global": 0.67872, "stage0_loss_mask": 2.81067, "stage1_loss_cls": 1.88821, "stage1_pos_acc": 55.5, "stage1_loss_bbox": 0.54058, "stage1_loss_iou": 0.87639, "stage1_loss_global": 1.36576, "stage1_loss_mask": 2.46399, "stage2_loss_cls": 2.54952, "stage2_pos_acc": 49.25, "stage2_loss_bbox": 0.55385, "stage2_loss_iou": 0.8803, "stage2_loss_global": 0.676, "stage2_loss_mask": 2.77297, "stage3_loss_cls": 2.40609, "stage3_pos_acc": 51.25, "stage3_loss_bbox": 0.56383, "stage3_loss_iou": 0.87834, "stage3_loss_global": 0.85738, "stage3_loss_mask": 2.85616, "stage4_loss_cls": 1.71908, "stage4_pos_acc": 49.25, "stage4_loss_bbox": 0.56733, "stage4_loss_iou": 0.8963, "stage4_loss_global": 1.17443, "stage4_loss_mask": 3.21875, "stage5_loss_cls": 2.30273, "stage5_pos_acc": 51.0, "stage5_loss_bbox": 0.57092, "stage5_loss_iou": 0.91386, "stage5_loss_global": 0.61021, "stage5_loss_mask": 3.03439, "loss": 44.36779, "grad_norm": 225.34055, "time": 1.32521}
{"mode": "train", "epoch": 2, "iter": 50, "lr": 0.0, "memory": 8605, "data_time": 0.21441, "stage0_loss_cls": 1.91034, "stage0_pos_acc": 50.75, "stage0_loss_bbox": 0.57229, "stage0_loss_iou": 0.92648, "stage0_loss_global": 0.61092, "stage0_loss_mask": 2.77756, "stage1_loss_cls": 1.73293, "stage1_pos_acc": 56.0, "stage1_loss_bbox": 0.45085, "stage1_loss_iou": 0.75642, "stage1_loss_global": 0.87784, "stage1_loss_mask": 2.35458, "stage2_loss_cls": 2.37305, "stage2_pos_acc": 48.25, "stage2_loss_bbox": 0.43921, "stage2_loss_iou": 0.7238, "stage2_loss_global": 0.52467, "stage2_loss_mask": 2.60931, "stage3_loss_cls": 2.14697, "stage3_pos_acc": 56.0, "stage3_loss_bbox": 0.43826, "stage3_loss_iou": 0.71006, "stage3_loss_global": 0.62181, "stage3_loss_mask": 2.62003, "stage4_loss_cls": 1.60276, "stage4_pos_acc": 52.75, "stage4_loss_bbox": 0.43237, "stage4_loss_iou": 0.70877, "stage4_loss_global": 0.58175, "stage4_loss_mask": 2.95931, "stage5_loss_cls": 1.95387, "stage5_pos_acc": 51.75, "stage5_loss_bbox": 0.42205, "stage5_loss_iou": 0.70382, "stage5_loss_global": 0.54006, "stage5_loss_mask": 2.74537, "loss": 38.82753, "grad_norm": 196.28487, "time": 1.33278}
{"mode": "train", "epoch": 3, "iter": 50, "lr": 0.0, "memory": 8605, "data_time": 0.21612, "stage0_loss_cls": 1.60277, "stage0_pos_acc": 52.5, "stage0_loss_bbox": 0.55706, "stage0_loss_iou": 0.89456, "stage0_loss_global": 0.52857, "stage0_loss_mask": 2.59601, "stage1_loss_cls": 1.47201, "stage1_pos_acc": 55.75, "stage1_loss_bbox": 0.38864, "stage1_loss_iou": 0.65579, "stage1_loss_global": 0.56803, "stage1_loss_mask": 2.11448, "stage2_loss_cls": 1.89428, "stage2_pos_acc": 50.5, "stage2_loss_bbox": 0.35079, "stage2_loss_iou": 0.60459, "stage2_loss_global": 0.48139, "stage2_loss_mask": 2.25413, "stage3_loss_cls": 1.63379, "stage3_pos_acc": 60.25, "stage3_loss_bbox": 0.34997, "stage3_loss_iou": 0.59944, "stage3_loss_global": 0.49714, "stage3_loss_mask": 2.18025, "stage4_loss_cls": 1.42615, "stage4_pos_acc": 56.5, "stage4_loss_bbox": 0.3433, "stage4_loss_iou": 0.59239, "stage4_loss_global": 0.48619, "stage4_loss_mask": 2.44649, "stage5_loss_cls": 1.44052, "stage5_pos_acc": 52.0, "stage5_loss_bbox": 0.34221, "stage5_loss_iou": 0.59307, "stage5_loss_global": 0.49927, "stage5_loss_mask": 2.36694, "loss": 32.76019, "grad_norm": 159.27714, "time": 1.31889}
{"mode": "train", "epoch": 4, "iter": 50, "lr": 1e-05, "memory": 8605, "data_time": 0.20997, "stage0_loss_cls": 1.44786, "stage0_pos_acc": 56.25, "stage0_loss_bbox": 0.50509, "stage0_loss_iou": 0.84255, "stage0_loss_global": 0.50292, "stage0_loss_mask": 2.13181, "stage1_loss_cls": 1.36169, "stage1_pos_acc": 55.0, "stage1_loss_bbox": 0.31691, "stage1_loss_iou": 0.56335, "stage1_loss_global": 0.51172, "stage1_loss_mask": 1.71849, "stage2_loss_cls": 1.42805, "stage2_pos_acc": 50.5, "stage2_loss_bbox": 0.27633, "stage2_loss_iou": 0.49698, "stage2_loss_global": 0.48171, "stage2_loss_mask": 1.82693, "stage3_loss_cls": 1.2236, "stage3_pos_acc": 57.25, "stage3_loss_bbox": 0.27756, "stage3_loss_iou": 0.4999, "stage3_loss_global": 0.48297, "stage3_loss_mask": 1.69956, "stage4_loss_cls": 1.20596, "stage4_pos_acc": 60.0, "stage4_loss_bbox": 0.26518, "stage4_loss_iou": 0.47868, "stage4_loss_global": 0.47848, "stage4_loss_mask": 1.87935, "stage5_loss_cls": 1.13957, "stage5_pos_acc": 58.75, "stage5_loss_bbox": 0.27162, "stage5_loss_iou": 0.48866, "stage5_loss_global": 0.49327, "stage5_loss_mask": 1.85118, "loss": 27.14793, "grad_norm": 138.35592, "time": 1.30679}
{"mode": "train", "epoch": 5, "iter": 50, "lr": 1e-05, "memory": 8605, "data_time": 0.21834, "stage0_loss_cls": 1.35411, "stage0_pos_acc": 58.75, "stage0_loss_bbox": 0.46861, "stage0_loss_iou": 0.78996, "stage0_loss_global": 0.48022, "stage0_loss_mask": 1.83517, "stage1_loss_cls": 1.23279, "stage1_pos_acc": 58.25, "stage1_loss_bbox": 0.27108, "stage1_loss_iou": 0.49889, "stage1_loss_global": 0.48234, "stage1_loss_mask": 1.49172, "stage2_loss_cls": 1.10606, "stage2_pos_acc": 59.75, "stage2_loss_bbox": 0.24136, "stage2_loss_iou": 0.44385, "stage2_loss_global": 0.47068, "stage2_loss_mask": 1.50343, "stage3_loss_cls": 0.94068, "stage3_pos_acc": 57.75, "stage3_loss_bbox": 0.27106, "stage3_loss_iou": 0.48393, "stage3_loss_global": 0.46685, "stage3_loss_mask": 1.37645, "stage4_loss_cls": 1.01454, "stage4_pos_acc": 63.75, "stage4_loss_bbox": 0.24176, "stage4_loss_iou": 0.43227, "stage4_loss_global": 0.46809, "stage4_loss_mask": 1.51024, "stage5_loss_cls": 0.85638, "stage5_pos_acc": 63.75, "stage5_loss_bbox": 0.25832, "stage5_loss_iou": 0.46307, "stage5_loss_global": 0.47, "stage5_loss_mask": 1.51149, "loss": 23.43541, "grad_norm": 143.88173, "time": 1.31152}
{"mode": "train", "epoch": 6, "iter": 50, "lr": 1e-05, "memory": 8605, "data_time": 0.21723, "stage0_loss_cls": 1.31124, "stage0_pos_acc": 58.0, "stage0_loss_bbox": 0.43965, "stage0_loss_iou": 0.75745, "stage0_loss_global": 0.48139, "stage0_loss_mask": 1.52396, "stage1_loss_cls": 1.1129, "stage1_pos_acc": 62.25, "stage1_loss_bbox": 0.2367, "stage1_loss_iou": 0.44271, "stage1_loss_global": 0.48094, "stage1_loss_mask": 1.20749, "stage2_loss_cls": 0.95653, "stage2_pos_acc": 66.25, "stage2_loss_bbox": 0.22374, "stage2_loss_iou": 0.4138, "stage2_loss_global": 0.4717, "stage2_loss_mask": 1.24164, "stage3_loss_cls": 0.69648, "stage3_pos_acc": 63.5, "stage3_loss_bbox": 0.25336, "stage3_loss_iou": 0.46428, "stage3_loss_global": 0.46885, "stage3_loss_mask": 1.12461, "stage4_loss_cls": 0.70915, "stage4_pos_acc": 66.5, "stage4_loss_bbox": 0.24342, "stage4_loss_iou": 0.44624, "stage4_loss_global": 0.46922, "stage4_loss_mask": 1.24052, "stage5_loss_cls": 0.62345, "stage5_pos_acc": 65.25, "stage5_loss_bbox": 0.25592, "stage5_loss_iou": 0.45954, "stage5_loss_global": 0.46749, "stage5_loss_mask": 1.20216, "loss": 20.42654, "grad_norm": 152.97106, "time": 1.30982}
{"mode": "train", "epoch": 7, "iter": 50, "lr": 1e-05, "memory": 8605, "data_time": 0.21994, "stage0_loss_cls": 1.27903, "stage0_pos_acc": 54.75, "stage0_loss_bbox": 0.38671, "stage0_loss_iou": 0.6839, "stage0_loss_global": 0.48454, "stage0_loss_mask": 1.24844, "stage1_loss_cls": 0.95741, "stage1_pos_acc": 64.0, "stage1_loss_bbox": 0.23114, "stage1_loss_iou": 0.42731, "stage1_loss_global": 0.48168, "stage1_loss_mask": 1.07773, "stage2_loss_cls": 0.86046, "stage2_pos_acc": 71.5, "stage2_loss_bbox": 0.22045, "stage2_loss_iou": 0.39926, "stage2_loss_global": 0.48683, "stage2_loss_mask": 1.09124, "stage3_loss_cls": 0.60505, "stage3_pos_acc": 58.5, "stage3_loss_bbox": 0.2499, "stage3_loss_iou": 0.44428, "stage3_loss_global": 0.48554, "stage3_loss_mask": 0.99637, "stage4_loss_cls": 0.58752, "stage4_pos_acc": 64.0, "stage4_loss_bbox": 0.24187, "stage4_loss_iou": 0.43412, "stage4_loss_global": 0.48449, "stage4_loss_mask": 1.05918, "stage5_loss_cls": 0.54858, "stage5_pos_acc": 70.25, "stage5_loss_bbox": 0.24644, "stage5_loss_iou": 0.43725, "stage5_loss_global": 0.46183, "stage5_loss_mask": 1.03796, "loss": 18.63648, "grad_norm": 134.45456, "time": 1.32574}
{"mode": "train", "epoch": 8, "iter": 50, "lr": 1e-05, "memory": 8605, "data_time": 0.21957, "stage0_loss_cls": 1.1418, "stage0_pos_acc": 63.25, "stage0_loss_bbox": 0.36752, "stage0_loss_iou": 0.64648, "stage0_loss_global": 0.47427, "stage0_loss_mask": 1.15423, "stage1_loss_cls": 0.86651, "stage1_pos_acc": 66.0, "stage1_loss_bbox": 0.23127, "stage1_loss_iou": 0.42302, "stage1_loss_global": 0.4716, "stage1_loss_mask": 0.97683, "stage2_loss_cls": 0.74632, "stage2_pos_acc": 65.75, "stage2_loss_bbox": 0.22708, "stage2_loss_iou": 0.41258, "stage2_loss_global": 0.45694, "stage2_loss_mask": 0.95059, "stage3_loss_cls": 0.53125, "stage3_pos_acc": 63.0, "stage3_loss_bbox": 0.24978, "stage3_loss_iou": 0.43996, "stage3_loss_global": 0.4495, "stage3_loss_mask": 0.87525, "stage4_loss_cls": 0.51021, "stage4_pos_acc": 70.75, "stage4_loss_bbox": 0.24765, "stage4_loss_iou": 0.438, "stage4_loss_global": 0.44189, "stage4_loss_mask": 0.92436, "stage5_loss_cls": 0.46401, "stage5_pos_acc": 76.25, "stage5_loss_bbox": 0.24805, "stage5_loss_iou": 0.43877, "stage5_loss_global": 0.42725, "stage5_loss_mask": 0.9168, "loss": 17.14978, "grad_norm": 171.39519, "time": 1.3325}
{"mode": "train", "epoch": 9, "iter": 50, "lr": 1e-05, "memory": 8605, "data_time": 0.22138, "stage0_loss_cls": 1.02662, "stage0_pos_acc": 64.5, "stage0_loss_bbox": 0.34455, "stage0_loss_iou": 0.60417, "stage0_loss_global": 0.46767, "stage0_loss_mask": 0.95524, "stage1_loss_cls": 0.80868, "stage1_pos_acc": 69.5, "stage1_loss_bbox": 0.2156, "stage1_loss_iou": 0.40154, "stage1_loss_global": 0.46469, "stage1_loss_mask": 0.85144, "stage2_loss_cls": 0.63158, "stage2_pos_acc": 60.75, "stage2_loss_bbox": 0.22414, "stage2_loss_iou": 0.4052, "stage2_loss_global": 0.43057, "stage2_loss_mask": 0.83078, "stage3_loss_cls": 0.48891, "stage3_pos_acc": 68.75, "stage3_loss_bbox": 0.23116, "stage3_loss_iou": 0.41132, "stage3_loss_global": 0.40788, "stage3_loss_mask": 0.77557, "stage4_loss_cls": 0.43821, "stage4_pos_acc": 80.25, "stage4_loss_bbox": 0.23235, "stage4_loss_iou": 0.41056, "stage4_loss_global": 0.38666, "stage4_loss_mask": 0.81923, "stage5_loss_cls": 0.42392, "stage5_pos_acc": 79.0, "stage5_loss_bbox": 0.23396, "stage5_loss_iou": 0.40931, "stage5_loss_global": 0.38146, "stage5_loss_mask": 0.83028, "loss": 15.54326, "grad_norm": 222.95465, "time": 1.3386}
{"mode": "train", "epoch": 10, "iter": 50, "lr": 1e-05, "memory": 8605, "data_time": 0.21886, "stage0_loss_cls": 0.94969, "stage0_pos_acc": 69.5, "stage0_loss_bbox": 0.33945, "stage0_loss_iou": 0.60505, "stage0_loss_global": 0.43567, "stage0_loss_mask": 0.81841, "stage1_loss_cls": 0.7375, "stage1_pos_acc": 68.5, "stage1_loss_bbox": 0.22042, "stage1_loss_iou": 0.402, "stage1_loss_global": 0.4311, "stage1_loss_mask": 0.78742, "stage2_loss_cls": 0.55983, "stage2_pos_acc": 66.0, "stage2_loss_bbox": 0.22051, "stage2_loss_iou": 0.40505, "stage2_loss_global": 0.36525, "stage2_loss_mask": 0.77226, "stage3_loss_cls": 0.40815, "stage3_pos_acc": 77.5, "stage3_loss_bbox": 0.23486, "stage3_loss_iou": 0.41663, "stage3_loss_global": 0.33595, "stage3_loss_mask": 0.72814, "stage4_loss_cls": 0.39127, "stage4_pos_acc": 81.5, "stage4_loss_bbox": 0.23338, "stage4_loss_iou": 0.4155, "stage4_loss_global": 0.33127, "stage4_loss_mask": 0.77211, "stage5_loss_cls": 0.37911, "stage5_pos_acc": 82.25, "stage5_loss_bbox": 0.23283, "stage5_loss_iou": 0.41297, "stage5_loss_global": 0.33439, "stage5_loss_mask": 0.76252, "loss": 14.43869, "grad_norm": 204.69693, "time": 1.32374}
{"mode": "train", "epoch": 11, "iter": 50, "lr": 1e-05, "memory": 8605, "data_time": 0.21672, "stage0_loss_cls": 0.8694, "stage0_pos_acc": 75.5, "stage0_loss_bbox": 0.33839, "stage0_loss_iou": 0.60932, "stage0_loss_global": 0.34387, "stage0_loss_mask": 0.76883, "stage1_loss_cls": 0.6801, "stage1_pos_acc": 80.75, "stage1_loss_bbox": 0.21793, "stage1_loss_iou": 0.40027, "stage1_loss_global": 0.32012, "stage1_loss_mask": 0.68853, "stage2_loss_cls": 0.47232, "stage2_pos_acc": 84.0, "stage2_loss_bbox": 0.22571, "stage2_loss_iou": 0.40964, "stage2_loss_global": 0.24089, "stage2_loss_mask": 0.69405, "stage3_loss_cls": 0.36579, "stage3_pos_acc": 87.5, "stage3_loss_bbox": 0.22545, "stage3_loss_iou": 0.40918, "stage3_loss_global": 0.21853, "stage3_loss_mask": 0.65259, "stage4_loss_cls": 0.3283, "stage4_pos_acc": 89.5, "stage4_loss_bbox": 0.22358, "stage4_loss_iou": 0.40376, "stage4_loss_global": 0.2189, "stage4_loss_mask": 0.69329, "stage5_loss_cls": 0.31218, "stage5_pos_acc": 89.25, "stage5_loss_bbox": 0.22563, "stage5_loss_iou": 0.4029, "stage5_loss_global": 0.2136, "stage5_loss_mask": 0.68299, "loss": 12.85604, "grad_norm": 294.81244, "time": 1.31986}
{"mode": "train", "epoch": 12, "iter": 50, "lr": 2e-05, "memory": 8605, "data_time": 0.21643, "stage0_loss_cls": 0.77593, "stage0_pos_acc": 77.75, "stage0_loss_bbox": 0.34957, "stage0_loss_iou": 0.62414, "stage0_loss_global": 0.28826, "stage0_loss_mask": 0.72795, "stage1_loss_cls": 0.59984, "stage1_pos_acc": 82.25, "stage1_loss_bbox": 0.22029, "stage1_loss_iou": 0.40086, "stage1_loss_global": 0.26908, "stage1_loss_mask": 0.65896, "stage2_loss_cls": 0.4187, "stage2_pos_acc": 88.0, "stage2_loss_bbox": 0.21521, "stage2_loss_iou": 0.38958, "stage2_loss_global": 0.26127, "stage2_loss_mask": 0.65091, "stage3_loss_cls": 0.31593, "stage3_pos_acc": 89.25, "stage3_loss_bbox": 0.2169, "stage3_loss_iou": 0.39223, "stage3_loss_global": 0.25049, "stage3_loss_mask": 0.6217, "stage4_loss_cls": 0.29846, "stage4_pos_acc": 89.75, "stage4_loss_bbox": 0.21366, "stage4_loss_iou": 0.38677, "stage4_loss_global": 0.25094, "stage4_loss_mask": 0.65266, "stage5_loss_cls": 0.28789, "stage5_pos_acc": 89.75, "stage5_loss_bbox": 0.21817, "stage5_loss_iou": 0.38916, "stage5_loss_global": 0.25086, "stage5_loss_mask": 0.63945, "loss": 12.23584, "grad_norm": 245.75347, "time": 1.33004}
{"mode": "train", "epoch": 13, "iter": 50, "lr": 2e-05, "memory": 8605, "data_time": 0.21665, "stage0_loss_cls": 0.78169, "stage0_pos_acc": 83.0, "stage0_loss_bbox": 0.35114, "stage0_loss_iou": 0.61665, "stage0_loss_global": 0.23594, "stage0_loss_mask": 0.73038, "stage1_loss_cls": 0.57627, "stage1_pos_acc": 90.75, "stage1_loss_bbox": 0.22209, "stage1_loss_iou": 0.39731, "stage1_loss_global": 0.21913, "stage1_loss_mask": 0.62461, "stage2_loss_cls": 0.38387, "stage2_pos_acc": 91.0, "stage2_loss_bbox": 0.22168, "stage2_loss_iou": 0.39261, "stage2_loss_global": 0.21105, "stage2_loss_mask": 0.6348, "stage3_loss_cls": 0.2916, "stage3_pos_acc": 92.0, "stage3_loss_bbox": 0.23142, "stage3_loss_iou": 0.40375, "stage3_loss_global": 0.20866, "stage3_loss_mask": 0.61222, "stage4_loss_cls": 0.27378, "stage4_pos_acc": 92.5, "stage4_loss_bbox": 0.23202, "stage4_loss_iou": 0.40461, "stage4_loss_global": 0.2076, "stage4_loss_mask": 0.64022, "stage5_loss_cls": 0.26507, "stage5_pos_acc": 92.5, "stage5_loss_bbox": 0.23027, "stage5_loss_iou": 0.40628, "stage5_loss_global": 0.21261, "stage5_loss_mask": 0.62807, "loss": 11.8474, "grad_norm": 215.70379, "time": 1.31731}
{"mode": "train", "epoch": 14, "iter": 50, "lr": 2e-05, "memory": 8605, "data_time": 0.21739, "stage0_loss_cls": 0.72461, "stage0_pos_acc": 84.0, "stage0_loss_bbox": 0.34412, "stage0_loss_iou": 0.608, "stage0_loss_global": 0.24013, "stage0_loss_mask": 0.66694, "stage1_loss_cls": 0.5505, "stage1_pos_acc": 89.75, "stage1_loss_bbox": 0.23384, "stage1_loss_iou": 0.41322, "stage1_loss_global": 0.23061, "stage1_loss_mask": 0.6202, "stage2_loss_cls": 0.37251, "stage2_pos_acc": 88.0, "stage2_loss_bbox": 0.22643, "stage2_loss_iou": 0.39901, "stage2_loss_global": 0.22745, "stage2_loss_mask": 0.6244, "stage3_loss_cls": 0.28243, "stage3_pos_acc": 88.0, "stage3_loss_bbox": 0.22869, "stage3_loss_iou": 0.39572, "stage3_loss_global": 0.2333, "stage3_loss_mask": 0.60151, "stage4_loss_cls": 0.27832, "stage4_pos_acc": 86.5, "stage4_loss_bbox": 0.23181, "stage4_loss_iou": 0.4003, "stage4_loss_global": 0.23309, "stage4_loss_mask": 0.63746, "stage5_loss_cls": 0.25736, "stage5_pos_acc": 88.75, "stage5_loss_bbox": 0.23081, "stage5_loss_iou": 0.3984, "stage5_loss_global": 0.23662, "stage5_loss_mask": 0.61996, "loss": 11.74775, "grad_norm": 279.35141, "time": 1.32597}
{"mode": "train", "epoch": 15, "iter": 50, "lr": 2e-05, "memory": 8605, "data_time": 0.223, "stage0_loss_cls": 0.75471, "stage0_pos_acc": 85.75, "stage0_loss_bbox": 0.35517, "stage0_loss_iou": 0.62271, "stage0_loss_global": 0.21464, "stage0_loss_mask": 0.65919, "stage1_loss_cls": 0.54403, "stage1_pos_acc": 90.5, "stage1_loss_bbox": 0.22343, "stage1_loss_iou": 0.39714, "stage1_loss_global": 0.21045, "stage1_loss_mask": 0.5728, "stage2_loss_cls": 0.36742, "stage2_pos_acc": 91.0, "stage2_loss_bbox": 0.20831, "stage2_loss_iou": 0.37514, "stage2_loss_global": 0.21347, "stage2_loss_mask": 0.56356, "stage3_loss_cls": 0.28083, "stage3_pos_acc": 91.75, "stage3_loss_bbox": 0.21065, "stage3_loss_iou": 0.37276, "stage3_loss_global": 0.21319, "stage3_loss_mask": 0.5466, "stage4_loss_cls": 0.26336, "stage4_pos_acc": 91.0, "stage4_loss_bbox": 0.21036, "stage4_loss_iou": 0.3713, "stage4_loss_global": 0.21676, "stage4_loss_mask": 0.58408, "stage5_loss_cls": 0.24566, "stage5_pos_acc": 92.0, "stage5_loss_bbox": 0.21118, "stage5_loss_iou": 0.37099, "stage5_loss_global": 0.22178, "stage5_loss_mask": 0.56224, "loss": 11.16391, "grad_norm": 243.70272, "time": 1.31072}
{"mode": "train", "epoch": 16, "iter": 50, "lr": 2e-05, "memory": 8605, "data_time": 0.21942, "stage0_loss_cls": 0.64017, "stage0_pos_acc": 82.5, "stage0_loss_bbox": 0.33857, "stage0_loss_iou": 0.59965, "stage0_loss_global": 0.19462, "stage0_loss_mask": 0.60016, "stage1_loss_cls": 0.4809, "stage1_pos_acc": 86.75, "stage1_loss_bbox": 0.22265, "stage1_loss_iou": 0.39525, "stage1_loss_global": 0.19921, "stage1_loss_mask": 0.54456, "stage2_loss_cls": 0.33478, "stage2_pos_acc": 87.5, "stage2_loss_bbox": 0.22325, "stage2_loss_iou": 0.38911, "stage2_loss_global": 0.19515, "stage2_loss_mask": 0.55071, "stage3_loss_cls": 0.25723, "stage3_pos_acc": 88.5, "stage3_loss_bbox": 0.22087, "stage3_loss_iou": 0.38326, "stage3_loss_global": 0.20348, "stage3_loss_mask": 0.53022, "stage4_loss_cls": 0.26343, "stage4_pos_acc": 89.75, "stage4_loss_bbox": 0.21434, "stage4_loss_iou": 0.37555, "stage4_loss_global": 0.20567, "stage4_loss_mask": 0.55336, "stage5_loss_cls": 0.24499, "stage5_pos_acc": 89.25, "stage5_loss_bbox": 0.21556, "stage5_loss_iou": 0.37719, "stage5_loss_global": 0.20958, "stage5_loss_mask": 0.54533, "loss": 10.70879, "grad_norm": 358.82356, "time": 1.31847}
{"mode": "train", "epoch": 17, "iter": 50, "lr": 2e-05, "memory": 8605, "data_time": 0.21952, "stage0_loss_cls": 0.6531, "stage0_pos_acc": 86.25, "stage0_loss_bbox": 0.34065, "stage0_loss_iou": 0.6052, "stage0_loss_global": 0.211, "stage0_loss_mask": 0.63402, "stage1_loss_cls": 0.49153, "stage1_pos_acc": 90.5, "stage1_loss_bbox": 0.21246, "stage1_loss_iou": 0.38567, "stage1_loss_global": 0.2016, "stage1_loss_mask": 0.54259, "stage2_loss_cls": 0.33207, "stage2_pos_acc": 92.0, "stage2_loss_bbox": 0.21232, "stage2_loss_iou": 0.37978, "stage2_loss_global": 0.20211, "stage2_loss_mask": 0.56988, "stage3_loss_cls": 0.25624, "stage3_pos_acc": 91.0, "stage3_loss_bbox": 0.21634, "stage3_loss_iou": 0.38434, "stage3_loss_global": 0.20585, "stage3_loss_mask": 0.54443, "stage4_loss_cls": 0.23415, "stage4_pos_acc": 92.5, "stage4_loss_bbox": 0.21406, "stage4_loss_iou": 0.37924, "stage4_loss_global": 0.19924, "stage4_loss_mask": 0.57208, "stage5_loss_cls": 0.2333, "stage5_pos_acc": 92.0, "stage5_loss_bbox": 0.21348, "stage5_loss_iou": 0.37903, "stage5_loss_global": 0.19953, "stage5_loss_mask": 0.5658, "loss": 10.77108, "grad_norm": 249.66257, "time": 1.34503}
{"mode": "train", "epoch": 18, "iter": 50, "lr": 2e-05, "memory": 8605, "data_time": 0.21495, "stage0_loss_cls": 0.6514, "stage0_pos_acc": 90.5, "stage0_loss_bbox": 0.3499, "stage0_loss_iou": 0.60793, "stage0_loss_global": 0.16267, "stage0_loss_mask": 0.63347, "stage1_loss_cls": 0.49357, "stage1_pos_acc": 93.25, "stage1_loss_bbox": 0.21838, "stage1_loss_iou": 0.38899, "stage1_loss_global": 0.16107, "stage1_loss_mask": 0.54174, "stage2_loss_cls": 0.29885, "stage2_pos_acc": 94.25, "stage2_loss_bbox": 0.21449, "stage2_loss_iou": 0.37995, "stage2_loss_global": 0.15556, "stage2_loss_mask": 0.54395, "stage3_loss_cls": 0.21516, "stage3_pos_acc": 93.0, "stage3_loss_bbox": 0.21614, "stage3_loss_iou": 0.3792, "stage3_loss_global": 0.15, "stage3_loss_mask": 0.54721, "stage4_loss_cls": 0.19335, "stage4_pos_acc": 93.75, "stage4_loss_bbox": 0.21597, "stage4_loss_iou": 0.37872, "stage4_loss_global": 0.14549, "stage4_loss_mask": 0.57208, "stage5_loss_cls": 0.19349, "stage5_pos_acc": 94.25, "stage5_loss_bbox": 0.21247, "stage5_loss_iou": 0.37563, "stage5_loss_global": 0.14865, "stage5_loss_mask": 0.5464, "loss": 10.29186, "grad_norm": 224.0562, "time": 1.34311}
{"mode": "train", "epoch": 19, "iter": 50, "lr": 3e-05, "memory": 8605, "data_time": 0.22364, "stage0_loss_cls": 0.6406, "stage0_pos_acc": 87.75, "stage0_loss_bbox": 0.33069, "stage0_loss_iou": 0.58006, "stage0_loss_global": 0.18068, "stage0_loss_mask": 0.61183, "stage1_loss_cls": 0.53402, "stage1_pos_acc": 91.0, "stage1_loss_bbox": 0.20352, "stage1_loss_iou": 0.36203, "stage1_loss_global": 0.17902, "stage1_loss_mask": 0.53189, "stage2_loss_cls": 0.33516, "stage2_pos_acc": 92.25, "stage2_loss_bbox": 0.20395, "stage2_loss_iou": 0.35958, "stage2_loss_global": 0.1778, "stage2_loss_mask": 0.53777, "stage3_loss_cls": 0.22972, "stage3_pos_acc": 93.25, "stage3_loss_bbox": 0.21423, "stage3_loss_iou": 0.36712, "stage3_loss_global": 0.18043, "stage3_loss_mask": 0.5333, "stage4_loss_cls": 0.21141, "stage4_pos_acc": 94.75, "stage4_loss_bbox": 0.2138, "stage4_loss_iou": 0.36915, "stage4_loss_global": 0.18538, "stage4_loss_mask": 0.53695, "stage5_loss_cls": 0.20923, "stage5_pos_acc": 94.25, "stage5_loss_bbox": 0.21736, "stage5_loss_iou": 0.37251, "stage5_loss_global": 0.18239, "stage5_loss_mask": 0.53818, "loss": 10.32976, "grad_norm": 296.08481, "time": 1.35637}
{"mode": "train", "epoch": 20, "iter": 50, "lr": 3e-05, "memory": 8605, "data_time": 0.2223, "stage0_loss_cls": 0.57282, "stage0_pos_acc": 88.75, "stage0_loss_bbox": 0.32886, "stage0_loss_iou": 0.58402, "stage0_loss_global": 0.15568, "stage0_loss_mask": 0.55061, "stage1_loss_cls": 0.4492, "stage1_pos_acc": 92.75, "stage1_loss_bbox": 0.21994, "stage1_loss_iou": 0.38719, "stage1_loss_global": 0.15758, "stage1_loss_mask": 0.51545, "stage2_loss_cls": 0.27226, "stage2_pos_acc": 93.75, "stage2_loss_bbox": 0.20805, "stage2_loss_iou": 0.37106, "stage2_loss_global": 0.15681, "stage2_loss_mask": 0.51606, "stage3_loss_cls": 0.21086, "stage3_pos_acc": 92.0, "stage3_loss_bbox": 0.20905, "stage3_loss_iou": 0.36897, "stage3_loss_global": 0.15707, "stage3_loss_mask": 0.51445, "stage4_loss_cls": 0.18024, "stage4_pos_acc": 93.5, "stage4_loss_bbox": 0.2122, "stage4_loss_iou": 0.37129, "stage4_loss_global": 0.16211, "stage4_loss_mask": 0.52342, "stage5_loss_cls": 0.18591, "stage5_pos_acc": 93.5, "stage5_loss_bbox": 0.21052, "stage5_loss_iou": 0.37024, "stage5_loss_global": 0.16033, "stage5_loss_mask": 0.51084, "loss": 9.79311, "grad_norm": 406.78382, "time": 1.33064}
{"mode": "train", "epoch": 21, "iter": 50, "lr": 3e-05, "memory": 8605, "data_time": 0.22203, "stage0_loss_cls": 0.62009, "stage0_pos_acc": 88.75, "stage0_loss_bbox": 0.33637, "stage0_loss_iou": 0.60658, "stage0_loss_global": 0.19438, "stage0_loss_mask": 0.56392, "stage1_loss_cls": 0.56456, "stage1_pos_acc": 90.75, "stage1_loss_bbox": 0.20812, "stage1_loss_iou": 0.37781, "stage1_loss_global": 0.19916, "stage1_loss_mask": 0.49804, "stage2_loss_cls": 0.29933, "stage2_pos_acc": 92.25, "stage2_loss_bbox": 0.20236, "stage2_loss_iou": 0.36435, "stage2_loss_global": 0.20031, "stage2_loss_mask": 0.50773, "stage3_loss_cls": 0.23123, "stage3_pos_acc": 90.75, "stage3_loss_bbox": 0.20407, "stage3_loss_iou": 0.36395, "stage3_loss_global": 0.20271, "stage3_loss_mask": 0.49343, "stage4_loss_cls": 0.22724, "stage4_pos_acc": 89.5, "stage4_loss_bbox": 0.20685, "stage4_loss_iou": 0.36683, "stage4_loss_global": 0.20295, "stage4_loss_mask": 0.51486, "stage5_loss_cls": 0.23473, "stage5_pos_acc": 89.75, "stage5_loss_bbox": 0.20017, "stage5_loss_iou": 0.3612, "stage5_loss_global": 0.21096, "stage5_loss_mask": 0.50429, "loss": 10.26858, "grad_norm": 323.82625, "time": 1.32116}
{"mode": "train", "epoch": 22, "iter": 50, "lr": 3e-05, "memory": 8605, "data_time": 0.21848, "stage0_loss_cls": 0.60603, "stage0_pos_acc": 89.0, "stage0_loss_bbox": 0.33815, "stage0_loss_iou": 0.59834, "stage0_loss_global": 0.20426, "stage0_loss_mask": 0.58798, "stage1_loss_cls": 0.51566, "stage1_pos_acc": 92.75, "stage1_loss_bbox": 0.2067, "stage1_loss_iou": 0.3731, "stage1_loss_global": 0.20458, "stage1_loss_mask": 0.53013, "stage2_loss_cls": 0.27838, "stage2_pos_acc": 92.75, "stage2_loss_bbox": 0.21296, "stage2_loss_iou": 0.37627, "stage2_loss_global": 0.20504, "stage2_loss_mask": 0.53647, "stage3_loss_cls": 0.21759, "stage3_pos_acc": 92.25, "stage3_loss_bbox": 0.21062, "stage3_loss_iou": 0.37241, "stage3_loss_global": 0.20898, "stage3_loss_mask": 0.5155, "stage4_loss_cls": 0.191, "stage4_pos_acc": 93.25, "stage4_loss_bbox": 0.21177, "stage4_loss_iou": 0.37152, "stage4_loss_global": 0.2183, "stage4_loss_mask": 0.52966, "stage5_loss_cls": 0.18892, "stage5_pos_acc": 93.0, "stage5_loss_bbox": 0.2073, "stage5_loss_iou": 0.36491, "stage5_loss_global": 0.22226, "stage5_loss_mask": 0.51381, "loss": 10.31863, "grad_norm": 348.84582, "time": 1.32011}
{"mode": "train", "epoch": 23, "iter": 50, "lr": 3e-05, "memory": 8605, "data_time": 0.2169, "stage0_loss_cls": 0.52906, "stage0_pos_acc": 89.75, "stage0_loss_bbox": 0.33323, "stage0_loss_iou": 0.60702, "stage0_loss_global": 0.14225, "stage0_loss_mask": 0.58064, "stage1_loss_cls": 0.42442, "stage1_pos_acc": 93.0, "stage1_loss_bbox": 0.20976, "stage1_loss_iou": 0.38094, "stage1_loss_global": 0.14603, "stage1_loss_mask": 0.49075, "stage2_loss_cls": 0.27449, "stage2_pos_acc": 93.75, "stage2_loss_bbox": 0.203, "stage2_loss_iou": 0.36427, "stage2_loss_global": 0.1401, "stage2_loss_mask": 0.48778, "stage3_loss_cls": 0.20539, "stage3_pos_acc": 94.0, "stage3_loss_bbox": 0.20364, "stage3_loss_iou": 0.36137, "stage3_loss_global": 0.1444, "stage3_loss_mask": 0.50295, "stage4_loss_cls": 0.18697, "stage4_pos_acc": 93.75, "stage4_loss_bbox": 0.20872, "stage4_loss_iou": 0.36793, "stage4_loss_global": 0.14445, "stage4_loss_mask": 0.53466, "stage5_loss_cls": 0.17048, "stage5_pos_acc": 93.75, "stage5_loss_bbox": 0.21255, "stage5_loss_iou": 0.37167, "stage5_loss_global": 0.1413, "stage5_loss_mask": 0.5454, "loss": 9.61562, "grad_norm": 231.49442, "time": 1.33266}
{"mode": "train", "epoch": 24, "iter": 50, "lr": 3e-05, "memory": 8605, "data_time": 0.21805, "stage0_loss_cls": 0.59577, "stage0_pos_acc": 89.0, "stage0_loss_bbox": 0.31624, "stage0_loss_iou": 0.5706, "stage0_loss_global": 0.19038, "stage0_loss_mask": 0.53786, "stage1_loss_cls": 0.45477, "stage1_pos_acc": 89.25, "stage1_loss_bbox": 0.21012, "stage1_loss_iou": 0.37378, "stage1_loss_global": 0.19145, "stage1_loss_mask": 0.50038, "stage2_loss_cls": 0.29348, "stage2_pos_acc": 91.0, "stage2_loss_bbox": 0.20843, "stage2_loss_iou": 0.36918, "stage2_loss_global": 0.19811, "stage2_loss_mask": 0.50628, "stage3_loss_cls": 0.22184, "stage3_pos_acc": 91.0, "stage3_loss_bbox": 0.21248, "stage3_loss_iou": 0.37013, "stage3_loss_global": 0.1989, "stage3_loss_mask": 0.50137, "stage4_loss_cls": 0.19741, "stage4_pos_acc": 91.25, "stage4_loss_bbox": 0.20995, "stage4_loss_iou": 0.3665, "stage4_loss_global": 0.20633, "stage4_loss_mask": 0.51558, "stage5_loss_cls": 0.19373, "stage5_pos_acc": 92.25, "stage5_loss_bbox": 0.20606, "stage5_loss_iou": 0.35975, "stage5_loss_global": 0.21587, "stage5_loss_mask": 0.50639, "loss": 9.99914, "grad_norm": 306.85782, "time": 1.31323}
{"mode": "train", "epoch": 25, "iter": 50, "lr": 3e-05, "memory": 8605, "data_time": 0.22375, "stage0_loss_cls": 0.52395, "stage0_pos_acc": 90.0, "stage0_loss_bbox": 0.3114, "stage0_loss_iou": 0.55821, "stage0_loss_global": 0.17043, "stage0_loss_mask": 0.5282, "stage1_loss_cls": 0.40027, "stage1_pos_acc": 92.5, "stage1_loss_bbox": 0.21406, "stage1_loss_iou": 0.37653, "stage1_loss_global": 0.16562, "stage1_loss_mask": 0.49033, "stage2_loss_cls": 0.22833, "stage2_pos_acc": 92.25, "stage2_loss_bbox": 0.21328, "stage2_loss_iou": 0.37113, "stage2_loss_global": 0.16223, "stage2_loss_mask": 0.49661, "stage3_loss_cls": 0.18463, "stage3_pos_acc": 92.25, "stage3_loss_bbox": 0.21106, "stage3_loss_iou": 0.36888, "stage3_loss_global": 0.16178, "stage3_loss_mask": 0.49218, "stage4_loss_cls": 0.16871, "stage4_pos_acc": 92.0, "stage4_loss_bbox": 0.21144, "stage4_loss_iou": 0.36968, "stage4_loss_global": 0.15951, "stage4_loss_mask": 0.51067, "stage5_loss_cls": 0.16655, "stage5_pos_acc": 92.0, "stage5_loss_bbox": 0.2119, "stage5_loss_iou": 0.37217, "stage5_loss_global": 0.16164, "stage5_loss_mask": 0.50158, "loss": 9.46297, "grad_norm": 307.63581, "time": 1.31716}
{"mode": "train", "epoch": 26, "iter": 50, "lr": 3e-05, "memory": 8605, "data_time": 0.21697, "stage0_loss_cls": 0.53026, "stage0_pos_acc": 86.5, "stage0_loss_bbox": 0.34231, "stage0_loss_iou": 0.60188, "stage0_loss_global": 0.24814, "stage0_loss_mask": 0.54679, "stage1_loss_cls": 0.42807, "stage1_pos_acc": 87.5, "stage1_loss_bbox": 0.22386, "stage1_loss_iou": 0.39147, "stage1_loss_global": 0.26411, "stage1_loss_mask": 0.50908, "stage2_loss_cls": 0.33068, "stage2_pos_acc": 85.25, "stage2_loss_bbox": 0.21401, "stage2_loss_iou": 0.37749, "stage2_loss_global": 0.2615, "stage2_loss_mask": 0.51821, "stage3_loss_cls": 0.2622, "stage3_pos_acc": 85.5, "stage3_loss_bbox": 0.21027, "stage3_loss_iou": 0.36931, "stage3_loss_global": 0.2755, "stage3_loss_mask": 0.49791, "stage4_loss_cls": 0.28, "stage4_pos_acc": 83.5, "stage4_loss_bbox": 0.20858, "stage4_loss_iou": 0.36499, "stage4_loss_global": 0.28602, "stage4_loss_mask": 0.50496, "stage5_loss_cls": 0.26555, "stage5_pos_acc": 84.25, "stage5_loss_bbox": 0.20774, "stage5_loss_iou": 0.36175, "stage5_loss_global": 0.29943, "stage5_loss_mask": 0.5017, "loss": 10.68379, "grad_norm": 359.52984, "time": 1.32561}
{"mode": "train", "epoch": 27, "iter": 50, "lr": 3e-05, "memory": 8605, "data_time": 0.21952, "stage0_loss_cls": 0.39567, "stage0_pos_acc": 88.75, "stage0_loss_bbox": 0.3563, "stage0_loss_iou": 0.62843, "stage0_loss_global": 0.17271, "stage0_loss_mask": 0.53565, "stage1_loss_cls": 0.31557, "stage1_pos_acc": 91.75, "stage1_loss_bbox": 0.20535, "stage1_loss_iou": 0.37192, "stage1_loss_global": 0.17381, "stage1_loss_mask": 0.47951, "stage2_loss_cls": 0.21655, "stage2_pos_acc": 90.5, "stage2_loss_bbox": 0.19537, "stage2_loss_iou": 0.35255, "stage2_loss_global": 0.17352, "stage2_loss_mask": 0.47416, "stage3_loss_cls": 0.16475, "stage3_pos_acc": 91.75, "stage3_loss_bbox": 0.19472, "stage3_loss_iou": 0.34937, "stage3_loss_global": 0.17444, "stage3_loss_mask": 0.4695, "stage4_loss_cls": 0.15054, "stage4_pos_acc": 92.0, "stage4_loss_bbox": 0.1943, "stage4_loss_iou": 0.34753, "stage4_loss_global": 0.17536, "stage4_loss_mask": 0.48699, "stage5_loss_cls": 0.14547, "stage5_pos_acc": 91.25, "stage5_loss_bbox": 0.19348, "stage5_loss_iou": 0.34737, "stage5_loss_global": 0.18272, "stage5_loss_mask": 0.47774, "loss": 9.10136, "grad_norm": 311.60672, "time": 1.33437}
{"mode": "train", "epoch": 28, "iter": 50, "lr": 0.0, "memory": 8605, "data_time": 0.22178, "stage0_loss_cls": 0.3417, "stage0_pos_acc": 94.0, "stage0_loss_bbox": 0.32709, "stage0_loss_iou": 0.58157, "stage0_loss_global": 0.12686, "stage0_loss_mask": 0.51821, "stage1_loss_cls": 0.26097, "stage1_pos_acc": 95.25, "stage1_loss_bbox": 0.20466, "stage1_loss_iou": 0.36519, "stage1_loss_global": 0.12395, "stage1_loss_mask": 0.46919, "stage2_loss_cls": 0.14906, "stage2_pos_acc": 96.5, "stage2_loss_bbox": 0.21155, "stage2_loss_iou": 0.35605, "stage2_loss_global": 0.12089, "stage2_loss_mask": 0.49211, "stage3_loss_cls": 0.10637, "stage3_pos_acc": 96.0, "stage3_loss_bbox": 0.209, "stage3_loss_iou": 0.3524, "stage3_loss_global": 0.12133, "stage3_loss_mask": 0.47303, "stage4_loss_cls": 0.09803, "stage4_pos_acc": 95.75, "stage4_loss_bbox": 0.20975, "stage4_loss_iou": 0.35308, "stage4_loss_global": 0.12194, "stage4_loss_mask": 0.48228, "stage5_loss_cls": 0.0989, "stage5_pos_acc": 96.0, "stage5_loss_bbox": 0.20623, "stage5_loss_iou": 0.34863, "stage5_loss_global": 0.12197, "stage5_loss_mask": 0.47621, "loss": 8.42819, "grad_norm": 125.56071, "time": 1.34237}
{"mode": "train", "epoch": 29, "iter": 50, "lr": 0.0, "memory": 8605, "data_time": 0.21945, "stage0_loss_cls": 0.33548, "stage0_pos_acc": 93.25, "stage0_loss_bbox": 0.33044, "stage0_loss_iou": 0.5858, "stage0_loss_global": 0.12789, "stage0_loss_mask": 0.5134, "stage1_loss_cls": 0.24678, "stage1_pos_acc": 95.5, "stage1_loss_bbox": 0.20241, "stage1_loss_iou": 0.36059, "stage1_loss_global": 0.13308, "stage1_loss_mask": 0.47953, "stage2_loss_cls": 0.15134, "stage2_pos_acc": 95.5, "stage2_loss_bbox": 0.19826, "stage2_loss_iou": 0.3516, "stage2_loss_global": 0.12871, "stage2_loss_mask": 0.48575, "stage3_loss_cls": 0.11238, "stage3_pos_acc": 94.75, "stage3_loss_bbox": 0.19206, "stage3_loss_iou": 0.3411, "stage3_loss_global": 0.13361, "stage3_loss_mask": 0.45887, "stage4_loss_cls": 0.10452, "stage4_pos_acc": 94.75, "stage4_loss_bbox": 0.19145, "stage4_loss_iou": 0.33829, "stage4_loss_global": 0.13113, "stage4_loss_mask": 0.4703, "stage5_loss_cls": 0.10224, "stage5_pos_acc": 94.0, "stage5_loss_bbox": 0.18983, "stage5_loss_iou": 0.33766, "stage5_loss_global": 0.13253, "stage5_loss_mask": 0.46781, "loss": 8.33482, "grad_norm": 203.23059, "time": 1.30408}
{"mode": "train", "epoch": 30, "iter": 50, "lr": 0.0, "memory": 8605, "data_time": 0.21736, "stage0_loss_cls": 0.32953, "stage0_pos_acc": 95.0, "stage0_loss_bbox": 0.30895, "stage0_loss_iou": 0.55438, "stage0_loss_global": 0.1162, "stage0_loss_mask": 0.48584, "stage1_loss_cls": 0.22686, "stage1_pos_acc": 96.0, "stage1_loss_bbox": 0.20288, "stage1_loss_iou": 0.36289, "stage1_loss_global": 0.11516, "stage1_loss_mask": 0.44847, "stage2_loss_cls": 0.13426, "stage2_pos_acc": 96.0, "stage2_loss_bbox": 0.19968, "stage2_loss_iou": 0.34875, "stage2_loss_global": 0.11275, "stage2_loss_mask": 0.45711, "stage3_loss_cls": 0.10187, "stage3_pos_acc": 95.25, "stage3_loss_bbox": 0.19771, "stage3_loss_iou": 0.34276, "stage3_loss_global": 0.11293, "stage3_loss_mask": 0.43976, "stage4_loss_cls": 0.09019, "stage4_pos_acc": 96.0, "stage4_loss_bbox": 0.19723, "stage4_loss_iou": 0.34087, "stage4_loss_global": 0.11198, "stage4_loss_mask": 0.46459, "stage5_loss_cls": 0.09023, "stage5_pos_acc": 96.0, "stage5_loss_bbox": 0.1974, "stage5_loss_iou": 0.3408, "stage5_loss_global": 0.11313, "stage5_loss_mask": 0.46027, "loss": 8.00543, "grad_norm": 153.38488, "time": 1.31362}
{"mode": "train", "epoch": 31, "iter": 50, "lr": 0.0, "memory": 8605, "data_time": 0.22089, "stage0_loss_cls": 0.34646, "stage0_pos_acc": 95.0, "stage0_loss_bbox": 0.30612, "stage0_loss_iou": 0.55199, "stage0_loss_global": 0.11933, "stage0_loss_mask": 0.48985, "stage1_loss_cls": 0.24645, "stage1_pos_acc": 95.25, "stage1_loss_bbox": 0.19502, "stage1_loss_iou": 0.35292, "stage1_loss_global": 0.1218, "stage1_loss_mask": 0.46356, "stage2_loss_cls": 0.1562, "stage2_pos_acc": 95.5, "stage2_loss_bbox": 0.18711, "stage2_loss_iou": 0.33486, "stage2_loss_global": 0.12013, "stage2_loss_mask": 0.46301, "stage3_loss_cls": 0.11803, "stage3_pos_acc": 95.5, "stage3_loss_bbox": 0.18261, "stage3_loss_iou": 0.32564, "stage3_loss_global": 0.12018, "stage3_loss_mask": 0.44772, "stage4_loss_cls": 0.10179, "stage4_pos_acc": 96.0, "stage4_loss_bbox": 0.18412, "stage4_loss_iou": 0.32761, "stage4_loss_global": 0.11906, "stage4_loss_mask": 0.46659, "stage5_loss_cls": 0.09693, "stage5_pos_acc": 96.5, "stage5_loss_bbox": 0.18375, "stage5_loss_iou": 0.32777, "stage5_loss_global": 0.11877, "stage5_loss_mask": 0.46256, "loss": 8.03792, "grad_norm": 496.54471, "time": 1.3133}
{"mode": "train", "epoch": 32, "iter": 50, "lr": 0.0, "memory": 8605, "data_time": 0.22109, "stage0_loss_cls": 0.32961, "stage0_pos_acc": 94.5, "stage0_loss_bbox": 0.30287, "stage0_loss_iou": 0.55095, "stage0_loss_global": 0.13782, "stage0_loss_mask": 0.47972, "stage1_loss_cls": 0.23155, "stage1_pos_acc": 94.75, "stage1_loss_bbox": 0.1995, "stage1_loss_iou": 0.35882, "stage1_loss_global": 0.14129, "stage1_loss_mask": 0.48953, "stage2_loss_cls": 0.1428, "stage2_pos_acc": 95.25, "stage2_loss_bbox": 0.18874, "stage2_loss_iou": 0.33992, "stage2_loss_global": 0.1368, "stage2_loss_mask": 0.47705, "stage3_loss_cls": 0.09704, "stage3_pos_acc": 95.75, "stage3_loss_bbox": 0.18946, "stage3_loss_iou": 0.3396, "stage3_loss_global": 0.13938, "stage3_loss_mask": 0.46188, "stage4_loss_cls": 0.07834, "stage4_pos_acc": 96.75, "stage4_loss_bbox": 0.19003, "stage4_loss_iou": 0.33905, "stage4_loss_global": 0.13611, "stage4_loss_mask": 0.49448, "stage5_loss_cls": 0.08443, "stage5_pos_acc": 96.25, "stage5_loss_bbox": 0.1868, "stage5_loss_iou": 0.33522, "stage5_loss_global": 0.13485, "stage5_loss_mask": 0.47139, "loss": 8.18502, "grad_norm": 170.9254, "time": 1.35}
{"mode": "train", "epoch": 33, "iter": 50, "lr": 0.0, "memory": 8605, "data_time": 0.2218, "stage0_loss_cls": 0.34074, "stage0_pos_acc": 96.5, "stage0_loss_bbox": 0.28284, "stage0_loss_iou": 0.51449, "stage0_loss_global": 0.11852, "stage0_loss_mask": 0.48848, "stage1_loss_cls": 0.22506, "stage1_pos_acc": 96.0, "stage1_loss_bbox": 0.18857, "stage1_loss_iou": 0.34217, "stage1_loss_global": 0.11823, "stage1_loss_mask": 0.46526, "stage2_loss_cls": 0.12806, "stage2_pos_acc": 96.5, "stage2_loss_bbox": 0.18396, "stage2_loss_iou": 0.3319, "stage2_loss_global": 0.11118, "stage2_loss_mask": 0.46304, "stage3_loss_cls": 0.08549, "stage3_pos_acc": 97.25, "stage3_loss_bbox": 0.17819, "stage3_loss_iou": 0.32216, "stage3_loss_global": 0.11117, "stage3_loss_mask": 0.45478, "stage4_loss_cls": 0.0737, "stage4_pos_acc": 97.0, "stage4_loss_bbox": 0.17594, "stage4_loss_iou": 0.31749, "stage4_loss_global": 0.10593, "stage4_loss_mask": 0.46424, "stage5_loss_cls": 0.07308, "stage5_pos_acc": 96.75, "stage5_loss_bbox": 0.17571, "stage5_loss_iou": 0.31672, "stage5_loss_global": 0.10432, "stage5_loss_mask": 0.4571, "loss": 7.71855, "grad_norm": 203.59643, "time": 1.31906}
{"mode": "train", "epoch": 34, "iter": 50, "lr": 0.0, "memory": 8605, "data_time": 0.22064, "stage0_loss_cls": 0.30909, "stage0_pos_acc": 95.5, "stage0_loss_bbox": 0.29464, "stage0_loss_iou": 0.53036, "stage0_loss_global": 0.10966, "stage0_loss_mask": 0.51409, "stage1_loss_cls": 0.20988, "stage1_pos_acc": 96.5, "stage1_loss_bbox": 0.19634, "stage1_loss_iou": 0.35777, "stage1_loss_global": 0.1096, "stage1_loss_mask": 0.45872, "stage2_loss_cls": 0.137, "stage2_pos_acc": 96.0, "stage2_loss_bbox": 0.18819, "stage2_loss_iou": 0.34153, "stage2_loss_global": 0.107, "stage2_loss_mask": 0.45928, "stage3_loss_cls": 0.08407, "stage3_pos_acc": 96.5, "stage3_loss_bbox": 0.18716, "stage3_loss_iou": 0.33715, "stage3_loss_global": 0.11007, "stage3_loss_mask": 0.44611, "stage4_loss_cls": 0.07812, "stage4_pos_acc": 97.0, "stage4_loss_bbox": 0.18623, "stage4_loss_iou": 0.3358, "stage4_loss_global": 0.10653, "stage4_loss_mask": 0.45365, "stage5_loss_cls": 0.07647, "stage5_pos_acc": 96.75, "stage5_loss_bbox": 0.18404, "stage5_loss_iou": 0.33172, "stage5_loss_global": 0.10682, "stage5_loss_mask": 0.45083, "loss": 7.79793, "grad_norm": 148.12671, "time": 1.33153}
{"mode": "train", "epoch": 35, "iter": 50, "lr": 0.0, "memory": 8605, "data_time": 0.21886, "stage0_loss_cls": 0.33389, "stage0_pos_acc": 94.75, "stage0_loss_bbox": 0.28966, "stage0_loss_iou": 0.52922, "stage0_loss_global": 0.1268, "stage0_loss_mask": 0.49405, "stage1_loss_cls": 0.23419, "stage1_pos_acc": 95.25, "stage1_loss_bbox": 0.18874, "stage1_loss_iou": 0.34679, "stage1_loss_global": 0.12979, "stage1_loss_mask": 0.46155, "stage2_loss_cls": 0.13616, "stage2_pos_acc": 95.5, "stage2_loss_bbox": 0.1792, "stage2_loss_iou": 0.32732, "stage2_loss_global": 0.12397, "stage2_loss_mask": 0.4546, "stage3_loss_cls": 0.08657, "stage3_pos_acc": 96.0, "stage3_loss_bbox": 0.18256, "stage3_loss_iou": 0.32918, "stage3_loss_global": 0.1249, "stage3_loss_mask": 0.45217, "stage4_loss_cls": 0.07783, "stage4_pos_acc": 96.0, "stage4_loss_bbox": 0.18014, "stage4_loss_iou": 0.32564, "stage4_loss_global": 0.12127, "stage4_loss_mask": 0.46483, "stage5_loss_cls": 0.07533, "stage5_pos_acc": 96.0, "stage5_loss_bbox": 0.17981, "stage5_loss_iou": 0.32362, "stage5_loss_global": 0.12216, "stage5_loss_mask": 0.46044, "loss": 7.8624, "grad_norm": 203.80408, "time": 1.32346}
{"mode": "train", "epoch": 36, "iter": 50, "lr": 0.0, "memory": 8605, "data_time": 0.21746, "stage0_loss_cls": 0.32727, "stage0_pos_acc": 95.75, "stage0_loss_bbox": 0.28203, "stage0_loss_iou": 0.51351, "stage0_loss_global": 0.11958, "stage0_loss_mask": 0.48973, "stage1_loss_cls": 0.21551, "stage1_pos_acc": 95.75, "stage1_loss_bbox": 0.18825, "stage1_loss_iou": 0.34911, "stage1_loss_global": 0.11686, "stage1_loss_mask": 0.46081, "stage2_loss_cls": 0.12785, "stage2_pos_acc": 96.25, "stage2_loss_bbox": 0.17799, "stage2_loss_iou": 0.32755, "stage2_loss_global": 0.11327, "stage2_loss_mask": 0.45447, "stage3_loss_cls": 0.0789, "stage3_pos_acc": 96.75, "stage3_loss_bbox": 0.17683, "stage3_loss_iou": 0.3248, "stage3_loss_global": 0.1103, "stage3_loss_mask": 0.45265, "stage4_loss_cls": 0.07306, "stage4_pos_acc": 97.0, "stage4_loss_bbox": 0.17334, "stage4_loss_iou": 0.32014, "stage4_loss_global": 0.10819, "stage4_loss_mask": 0.45891, "stage5_loss_cls": 0.07436, "stage5_pos_acc": 96.25, "stage5_loss_bbox": 0.17245, "stage5_loss_iou": 0.31802, "stage5_loss_global": 0.10696, "stage5_loss_mask": 0.45952, "loss": 7.67223, "grad_norm": 133.30201, "time": 1.32322}
