{"env_info": "sys.platform: linux\nPython: 3.8.10 (default, Jun  4 2021, 15:09:15) [GCC 7.5.0]\nCUDA available: True\nGPU 0,1,2,3: NVIDIA TITAN Xp\nCUDA_HOME: /usr/local/cuda\nNVCC: Cuda compilation tools, release 10.2, V10.2.89\nGCC: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609\nPyTorch: 1.7.0\nPyTorch compiling details: PyTorch built with:\n  - GCC 7.3\n  - C++ Version: 201402\n  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 10.2\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75\n  - CuDNN 7.6.5\n  - Magma 2.5.2\n  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n\nTorchVision: 0.8.1\nOpenCV: 4.5.3\nMMCV: 1.3.18\nMMCV Compiler: GCC 7.3\nMMCV CUDA Compiler: 10.2\nMMDetection: 2.12.0+170db93", "config": "dataset_type = 'AnatomyDataset'\ndata_root = '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi'\nsplit = 'split_3'\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\nalbu_train_transforms = [\n    dict(\n        type='OneOf',\n        transforms=[\n            dict(\n                type='Affine',\n                translate_percent=0.0,\n                rotate=90,\n                fit_output=True,\n                p=0.25),\n            dict(\n                type='Affine',\n                translate_percent=0.0,\n                rotate=180,\n                fit_output=True,\n                p=0.25),\n            dict(\n                type='Affine',\n                translate_percent=0.0,\n                rotate=270,\n                fit_output=True,\n                p=0.25)\n        ],\n        p=0.75)\n]\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n    dict(type='LoadAnatomy'),\n    dict(type='RandomFlip', flip_ratio=0.5),\n    dict(\n        type='Albu',\n        transforms=[\n            dict(\n                type='OneOf',\n                transforms=[\n                    dict(\n                        type='Affine',\n                        translate_percent=0.0,\n                        rotate=90,\n                        fit_output=True,\n                        p=0.25),\n                    dict(\n                        type='Affine',\n                        translate_percent=0.0,\n                        rotate=180,\n                        fit_output=True,\n                        p=0.25),\n                    dict(\n                        type='Affine',\n                        translate_percent=0.0,\n                        rotate=270,\n                        fit_output=True,\n                        p=0.25)\n                ],\n                p=0.75)\n        ],\n        bbox_params=dict(\n            type='BboxParams',\n            format='pascal_voc',\n            label_fields=['gt_labels'],\n            min_visibility=0.0,\n            filter_lost_elements=True),\n        keymap=dict(img='image', gt_masks='masks', gt_bboxes='bboxes'),\n        update_pad_shape=False,\n        skip_img_without_anno=True),\n    dict(\n        type='Resize',\n        img_scale=[(1333, 480), (1333, 512), (1333, 544), (1333, 576),\n                   (1333, 608), (1333, 640), (1333, 672), (1333, 704),\n                   (1333, 736), (1333, 768), (1333, 800)],\n        multiscale_mode='value',\n        keep_ratio=True),\n    dict(\n        type='Normalize',\n        mean=[123.675, 116.28, 103.53],\n        std=[58.395, 57.12, 57.375],\n        to_rgb=True),\n    dict(type='Pad', size_divisor=32),\n    dict(type='DefaultFormatBundle'),\n    dict(type='FormatAnatomyBundle'),\n    dict(\n        type='Collect',\n        keys=['img', 'anatomy', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnatomy'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(1333, 800),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='FormatAnatomyBundle'),\n            dict(type='Collect', keys=['img', 'anatomy'])\n        ])\n]\ndata = dict(\n    samples_per_gpu=2,\n    workers_per_gpu=2,\n    train=dict(\n        type='AnatomyDataset',\n        ann_file=\n        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/annotations/train_anno_crop_split_3.json',\n        img_prefix=\n        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/images/',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n            dict(type='LoadAnatomy'),\n            dict(type='RandomFlip', flip_ratio=0.5),\n            dict(\n                type='Albu',\n                transforms=[\n                    dict(\n                        type='OneOf',\n                        transforms=[\n                            dict(\n                                type='Affine',\n                                translate_percent=0.0,\n                                rotate=90,\n                                fit_output=True,\n                                p=0.25),\n                            dict(\n                                type='Affine',\n                                translate_percent=0.0,\n                                rotate=180,\n                                fit_output=True,\n                                p=0.25),\n                            dict(\n                                type='Affine',\n                                translate_percent=0.0,\n                                rotate=270,\n                                fit_output=True,\n                                p=0.25)\n                        ],\n                        p=0.75)\n                ],\n                bbox_params=dict(\n                    type='BboxParams',\n                    format='pascal_voc',\n                    label_fields=['gt_labels'],\n                    min_visibility=0.0,\n                    filter_lost_elements=True),\n                keymap=dict(img='image', gt_masks='masks', gt_bboxes='bboxes'),\n                update_pad_shape=False,\n                skip_img_without_anno=True),\n            dict(\n                type='Resize',\n                img_scale=[(1333, 480), (1333, 512), (1333, 544), (1333, 576),\n                           (1333, 608), (1333, 640), (1333, 672), (1333, 704),\n                           (1333, 736), (1333, 768), (1333, 800)],\n                multiscale_mode='value',\n                keep_ratio=True),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='DefaultFormatBundle'),\n            dict(type='FormatAnatomyBundle'),\n            dict(\n                type='Collect',\n                keys=['img', 'anatomy', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n        ],\n        classes=('lmym', 'GIST')),\n    val=dict(\n        type='AnatomyDataset',\n        ann_file=\n        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/annotations/val_anno_crop_split_3.json',\n        img_prefix=\n        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/images/',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnatomy'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(1333, 800),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='Pad', size_divisor=32),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='FormatAnatomyBundle'),\n                    dict(type='Collect', keys=['img', 'anatomy'])\n                ])\n        ],\n        classes=('lmym', 'GIST')),\n    test=dict(\n        type='AnatomyDataset',\n        ann_file=\n        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/annotations/val_anno_crop_split_3.json',\n        img_prefix=\n        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/images/',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnatomy'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(1333, 800),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='Pad', size_divisor=32),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='FormatAnatomyBundle'),\n                    dict(type='Collect', keys=['img', 'anatomy'])\n                ])\n        ],\n        classes=('lmym', 'GIST')))\nevaluation = dict(metric=['bbox', 'segm', 'glob'])\noptimizer = dict(type='AdamW', lr=2.5e-05, weight_decay=0.0001)\noptimizer_config = dict(grad_clip=dict(max_norm=1, norm_type=2))\nlr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=1000,\n    warmup_ratio=0.001,\n    step=[27, 33])\nrunner = dict(type='EpochBasedRunner', max_epochs=36)\ncheckpoint_config = dict(interval=1)\nlog_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\ncustom_hooks = [dict(type='NumClassCheckHook')]\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = 'work_dirs/pretrained/queryInst/queryinst_r101_300_queries-860dc5d5.pth'\nresume_from = None\nworkflow = [('train', 1)]\nnum_stages = 6\nnum_proposals = 300\nmodel = dict(\n    type='QueryGlob',\n    pretrained='torchvision://resnet101',\n    backbone=dict(\n        type='ResNet',\n        depth=101,\n        num_stages=4,\n        out_indices=(0, 1, 2, 3),\n        frozen_stages=1,\n        norm_cfg=dict(type='BN', requires_grad=True),\n        norm_eval=True,\n        style='pytorch'),\n    neck=dict(\n        type='FPN',\n        in_channels=[256, 512, 1024, 2048],\n        out_channels=256,\n        start_level=0,\n        add_extra_convs='on_input',\n        num_outs=4),\n    rpn_head=dict(\n        type='GlobalEmbeddingRPNHead',\n        num_proposals=300,\n        dim_global=7,\n        proposal_feature_channel=256),\n    roi_head=dict(\n        type='QueryGlobRoIHead',\n        num_stages=6,\n        stage_loss_weights=[1, 1, 1, 1, 1, 1],\n        proposal_feature_channel=256,\n        bbox_roi_extractor=dict(\n            type='SingleRoIExtractor',\n            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=2),\n            out_channels=256,\n            featmap_strides=[4, 8, 16, 32]),\n        mask_roi_extractor=dict(\n            type='SingleRoIExtractor',\n            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=2),\n            out_channels=256,\n            featmap_strides=[4, 8, 16, 32]),\n        bbox_head=[\n            dict(\n                type='GlobDIIHead',\n                num_classes=2,\n                num_ffn_fcs=2,\n                num_heads=8,\n                num_cls_fcs=2,\n                num_glb_fcs=2,\n                num_reg_fcs=3,\n                feedforward_channels=2048,\n                in_channels=256,\n                dropout=0.0,\n                ffn_act_cfg=dict(type='ReLU', inplace=True),\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=7,\n                    with_proj=True,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n                loss_cls=dict(\n                    type='FocalLoss',\n                    use_sigmoid=True,\n                    gamma=2.0,\n                    alpha=0.25,\n                    loss_weight=2.0),\n                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    clip_border=False,\n                    target_means=[0.0, 0.0, 0.0, 0.0],\n                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n            dict(\n                type='GlobDIIHead',\n                num_classes=2,\n                num_ffn_fcs=2,\n                num_heads=8,\n                num_cls_fcs=2,\n                num_glb_fcs=2,\n                num_reg_fcs=3,\n                feedforward_channels=2048,\n                in_channels=256,\n                dropout=0.0,\n                ffn_act_cfg=dict(type='ReLU', inplace=True),\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=7,\n                    with_proj=True,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n                loss_cls=dict(\n                    type='FocalLoss',\n                    use_sigmoid=True,\n                    gamma=2.0,\n                    alpha=0.25,\n                    loss_weight=2.0),\n                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    clip_border=False,\n                    target_means=[0.0, 0.0, 0.0, 0.0],\n                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n            dict(\n                type='GlobDIIHead',\n                num_classes=2,\n                num_ffn_fcs=2,\n                num_heads=8,\n                num_cls_fcs=2,\n                num_glb_fcs=2,\n                num_reg_fcs=3,\n                feedforward_channels=2048,\n                in_channels=256,\n                dropout=0.0,\n                ffn_act_cfg=dict(type='ReLU', inplace=True),\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=7,\n                    with_proj=True,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n                loss_cls=dict(\n                    type='FocalLoss',\n                    use_sigmoid=True,\n                    gamma=2.0,\n                    alpha=0.25,\n                    loss_weight=2.0),\n                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    clip_border=False,\n                    target_means=[0.0, 0.0, 0.0, 0.0],\n                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n            dict(\n                type='GlobDIIHead',\n                num_classes=2,\n                num_ffn_fcs=2,\n                num_heads=8,\n                num_cls_fcs=2,\n                num_glb_fcs=2,\n                num_reg_fcs=3,\n                feedforward_channels=2048,\n                in_channels=256,\n                dropout=0.0,\n                ffn_act_cfg=dict(type='ReLU', inplace=True),\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=7,\n                    with_proj=True,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n                loss_cls=dict(\n                    type='FocalLoss',\n                    use_sigmoid=True,\n                    gamma=2.0,\n                    alpha=0.25,\n                    loss_weight=2.0),\n                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    clip_border=False,\n                    target_means=[0.0, 0.0, 0.0, 0.0],\n                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n            dict(\n                type='GlobDIIHead',\n                num_classes=2,\n                num_ffn_fcs=2,\n                num_heads=8,\n                num_cls_fcs=2,\n                num_glb_fcs=2,\n                num_reg_fcs=3,\n                feedforward_channels=2048,\n                in_channels=256,\n                dropout=0.0,\n                ffn_act_cfg=dict(type='ReLU', inplace=True),\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=7,\n                    with_proj=True,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n                loss_cls=dict(\n                    type='FocalLoss',\n                    use_sigmoid=True,\n                    gamma=2.0,\n                    alpha=0.25,\n                    loss_weight=2.0),\n                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    clip_border=False,\n                    target_means=[0.0, 0.0, 0.0, 0.0],\n                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n            dict(\n                type='GlobDIIHead',\n                num_classes=2,\n                num_ffn_fcs=2,\n                num_heads=8,\n                num_cls_fcs=2,\n                num_glb_fcs=2,\n                num_reg_fcs=3,\n                feedforward_channels=2048,\n                in_channels=256,\n                dropout=0.0,\n                ffn_act_cfg=dict(type='ReLU', inplace=True),\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=7,\n                    with_proj=True,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n                loss_cls=dict(\n                    type='FocalLoss',\n                    use_sigmoid=True,\n                    gamma=2.0,\n                    alpha=0.25,\n                    loss_weight=2.0),\n                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    clip_border=False,\n                    target_means=[0.0, 0.0, 0.0, 0.0],\n                    target_stds=[0.5, 0.5, 1.0, 1.0]))\n        ],\n        mask_head=[\n            dict(\n                type='DynamicMaskHead',\n                num_classes=2,\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=14,\n                    with_proj=False,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                dropout=0.0,\n                num_convs=4,\n                roi_feat_size=14,\n                in_channels=256,\n                conv_kernel_size=3,\n                conv_out_channels=256,\n                class_agnostic=False,\n                norm_cfg=dict(type='BN'),\n                upsample_cfg=dict(type='deconv', scale_factor=2),\n                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n            dict(\n                type='DynamicMaskHead',\n                num_classes=2,\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=14,\n                    with_proj=False,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                dropout=0.0,\n                num_convs=4,\n                roi_feat_size=14,\n                in_channels=256,\n                conv_kernel_size=3,\n                conv_out_channels=256,\n                class_agnostic=False,\n                norm_cfg=dict(type='BN'),\n                upsample_cfg=dict(type='deconv', scale_factor=2),\n                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n            dict(\n                type='DynamicMaskHead',\n                num_classes=2,\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=14,\n                    with_proj=False,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                dropout=0.0,\n                num_convs=4,\n                roi_feat_size=14,\n                in_channels=256,\n                conv_kernel_size=3,\n                conv_out_channels=256,\n                class_agnostic=False,\n                norm_cfg=dict(type='BN'),\n                upsample_cfg=dict(type='deconv', scale_factor=2),\n                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n            dict(\n                type='DynamicMaskHead',\n                num_classes=2,\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=14,\n                    with_proj=False,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                dropout=0.0,\n                num_convs=4,\n                roi_feat_size=14,\n                in_channels=256,\n                conv_kernel_size=3,\n                conv_out_channels=256,\n                class_agnostic=False,\n                norm_cfg=dict(type='BN'),\n                upsample_cfg=dict(type='deconv', scale_factor=2),\n                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n            dict(\n                type='DynamicMaskHead',\n                num_classes=2,\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=14,\n                    with_proj=False,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                dropout=0.0,\n                num_convs=4,\n                roi_feat_size=14,\n                in_channels=256,\n                conv_kernel_size=3,\n                conv_out_channels=256,\n                class_agnostic=False,\n                norm_cfg=dict(type='BN'),\n                upsample_cfg=dict(type='deconv', scale_factor=2),\n                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n            dict(\n                type='DynamicMaskHead',\n                num_classes=2,\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=14,\n                    with_proj=False,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                dropout=0.0,\n                num_convs=4,\n                roi_feat_size=14,\n                in_channels=256,\n                conv_kernel_size=3,\n                conv_out_channels=256,\n                class_agnostic=False,\n                norm_cfg=dict(type='BN'),\n                upsample_cfg=dict(type='deconv', scale_factor=2),\n                loss_dice=dict(type='DiceLoss', loss_weight=8.0))\n        ]),\n    train_cfg=dict(\n        rpn=None,\n        rcnn=[\n            dict(\n                assigner=dict(\n                    type='HungarianAssigner',\n                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n                                  weight=2.0)),\n                sampler=dict(type='PseudoSampler'),\n                pos_weight=1,\n                mask_size=28,\n                debug=False),\n            dict(\n                assigner=dict(\n                    type='HungarianAssigner',\n                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n                                  weight=2.0)),\n                sampler=dict(type='PseudoSampler'),\n                pos_weight=1,\n                mask_size=28,\n                debug=False),\n            dict(\n                assigner=dict(\n                    type='HungarianAssigner',\n                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n                                  weight=2.0)),\n                sampler=dict(type='PseudoSampler'),\n                pos_weight=1,\n                mask_size=28,\n                debug=False),\n            dict(\n                assigner=dict(\n                    type='HungarianAssigner',\n                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n                                  weight=2.0)),\n                sampler=dict(type='PseudoSampler'),\n                pos_weight=1,\n                mask_size=28,\n                debug=False),\n            dict(\n                assigner=dict(\n                    type='HungarianAssigner',\n                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n                                  weight=2.0)),\n                sampler=dict(type='PseudoSampler'),\n                pos_weight=1,\n                mask_size=28,\n                debug=False),\n            dict(\n                assigner=dict(\n                    type='HungarianAssigner',\n                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n                                  weight=2.0)),\n                sampler=dict(type='PseudoSampler'),\n                pos_weight=1,\n                mask_size=28,\n                debug=False)\n        ]),\n    test_cfg=dict(\n        rpn=None,\n        rcnn=dict(\n            max_per_img=300,\n            mask_thr_binary=0.5,\n            nms=dict(type='nms', iou_threshold=0.7))))\ntotal_epochs = 36\nmin_values = (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)\nclasses = ('lmym', 'GIST')\ngpu_ids = range(0, 4)\nwork_dir = './work_dirs/queryglob_usdanno514roi_B_2_7_split3'\n", "seed": null, "exp_name": "queryglob_usdanno514roi_B_2_7_split3.py"}
{"mode": "train", "epoch": 1, "iter": 50, "lr": 0.0, "memory": 8081, "data_time": 0.21999, "stage0_loss_cls": 1.83782, "stage0_pos_acc": 53.5, "stage0_loss_bbox": 0.66261, "stage0_loss_iou": 1.01785, "stage0_loss_global": 0.97042, "stage0_loss_mask": 3.19956, "stage1_loss_cls": 2.87853, "stage1_pos_acc": 58.5, "stage1_loss_bbox": 0.54641, "stage1_loss_iou": 0.89504, "stage1_loss_global": 0.61882, "stage1_loss_mask": 2.74636, "stage2_loss_cls": 2.09668, "stage2_pos_acc": 56.25, "stage2_loss_bbox": 0.56561, "stage2_loss_iou": 0.90021, "stage2_loss_global": 1.6182, "stage2_loss_mask": 2.33458, "stage3_loss_cls": 2.43943, "stage3_pos_acc": 55.0, "stage3_loss_bbox": 0.56839, "stage3_loss_iou": 0.90545, "stage3_loss_global": 0.54773, "stage3_loss_mask": 2.84659, "stage4_loss_cls": 2.37335, "stage4_pos_acc": 48.75, "stage4_loss_bbox": 0.57667, "stage4_loss_iou": 0.8941, "stage4_loss_global": 0.67438, "stage4_loss_mask": 2.55079, "stage5_loss_cls": 2.36496, "stage5_pos_acc": 48.75, "stage5_loss_bbox": 0.5842, "stage5_loss_iou": 0.90603, "stage5_loss_global": 0.77503, "stage5_loss_mask": 3.0241, "loss": 44.91988, "grad_norm": 221.31905, "time": 1.35285}
{"mode": "train", "epoch": 2, "iter": 50, "lr": 0.0, "memory": 8501, "data_time": 0.21739, "stage0_loss_cls": 1.65179, "stage0_pos_acc": 53.75, "stage0_loss_bbox": 0.59213, "stage0_loss_iou": 0.92792, "stage0_loss_global": 0.79551, "stage0_loss_mask": 3.02986, "stage1_loss_cls": 2.6311, "stage1_pos_acc": 53.0, "stage1_loss_bbox": 0.41702, "stage1_loss_iou": 0.70899, "stage1_loss_global": 0.54846, "stage1_loss_mask": 2.51405, "stage2_loss_cls": 1.79384, "stage2_pos_acc": 56.25, "stage2_loss_bbox": 0.39499, "stage2_loss_iou": 0.66646, "stage2_loss_global": 0.91025, "stage2_loss_mask": 1.95147, "stage3_loss_cls": 2.23868, "stage3_pos_acc": 54.5, "stage3_loss_bbox": 0.39965, "stage3_loss_iou": 0.66211, "stage3_loss_global": 0.53117, "stage3_loss_mask": 2.38235, "stage4_loss_cls": 2.01865, "stage4_pos_acc": 48.25, "stage4_loss_bbox": 0.38269, "stage4_loss_iou": 0.63341, "stage4_loss_global": 0.54539, "stage4_loss_mask": 2.04732, "stage5_loss_cls": 2.08571, "stage5_pos_acc": 48.75, "stage5_loss_bbox": 0.38076, "stage5_loss_iou": 0.64006, "stage5_loss_global": 0.61811, "stage5_loss_mask": 2.51747, "loss": 37.61735, "grad_norm": 193.31938, "time": 1.32333}
{"mode": "train", "epoch": 3, "iter": 50, "lr": 0.0, "memory": 8501, "data_time": 0.21824, "stage0_loss_cls": 1.45269, "stage0_pos_acc": 54.75, "stage0_loss_bbox": 0.50958, "stage0_loss_iou": 0.85387, "stage0_loss_global": 0.54599, "stage0_loss_mask": 2.59321, "stage1_loss_cls": 2.09232, "stage1_pos_acc": 58.5, "stage1_loss_bbox": 0.35017, "stage1_loss_iou": 0.61967, "stage1_loss_global": 0.50067, "stage1_loss_mask": 2.18204, "stage2_loss_cls": 1.49645, "stage2_pos_acc": 54.0, "stage2_loss_bbox": 0.32123, "stage2_loss_iou": 0.57305, "stage2_loss_global": 0.53819, "stage2_loss_mask": 1.6895, "stage3_loss_cls": 1.80646, "stage3_pos_acc": 57.75, "stage3_loss_bbox": 0.32309, "stage3_loss_iou": 0.56581, "stage3_loss_global": 0.50342, "stage3_loss_mask": 2.01825, "stage4_loss_cls": 1.50706, "stage4_pos_acc": 51.25, "stage4_loss_bbox": 0.3149, "stage4_loss_iou": 0.55421, "stage4_loss_global": 0.50381, "stage4_loss_mask": 1.69512, "stage5_loss_cls": 1.60234, "stage5_pos_acc": 52.75, "stage5_loss_bbox": 0.31923, "stage5_loss_iou": 0.56051, "stage5_loss_global": 0.53493, "stage5_loss_mask": 2.09797, "loss": 31.22576, "grad_norm": 173.78745, "time": 1.32779}
{"mode": "train", "epoch": 4, "iter": 50, "lr": 1e-05, "memory": 8501, "data_time": 0.21409, "stage0_loss_cls": 1.33141, "stage0_pos_acc": 57.75, "stage0_loss_bbox": 0.47672, "stage0_loss_iou": 0.80946, "stage0_loss_global": 0.47792, "stage0_loss_mask": 2.18053, "stage1_loss_cls": 1.50193, "stage1_pos_acc": 62.0, "stage1_loss_bbox": 0.304, "stage1_loss_iou": 0.54672, "stage1_loss_global": 0.46623, "stage1_loss_mask": 1.86465, "stage2_loss_cls": 1.29478, "stage2_pos_acc": 57.75, "stage2_loss_bbox": 0.27678, "stage2_loss_iou": 0.49952, "stage2_loss_global": 0.47301, "stage2_loss_mask": 1.46909, "stage3_loss_cls": 1.40009, "stage3_pos_acc": 58.25, "stage3_loss_bbox": 0.27347, "stage3_loss_iou": 0.49212, "stage3_loss_global": 0.47562, "stage3_loss_mask": 1.64943, "stage4_loss_cls": 1.24554, "stage4_pos_acc": 62.75, "stage4_loss_bbox": 0.26274, "stage4_loss_iou": 0.46877, "stage4_loss_global": 0.47021, "stage4_loss_mask": 1.44624, "stage5_loss_cls": 1.1954, "stage5_pos_acc": 72.25, "stage5_loss_bbox": 0.26649, "stage5_loss_iou": 0.47436, "stage5_loss_global": 0.4778, "stage5_loss_mask": 1.80574, "loss": 26.37679, "grad_norm": 159.23933, "time": 1.31939}
{"mode": "train", "epoch": 5, "iter": 50, "lr": 1e-05, "memory": 8501, "data_time": 0.2192, "stage0_loss_cls": 1.24691, "stage0_pos_acc": 62.25, "stage0_loss_bbox": 0.43611, "stage0_loss_iou": 0.73825, "stage0_loss_global": 0.46243, "stage0_loss_mask": 1.76023, "stage1_loss_cls": 1.28654, "stage1_pos_acc": 64.5, "stage1_loss_bbox": 0.26861, "stage1_loss_iou": 0.47671, "stage1_loss_global": 0.46178, "stage1_loss_mask": 1.50141, "stage2_loss_cls": 1.09238, "stage2_pos_acc": 63.5, "stage2_loss_bbox": 0.26334, "stage2_loss_iou": 0.46608, "stage2_loss_global": 0.4557, "stage2_loss_mask": 1.22662, "stage3_loss_cls": 1.15587, "stage3_pos_acc": 54.5, "stage3_loss_bbox": 0.25255, "stage3_loss_iou": 0.44083, "stage3_loss_global": 0.46582, "stage3_loss_mask": 1.30004, "stage4_loss_cls": 1.05058, "stage4_pos_acc": 59.0, "stage4_loss_bbox": 0.24395, "stage4_loss_iou": 0.42652, "stage4_loss_global": 0.46366, "stage4_loss_mask": 1.18521, "stage5_loss_cls": 0.95866, "stage5_pos_acc": 87.75, "stage5_loss_bbox": 0.25573, "stage5_loss_iou": 0.442, "stage5_loss_global": 0.45393, "stage5_loss_mask": 1.44537, "loss": 22.68382, "grad_norm": 143.54412, "time": 1.33846}
{"mode": "train", "epoch": 6, "iter": 50, "lr": 1e-05, "memory": 8501, "data_time": 0.21392, "stage0_loss_cls": 1.17014, "stage0_pos_acc": 63.25, "stage0_loss_bbox": 0.39698, "stage0_loss_iou": 0.69825, "stage0_loss_global": 0.44274, "stage0_loss_mask": 1.40709, "stage1_loss_cls": 1.11618, "stage1_pos_acc": 71.0, "stage1_loss_bbox": 0.23649, "stage1_loss_iou": 0.42396, "stage1_loss_global": 0.43705, "stage1_loss_mask": 1.23562, "stage2_loss_cls": 0.89142, "stage2_pos_acc": 60.75, "stage2_loss_bbox": 0.24108, "stage2_loss_iou": 0.43022, "stage2_loss_global": 0.43692, "stage2_loss_mask": 1.07445, "stage3_loss_cls": 0.85702, "stage3_pos_acc": 58.25, "stage3_loss_bbox": 0.24406, "stage3_loss_iou": 0.43258, "stage3_loss_global": 0.43905, "stage3_loss_mask": 1.10006, "stage4_loss_cls": 0.75091, "stage4_pos_acc": 62.75, "stage4_loss_bbox": 0.2492, "stage4_loss_iou": 0.43811, "stage4_loss_global": 0.44094, "stage4_loss_mask": 1.06542, "stage5_loss_cls": 0.77747, "stage5_pos_acc": 90.0, "stage5_loss_bbox": 0.23772, "stage5_loss_iou": 0.42181, "stage5_loss_global": 0.43269, "stage5_loss_mask": 1.19797, "loss": 19.72358, "grad_norm": 154.97936, "time": 1.32044}
{"mode": "train", "epoch": 7, "iter": 50, "lr": 1e-05, "memory": 8586, "data_time": 0.2138, "stage0_loss_cls": 1.12844, "stage0_pos_acc": 61.25, "stage0_loss_bbox": 0.37548, "stage0_loss_iou": 0.65036, "stage0_loss_global": 0.44445, "stage0_loss_mask": 1.21694, "stage1_loss_cls": 0.9655, "stage1_pos_acc": 74.5, "stage1_loss_bbox": 0.23177, "stage1_loss_iou": 0.42312, "stage1_loss_global": 0.43877, "stage1_loss_mask": 1.08514, "stage2_loss_cls": 0.70459, "stage2_pos_acc": 67.0, "stage2_loss_bbox": 0.2482, "stage2_loss_iou": 0.44021, "stage2_loss_global": 0.42176, "stage2_loss_mask": 0.97906, "stage3_loss_cls": 0.71708, "stage3_pos_acc": 64.5, "stage3_loss_bbox": 0.23993, "stage3_loss_iou": 0.42201, "stage3_loss_global": 0.41087, "stage3_loss_mask": 0.99152, "stage4_loss_cls": 0.61119, "stage4_pos_acc": 66.75, "stage4_loss_bbox": 0.25648, "stage4_loss_iou": 0.44809, "stage4_loss_global": 0.41385, "stage4_loss_mask": 0.98058, "stage5_loss_cls": 0.62299, "stage5_pos_acc": 82.5, "stage5_loss_bbox": 0.25097, "stage5_loss_iou": 0.43318, "stage5_loss_global": 0.40329, "stage5_loss_mask": 1.15556, "loss": 18.11139, "grad_norm": 236.31902, "time": 1.32321}
{"mode": "train", "epoch": 8, "iter": 50, "lr": 1e-05, "memory": 8586, "data_time": 0.21595, "stage0_loss_cls": 1.00699, "stage0_pos_acc": 66.25, "stage0_loss_bbox": 0.3479, "stage0_loss_iou": 0.61295, "stage0_loss_global": 0.4335, "stage0_loss_mask": 1.02571, "stage1_loss_cls": 0.87037, "stage1_pos_acc": 77.75, "stage1_loss_bbox": 0.21705, "stage1_loss_iou": 0.39738, "stage1_loss_global": 0.42531, "stage1_loss_mask": 0.91612, "stage2_loss_cls": 0.6118, "stage2_pos_acc": 67.25, "stage2_loss_bbox": 0.24223, "stage2_loss_iou": 0.43601, "stage2_loss_global": 0.40877, "stage2_loss_mask": 0.87161, "stage3_loss_cls": 0.59876, "stage3_pos_acc": 68.5, "stage3_loss_bbox": 0.22893, "stage3_loss_iou": 0.41452, "stage3_loss_global": 0.38422, "stage3_loss_mask": 0.8941, "stage4_loss_cls": 0.53233, "stage4_pos_acc": 73.75, "stage4_loss_bbox": 0.235, "stage4_loss_iou": 0.42719, "stage4_loss_global": 0.37002, "stage4_loss_mask": 0.87467, "stage5_loss_cls": 0.53656, "stage5_pos_acc": 84.75, "stage5_loss_bbox": 0.23312, "stage5_loss_iou": 0.42088, "stage5_loss_global": 0.36098, "stage5_loss_mask": 1.00615, "loss": 16.34114, "grad_norm": 252.63948, "time": 1.34628}
{"mode": "train", "epoch": 9, "iter": 50, "lr": 1e-05, "memory": 8586, "data_time": 0.21326, "stage0_loss_cls": 0.98632, "stage0_pos_acc": 67.75, "stage0_loss_bbox": 0.33989, "stage0_loss_iou": 0.60337, "stage0_loss_global": 0.4399, "stage0_loss_mask": 0.90248, "stage1_loss_cls": 0.7909, "stage1_pos_acc": 76.75, "stage1_loss_bbox": 0.22884, "stage1_loss_iou": 0.41279, "stage1_loss_global": 0.4152, "stage1_loss_mask": 0.86885, "stage2_loss_cls": 0.56024, "stage2_pos_acc": 73.25, "stage2_loss_bbox": 0.24347, "stage2_loss_iou": 0.43302, "stage2_loss_global": 0.35382, "stage2_loss_mask": 0.85605, "stage3_loss_cls": 0.50938, "stage3_pos_acc": 79.0, "stage3_loss_bbox": 0.22564, "stage3_loss_iou": 0.4047, "stage3_loss_global": 0.29149, "stage3_loss_mask": 0.85516, "stage4_loss_cls": 0.4492, "stage4_pos_acc": 83.75, "stage4_loss_bbox": 0.22807, "stage4_loss_iou": 0.40735, "stage4_loss_global": 0.26733, "stage4_loss_mask": 0.86872, "stage5_loss_cls": 0.44333, "stage5_pos_acc": 86.25, "stage5_loss_bbox": 0.22922, "stage5_loss_iou": 0.4061, "stage5_loss_global": 0.26145, "stage5_loss_mask": 0.97192, "loss": 15.25421, "grad_norm": 217.35466, "time": 1.33155}
{"mode": "train", "epoch": 10, "iter": 50, "lr": 1e-05, "memory": 8586, "data_time": 0.21857, "stage0_loss_cls": 0.9047, "stage0_pos_acc": 68.5, "stage0_loss_bbox": 0.34717, "stage0_loss_iou": 0.60556, "stage0_loss_global": 0.4056, "stage0_loss_mask": 0.84946, "stage1_loss_cls": 0.70108, "stage1_pos_acc": 81.5, "stage1_loss_bbox": 0.23516, "stage1_loss_iou": 0.41778, "stage1_loss_global": 0.35776, "stage1_loss_mask": 0.76762, "stage2_loss_cls": 0.45915, "stage2_pos_acc": 84.0, "stage2_loss_bbox": 0.24742, "stage2_loss_iou": 0.43598, "stage2_loss_global": 0.26922, "stage2_loss_mask": 0.79413, "stage3_loss_cls": 0.39679, "stage3_pos_acc": 87.5, "stage3_loss_bbox": 0.24109, "stage3_loss_iou": 0.42126, "stage3_loss_global": 0.23306, "stage3_loss_mask": 0.76438, "stage4_loss_cls": 0.35407, "stage4_pos_acc": 88.0, "stage4_loss_bbox": 0.24419, "stage4_loss_iou": 0.42327, "stage4_loss_global": 0.23814, "stage4_loss_mask": 0.8105, "stage5_loss_cls": 0.35438, "stage5_pos_acc": 89.0, "stage5_loss_bbox": 0.24383, "stage5_loss_iou": 0.42138, "stage5_loss_global": 0.23245, "stage5_loss_mask": 0.83074, "loss": 14.00733, "grad_norm": 225.04546, "time": 1.33013}
{"mode": "train", "epoch": 11, "iter": 50, "lr": 1e-05, "memory": 8586, "data_time": 0.21661, "stage0_loss_cls": 0.87757, "stage0_pos_acc": 75.25, "stage0_loss_bbox": 0.33217, "stage0_loss_iou": 0.60248, "stage0_loss_global": 0.33686, "stage0_loss_mask": 0.77675, "stage1_loss_cls": 0.64468, "stage1_pos_acc": 89.0, "stage1_loss_bbox": 0.23203, "stage1_loss_iou": 0.41767, "stage1_loss_global": 0.25337, "stage1_loss_mask": 0.70898, "stage2_loss_cls": 0.43595, "stage2_pos_acc": 89.25, "stage2_loss_bbox": 0.24216, "stage2_loss_iou": 0.42933, "stage2_loss_global": 0.18083, "stage2_loss_mask": 0.75873, "stage3_loss_cls": 0.36374, "stage3_pos_acc": 89.75, "stage3_loss_bbox": 0.23929, "stage3_loss_iou": 0.42574, "stage3_loss_global": 0.17562, "stage3_loss_mask": 0.74907, "stage4_loss_cls": 0.32612, "stage4_pos_acc": 91.5, "stage4_loss_bbox": 0.24325, "stage4_loss_iou": 0.42397, "stage4_loss_global": 0.17143, "stage4_loss_mask": 0.81445, "stage5_loss_cls": 0.33611, "stage5_pos_acc": 90.5, "stage5_loss_bbox": 0.23773, "stage5_loss_iou": 0.41629, "stage5_loss_global": 0.17439, "stage5_loss_mask": 0.79441, "loss": 13.12118, "grad_norm": 236.54682, "time": 1.31754}
{"mode": "train", "epoch": 12, "iter": 50, "lr": 2e-05, "memory": 8586, "data_time": 0.21878, "stage0_loss_cls": 0.77954, "stage0_pos_acc": 81.75, "stage0_loss_bbox": 0.34918, "stage0_loss_iou": 0.61209, "stage0_loss_global": 0.23263, "stage0_loss_mask": 0.71549, "stage1_loss_cls": 0.55977, "stage1_pos_acc": 91.75, "stage1_loss_bbox": 0.23157, "stage1_loss_iou": 0.41426, "stage1_loss_global": 0.17793, "stage1_loss_mask": 0.65878, "stage2_loss_cls": 0.36394, "stage2_pos_acc": 92.5, "stage2_loss_bbox": 0.23525, "stage2_loss_iou": 0.41166, "stage2_loss_global": 0.14879, "stage2_loss_mask": 0.7084, "stage3_loss_cls": 0.29883, "stage3_pos_acc": 91.75, "stage3_loss_bbox": 0.23321, "stage3_loss_iou": 0.4048, "stage3_loss_global": 0.14672, "stage3_loss_mask": 0.67254, "stage4_loss_cls": 0.27245, "stage4_pos_acc": 92.0, "stage4_loss_bbox": 0.22947, "stage4_loss_iou": 0.40076, "stage4_loss_global": 0.15002, "stage4_loss_mask": 0.73315, "stage5_loss_cls": 0.27742, "stage5_pos_acc": 91.75, "stage5_loss_bbox": 0.23049, "stage5_loss_iou": 0.39954, "stage5_loss_global": 0.15206, "stage5_loss_mask": 0.71399, "loss": 11.91473, "grad_norm": 267.58739, "time": 1.3226}
{"mode": "train", "epoch": 13, "iter": 50, "lr": 2e-05, "memory": 8608, "data_time": 0.21582, "stage0_loss_cls": 0.73118, "stage0_pos_acc": 84.0, "stage0_loss_bbox": 0.3277, "stage0_loss_iou": 0.56784, "stage0_loss_global": 0.17832, "stage0_loss_mask": 0.654, "stage1_loss_cls": 0.49615, "stage1_pos_acc": 91.0, "stage1_loss_bbox": 0.24367, "stage1_loss_iou": 0.41708, "stage1_loss_global": 0.15788, "stage1_loss_mask": 0.63123, "stage2_loss_cls": 0.33158, "stage2_pos_acc": 93.5, "stage2_loss_bbox": 0.2392, "stage2_loss_iou": 0.40799, "stage2_loss_global": 0.1425, "stage2_loss_mask": 0.65116, "stage3_loss_cls": 0.30078, "stage3_pos_acc": 93.0, "stage3_loss_bbox": 0.23228, "stage3_loss_iou": 0.39764, "stage3_loss_global": 0.14129, "stage3_loss_mask": 0.64963, "stage4_loss_cls": 0.2788, "stage4_pos_acc": 93.5, "stage4_loss_bbox": 0.22956, "stage4_loss_iou": 0.39503, "stage4_loss_global": 0.14424, "stage4_loss_mask": 0.71502, "stage5_loss_cls": 0.2769, "stage5_pos_acc": 92.75, "stage5_loss_bbox": 0.22874, "stage5_loss_iou": 0.39621, "stage5_loss_global": 0.14041, "stage5_loss_mask": 0.67255, "loss": 11.37659, "grad_norm": 223.14127, "time": 1.32978}
{"mode": "train", "epoch": 14, "iter": 50, "lr": 2e-05, "memory": 8608, "data_time": 0.21595, "stage0_loss_cls": 0.73813, "stage0_pos_acc": 84.75, "stage0_loss_bbox": 0.36207, "stage0_loss_iou": 0.63409, "stage0_loss_global": 0.18397, "stage0_loss_mask": 0.6576, "stage1_loss_cls": 0.55346, "stage1_pos_acc": 91.25, "stage1_loss_bbox": 0.23273, "stage1_loss_iou": 0.41246, "stage1_loss_global": 0.17619, "stage1_loss_mask": 0.62021, "stage2_loss_cls": 0.38324, "stage2_pos_acc": 91.25, "stage2_loss_bbox": 0.22949, "stage2_loss_iou": 0.40484, "stage2_loss_global": 0.17989, "stage2_loss_mask": 0.63619, "stage3_loss_cls": 0.30254, "stage3_pos_acc": 91.25, "stage3_loss_bbox": 0.22535, "stage3_loss_iou": 0.39386, "stage3_loss_global": 0.18311, "stage3_loss_mask": 0.61895, "stage4_loss_cls": 0.27336, "stage4_pos_acc": 91.75, "stage4_loss_bbox": 0.22535, "stage4_loss_iou": 0.39223, "stage4_loss_global": 0.19105, "stage4_loss_mask": 0.66855, "stage5_loss_cls": 0.2756, "stage5_pos_acc": 92.25, "stage5_loss_bbox": 0.22282, "stage5_loss_iou": 0.3884, "stage5_loss_global": 0.18784, "stage5_loss_mask": 0.62987, "loss": 11.58343, "grad_norm": 330.6865, "time": 1.32388}
{"mode": "train", "epoch": 15, "iter": 50, "lr": 2e-05, "memory": 8608, "data_time": 0.212, "stage0_loss_cls": 0.7269, "stage0_pos_acc": 90.5, "stage0_loss_bbox": 0.33534, "stage0_loss_iou": 0.5818, "stage0_loss_global": 0.18538, "stage0_loss_mask": 0.64215, "stage1_loss_cls": 0.54523, "stage1_pos_acc": 94.0, "stage1_loss_bbox": 0.21795, "stage1_loss_iou": 0.38845, "stage1_loss_global": 0.19286, "stage1_loss_mask": 0.58831, "stage2_loss_cls": 0.34473, "stage2_pos_acc": 91.0, "stage2_loss_bbox": 0.22466, "stage2_loss_iou": 0.39174, "stage2_loss_global": 0.194, "stage2_loss_mask": 0.60783, "stage3_loss_cls": 0.29682, "stage3_pos_acc": 91.0, "stage3_loss_bbox": 0.21951, "stage3_loss_iou": 0.38609, "stage3_loss_global": 0.19752, "stage3_loss_mask": 0.58353, "stage4_loss_cls": 0.26045, "stage4_pos_acc": 90.75, "stage4_loss_bbox": 0.21942, "stage4_loss_iou": 0.38429, "stage4_loss_global": 0.19917, "stage4_loss_mask": 0.62651, "stage5_loss_cls": 0.25807, "stage5_pos_acc": 90.0, "stage5_loss_bbox": 0.22182, "stage5_loss_iou": 0.38535, "stage5_loss_global": 0.2023, "stage5_loss_mask": 0.60334, "loss": 11.21153, "grad_norm": 417.7769, "time": 1.29942}
{"mode": "train", "epoch": 16, "iter": 50, "lr": 2e-05, "memory": 8608, "data_time": 0.21653, "stage0_loss_cls": 0.6918, "stage0_pos_acc": 89.75, "stage0_loss_bbox": 0.32753, "stage0_loss_iou": 0.57893, "stage0_loss_global": 0.12923, "stage0_loss_mask": 0.59261, "stage1_loss_cls": 0.49656, "stage1_pos_acc": 92.0, "stage1_loss_bbox": 0.2298, "stage1_loss_iou": 0.40631, "stage1_loss_global": 0.12845, "stage1_loss_mask": 0.59386, "stage2_loss_cls": 0.32639, "stage2_pos_acc": 93.75, "stage2_loss_bbox": 0.22191, "stage2_loss_iou": 0.39588, "stage2_loss_global": 0.1248, "stage2_loss_mask": 0.60869, "stage3_loss_cls": 0.25851, "stage3_pos_acc": 93.75, "stage3_loss_bbox": 0.21967, "stage3_loss_iou": 0.39339, "stage3_loss_global": 0.12854, "stage3_loss_mask": 0.60339, "stage4_loss_cls": 0.21419, "stage4_pos_acc": 93.25, "stage4_loss_bbox": 0.22241, "stage4_loss_iou": 0.39397, "stage4_loss_global": 0.12905, "stage4_loss_mask": 0.6346, "stage5_loss_cls": 0.22876, "stage5_pos_acc": 93.25, "stage5_loss_bbox": 0.22351, "stage5_loss_iou": 0.39583, "stage5_loss_global": 0.12555, "stage5_loss_mask": 0.61272, "loss": 10.63683, "grad_norm": 279.05924, "time": 1.32627}
{"mode": "train", "epoch": 17, "iter": 50, "lr": 2e-05, "memory": 8608, "data_time": 0.21456, "stage0_loss_cls": 0.67559, "stage0_pos_acc": 92.5, "stage0_loss_bbox": 0.32648, "stage0_loss_iou": 0.57668, "stage0_loss_global": 0.14897, "stage0_loss_mask": 0.59753, "stage1_loss_cls": 0.45684, "stage1_pos_acc": 93.25, "stage1_loss_bbox": 0.2331, "stage1_loss_iou": 0.40835, "stage1_loss_global": 0.15241, "stage1_loss_mask": 0.5643, "stage2_loss_cls": 0.29024, "stage2_pos_acc": 93.0, "stage2_loss_bbox": 0.22437, "stage2_loss_iou": 0.39467, "stage2_loss_global": 0.1613, "stage2_loss_mask": 0.57361, "stage3_loss_cls": 0.2663, "stage3_pos_acc": 94.25, "stage3_loss_bbox": 0.21792, "stage3_loss_iou": 0.38258, "stage3_loss_global": 0.16142, "stage3_loss_mask": 0.55793, "stage4_loss_cls": 0.22883, "stage4_pos_acc": 94.5, "stage4_loss_bbox": 0.21765, "stage4_loss_iou": 0.38251, "stage4_loss_global": 0.16825, "stage4_loss_mask": 0.58247, "stage5_loss_cls": 0.23816, "stage5_pos_acc": 94.0, "stage5_loss_bbox": 0.21581, "stage5_loss_iou": 0.38022, "stage5_loss_global": 0.16924, "stage5_loss_mask": 0.57369, "loss": 10.52741, "grad_norm": 653.17284, "time": 1.32789}
{"mode": "train", "epoch": 18, "iter": 50, "lr": 2e-05, "memory": 8608, "data_time": 0.21934, "stage0_loss_cls": 0.62622, "stage0_pos_acc": 92.75, "stage0_loss_bbox": 0.32418, "stage0_loss_iou": 0.58044, "stage0_loss_global": 0.11785, "stage0_loss_mask": 0.58177, "stage1_loss_cls": 0.43685, "stage1_pos_acc": 95.75, "stage1_loss_bbox": 0.23111, "stage1_loss_iou": 0.40216, "stage1_loss_global": 0.11564, "stage1_loss_mask": 0.57534, "stage2_loss_cls": 0.27326, "stage2_pos_acc": 96.0, "stage2_loss_bbox": 0.22804, "stage2_loss_iou": 0.39653, "stage2_loss_global": 0.11804, "stage2_loss_mask": 0.57575, "stage3_loss_cls": 0.22368, "stage3_pos_acc": 96.5, "stage3_loss_bbox": 0.22443, "stage3_loss_iou": 0.39023, "stage3_loss_global": 0.12118, "stage3_loss_mask": 0.5756, "stage4_loss_cls": 0.20343, "stage4_pos_acc": 95.5, "stage4_loss_bbox": 0.22125, "stage4_loss_iou": 0.38747, "stage4_loss_global": 0.12316, "stage4_loss_mask": 0.59488, "stage5_loss_cls": 0.2028, "stage5_pos_acc": 96.25, "stage5_loss_bbox": 0.22219, "stage5_loss_iou": 0.38801, "stage5_loss_global": 0.11876, "stage5_loss_mask": 0.57908, "loss": 10.15934, "grad_norm": 268.43413, "time": 1.32847}
{"mode": "train", "epoch": 19, "iter": 50, "lr": 2e-05, "memory": 8608, "data_time": 0.22132, "stage0_loss_cls": 0.60353, "stage0_pos_acc": 90.25, "stage0_loss_bbox": 0.33491, "stage0_loss_iou": 0.59498, "stage0_loss_global": 0.18832, "stage0_loss_mask": 0.58765, "stage1_loss_cls": 0.42609, "stage1_pos_acc": 92.5, "stage1_loss_bbox": 0.23693, "stage1_loss_iou": 0.41481, "stage1_loss_global": 0.19877, "stage1_loss_mask": 0.57287, "stage2_loss_cls": 0.29066, "stage2_pos_acc": 92.0, "stage2_loss_bbox": 0.22959, "stage2_loss_iou": 0.39634, "stage2_loss_global": 0.21004, "stage2_loss_mask": 0.56217, "stage3_loss_cls": 0.247, "stage3_pos_acc": 91.75, "stage3_loss_bbox": 0.22861, "stage3_loss_iou": 0.39465, "stage3_loss_global": 0.21878, "stage3_loss_mask": 0.56036, "stage4_loss_cls": 0.22958, "stage4_pos_acc": 90.75, "stage4_loss_bbox": 0.22733, "stage4_loss_iou": 0.39515, "stage4_loss_global": 0.2217, "stage4_loss_mask": 0.58634, "stage5_loss_cls": 0.22647, "stage5_pos_acc": 91.5, "stage5_loss_bbox": 0.23006, "stage5_loss_iou": 0.4007, "stage5_loss_global": 0.22199, "stage5_loss_mask": 0.57159, "loss": 10.80795, "grad_norm": 323.66858, "time": 1.33641}
{"mode": "train", "epoch": 20, "iter": 50, "lr": 3e-05, "memory": 8608, "data_time": 0.21908, "stage0_loss_cls": 0.5567, "stage0_pos_acc": 89.25, "stage0_loss_bbox": 0.3282, "stage0_loss_iou": 0.57396, "stage0_loss_global": 0.15947, "stage0_loss_mask": 0.56989, "stage1_loss_cls": 0.38031, "stage1_pos_acc": 91.0, "stage1_loss_bbox": 0.2274, "stage1_loss_iou": 0.40628, "stage1_loss_global": 0.16677, "stage1_loss_mask": 0.55826, "stage2_loss_cls": 0.2939, "stage2_pos_acc": 92.5, "stage2_loss_bbox": 0.21156, "stage2_loss_iou": 0.38212, "stage2_loss_global": 0.17932, "stage2_loss_mask": 0.53936, "stage3_loss_cls": 0.24142, "stage3_pos_acc": 92.25, "stage3_loss_bbox": 0.21426, "stage3_loss_iou": 0.3796, "stage3_loss_global": 0.20186, "stage3_loss_mask": 0.54647, "stage4_loss_cls": 0.23047, "stage4_pos_acc": 93.0, "stage4_loss_bbox": 0.21489, "stage4_loss_iou": 0.37999, "stage4_loss_global": 0.20359, "stage4_loss_mask": 0.57101, "stage5_loss_cls": 0.23915, "stage5_pos_acc": 93.5, "stage5_loss_bbox": 0.21614, "stage5_loss_iou": 0.38316, "stage5_loss_global": 0.21063, "stage5_loss_mask": 0.56064, "loss": 10.32678, "grad_norm": 335.58977, "time": 1.32331}
{"mode": "train", "epoch": 21, "iter": 50, "lr": 3e-05, "memory": 8608, "data_time": 0.21279, "stage0_loss_cls": 0.51679, "stage0_pos_acc": 88.5, "stage0_loss_bbox": 0.3228, "stage0_loss_iou": 0.5775, "stage0_loss_global": 0.18448, "stage0_loss_mask": 0.53688, "stage1_loss_cls": 0.35213, "stage1_pos_acc": 91.75, "stage1_loss_bbox": 0.22194, "stage1_loss_iou": 0.39302, "stage1_loss_global": 0.19582, "stage1_loss_mask": 0.52346, "stage2_loss_cls": 0.25373, "stage2_pos_acc": 92.0, "stage2_loss_bbox": 0.21743, "stage2_loss_iou": 0.37934, "stage2_loss_global": 0.20805, "stage2_loss_mask": 0.52485, "stage3_loss_cls": 0.20048, "stage3_pos_acc": 91.0, "stage3_loss_bbox": 0.21627, "stage3_loss_iou": 0.3769, "stage3_loss_global": 0.21162, "stage3_loss_mask": 0.52293, "stage4_loss_cls": 0.19629, "stage4_pos_acc": 91.5, "stage4_loss_bbox": 0.21335, "stage4_loss_iou": 0.37398, "stage4_loss_global": 0.21768, "stage4_loss_mask": 0.53236, "stage5_loss_cls": 0.18854, "stage5_pos_acc": 91.5, "stage5_loss_bbox": 0.21321, "stage5_loss_iou": 0.37394, "stage5_loss_global": 0.2175, "stage5_loss_mask": 0.53005, "loss": 9.99332, "grad_norm": 256.14138, "time": 1.30599}
{"mode": "train", "epoch": 22, "iter": 50, "lr": 3e-05, "memory": 8624, "data_time": 0.21979, "stage0_loss_cls": 0.48357, "stage0_pos_acc": 90.5, "stage0_loss_bbox": 0.30543, "stage0_loss_iou": 0.55312, "stage0_loss_global": 0.16727, "stage0_loss_mask": 0.5316, "stage1_loss_cls": 0.33582, "stage1_pos_acc": 91.0, "stage1_loss_bbox": 0.2199, "stage1_loss_iou": 0.38132, "stage1_loss_global": 0.16866, "stage1_loss_mask": 0.52123, "stage2_loss_cls": 0.24749, "stage2_pos_acc": 90.75, "stage2_loss_bbox": 0.21037, "stage2_loss_iou": 0.3673, "stage2_loss_global": 0.16949, "stage2_loss_mask": 0.52687, "stage3_loss_cls": 0.1948, "stage3_pos_acc": 90.5, "stage3_loss_bbox": 0.21354, "stage3_loss_iou": 0.37132, "stage3_loss_global": 0.17017, "stage3_loss_mask": 0.53265, "stage4_loss_cls": 0.18183, "stage4_pos_acc": 90.75, "stage4_loss_bbox": 0.21096, "stage4_loss_iou": 0.367, "stage4_loss_global": 0.17847, "stage4_loss_mask": 0.53512, "stage5_loss_cls": 0.17957, "stage5_pos_acc": 91.0, "stage5_loss_bbox": 0.21178, "stage5_loss_iou": 0.36746, "stage5_loss_global": 0.17701, "stage5_loss_mask": 0.53065, "loss": 9.61179, "grad_norm": 291.73189, "time": 1.31863}
{"mode": "train", "epoch": 23, "iter": 50, "lr": 3e-05, "memory": 8624, "data_time": 0.21712, "stage0_loss_cls": 0.50486, "stage0_pos_acc": 90.75, "stage0_loss_bbox": 0.33701, "stage0_loss_iou": 0.6165, "stage0_loss_global": 0.21328, "stage0_loss_mask": 0.53493, "stage1_loss_cls": 0.36816, "stage1_pos_acc": 91.0, "stage1_loss_bbox": 0.22188, "stage1_loss_iou": 0.39487, "stage1_loss_global": 0.21871, "stage1_loss_mask": 0.53437, "stage2_loss_cls": 0.24981, "stage2_pos_acc": 90.5, "stage2_loss_bbox": 0.212, "stage2_loss_iou": 0.37463, "stage2_loss_global": 0.23633, "stage2_loss_mask": 0.52819, "stage3_loss_cls": 0.22864, "stage3_pos_acc": 90.5, "stage3_loss_bbox": 0.21023, "stage3_loss_iou": 0.37217, "stage3_loss_global": 0.23333, "stage3_loss_mask": 0.52819, "stage4_loss_cls": 0.19682, "stage4_pos_acc": 90.5, "stage4_loss_bbox": 0.21387, "stage4_loss_iou": 0.37252, "stage4_loss_global": 0.24237, "stage4_loss_mask": 0.52663, "stage5_loss_cls": 0.19182, "stage5_pos_acc": 90.25, "stage5_loss_bbox": 0.21331, "stage5_loss_iou": 0.37256, "stage5_loss_global": 0.23477, "stage5_loss_mask": 0.5205, "loss": 10.20326, "grad_norm": 380.8131, "time": 1.32153}
{"mode": "train", "epoch": 24, "iter": 50, "lr": 3e-05, "memory": 8624, "data_time": 0.21834, "stage0_loss_cls": 0.46756, "stage0_pos_acc": 94.5, "stage0_loss_bbox": 0.35345, "stage0_loss_iou": 0.62749, "stage0_loss_global": 0.08597, "stage0_loss_mask": 0.52958, "stage1_loss_cls": 0.30671, "stage1_pos_acc": 95.5, "stage1_loss_bbox": 0.21737, "stage1_loss_iou": 0.37894, "stage1_loss_global": 0.08442, "stage1_loss_mask": 0.49876, "stage2_loss_cls": 0.17655, "stage2_pos_acc": 96.0, "stage2_loss_bbox": 0.20983, "stage2_loss_iou": 0.36554, "stage2_loss_global": 0.08881, "stage2_loss_mask": 0.49323, "stage3_loss_cls": 0.15185, "stage3_pos_acc": 96.25, "stage3_loss_bbox": 0.20105, "stage3_loss_iou": 0.35066, "stage3_loss_global": 0.08928, "stage3_loss_mask": 0.48916, "stage4_loss_cls": 0.13672, "stage4_pos_acc": 95.75, "stage4_loss_bbox": 0.2008, "stage4_loss_iou": 0.34869, "stage4_loss_global": 0.09079, "stage4_loss_mask": 0.49189, "stage5_loss_cls": 0.13235, "stage5_pos_acc": 96.0, "stage5_loss_bbox": 0.20548, "stage5_loss_iou": 0.35439, "stage5_loss_global": 0.09461, "stage5_loss_mask": 0.50677, "loss": 8.72869, "grad_norm": 272.80058, "time": 1.31459}
{"mode": "train", "epoch": 25, "iter": 50, "lr": 3e-05, "memory": 8624, "data_time": 0.21681, "stage0_loss_cls": 0.48311, "stage0_pos_acc": 92.25, "stage0_loss_bbox": 0.3371, "stage0_loss_iou": 0.6007, "stage0_loss_global": 0.137, "stage0_loss_mask": 0.49071, "stage1_loss_cls": 0.32929, "stage1_pos_acc": 93.75, "stage1_loss_bbox": 0.22091, "stage1_loss_iou": 0.38906, "stage1_loss_global": 0.14884, "stage1_loss_mask": 0.50267, "stage2_loss_cls": 0.23316, "stage2_pos_acc": 92.25, "stage2_loss_bbox": 0.20938, "stage2_loss_iou": 0.36676, "stage2_loss_global": 0.14874, "stage2_loss_mask": 0.49735, "stage3_loss_cls": 0.19609, "stage3_pos_acc": 92.75, "stage3_loss_bbox": 0.2023, "stage3_loss_iou": 0.3553, "stage3_loss_global": 0.15146, "stage3_loss_mask": 0.4933, "stage4_loss_cls": 0.17661, "stage4_pos_acc": 92.0, "stage4_loss_bbox": 0.20463, "stage4_loss_iou": 0.35832, "stage4_loss_global": 0.15552, "stage4_loss_mask": 0.51868, "stage5_loss_cls": 0.17756, "stage5_pos_acc": 92.25, "stage5_loss_bbox": 0.20334, "stage5_loss_iou": 0.3572, "stage5_loss_global": 0.15222, "stage5_loss_mask": 0.51237, "loss": 9.30969, "grad_norm": 367.184, "time": 1.33235}
{"mode": "train", "epoch": 26, "iter": 50, "lr": 3e-05, "memory": 8624, "data_time": 0.21676, "stage0_loss_cls": 0.4333, "stage0_pos_acc": 94.5, "stage0_loss_bbox": 0.34581, "stage0_loss_iou": 0.6126, "stage0_loss_global": 0.08849, "stage0_loss_mask": 0.52516, "stage1_loss_cls": 0.29551, "stage1_pos_acc": 96.25, "stage1_loss_bbox": 0.22055, "stage1_loss_iou": 0.38337, "stage1_loss_global": 0.09019, "stage1_loss_mask": 0.5105, "stage2_loss_cls": 0.19065, "stage2_pos_acc": 95.5, "stage2_loss_bbox": 0.22007, "stage2_loss_iou": 0.37457, "stage2_loss_global": 0.09057, "stage2_loss_mask": 0.5045, "stage3_loss_cls": 0.14854, "stage3_pos_acc": 96.25, "stage3_loss_bbox": 0.21997, "stage3_loss_iou": 0.37303, "stage3_loss_global": 0.08825, "stage3_loss_mask": 0.51301, "stage4_loss_cls": 0.14251, "stage4_pos_acc": 95.75, "stage4_loss_bbox": 0.21622, "stage4_loss_iou": 0.37106, "stage4_loss_global": 0.08854, "stage4_loss_mask": 0.51261, "stage5_loss_cls": 0.14092, "stage5_pos_acc": 95.5, "stage5_loss_bbox": 0.21916, "stage5_loss_iou": 0.37226, "stage5_loss_global": 0.09046, "stage5_loss_mask": 0.52035, "loss": 8.90275, "grad_norm": 250.18089, "time": 1.31029}
{"mode": "train", "epoch": 27, "iter": 50, "lr": 3e-05, "memory": 8624, "data_time": 0.22083, "stage0_loss_cls": 0.42417, "stage0_pos_acc": 92.0, "stage0_loss_bbox": 0.33324, "stage0_loss_iou": 0.61167, "stage0_loss_global": 0.10348, "stage0_loss_mask": 0.49659, "stage1_loss_cls": 0.29483, "stage1_pos_acc": 95.75, "stage1_loss_bbox": 0.214, "stage1_loss_iou": 0.38771, "stage1_loss_global": 0.10519, "stage1_loss_mask": 0.4917, "stage2_loss_cls": 0.18636, "stage2_pos_acc": 95.5, "stage2_loss_bbox": 0.20797, "stage2_loss_iou": 0.37276, "stage2_loss_global": 0.10754, "stage2_loss_mask": 0.4888, "stage3_loss_cls": 0.13233, "stage3_pos_acc": 96.0, "stage3_loss_bbox": 0.20564, "stage3_loss_iou": 0.36609, "stage3_loss_global": 0.11011, "stage3_loss_mask": 0.49027, "stage4_loss_cls": 0.12615, "stage4_pos_acc": 96.0, "stage4_loss_bbox": 0.2094, "stage4_loss_iou": 0.36923, "stage4_loss_global": 0.11058, "stage4_loss_mask": 0.49524, "stage5_loss_cls": 0.12445, "stage5_pos_acc": 96.0, "stage5_loss_bbox": 0.20916, "stage5_loss_iou": 0.36839, "stage5_loss_global": 0.11223, "stage5_loss_mask": 0.49619, "loss": 8.75148, "grad_norm": 237.78968, "time": 1.33934}
{"mode": "train", "epoch": 28, "iter": 50, "lr": 0.0, "memory": 8624, "data_time": 0.21952, "stage0_loss_cls": 0.38285, "stage0_pos_acc": 94.75, "stage0_loss_bbox": 0.31458, "stage0_loss_iou": 0.56671, "stage0_loss_global": 0.08409, "stage0_loss_mask": 0.48674, "stage1_loss_cls": 0.24079, "stage1_pos_acc": 96.5, "stage1_loss_bbox": 0.20583, "stage1_loss_iou": 0.36422, "stage1_loss_global": 0.0875, "stage1_loss_mask": 0.46948, "stage2_loss_cls": 0.16979, "stage2_pos_acc": 96.0, "stage2_loss_bbox": 0.20485, "stage2_loss_iou": 0.35223, "stage2_loss_global": 0.08594, "stage2_loss_mask": 0.47064, "stage3_loss_cls": 0.12063, "stage3_pos_acc": 96.25, "stage3_loss_bbox": 0.19989, "stage3_loss_iou": 0.34364, "stage3_loss_global": 0.09064, "stage3_loss_mask": 0.47613, "stage4_loss_cls": 0.10631, "stage4_pos_acc": 96.75, "stage4_loss_bbox": 0.20121, "stage4_loss_iou": 0.34261, "stage4_loss_global": 0.09343, "stage4_loss_mask": 0.4745, "stage5_loss_cls": 0.09949, "stage5_pos_acc": 97.5, "stage5_loss_bbox": 0.19727, "stage5_loss_iou": 0.33964, "stage5_loss_global": 0.09496, "stage5_loss_mask": 0.47896, "loss": 8.14554, "grad_norm": 587.11419, "time": 1.33333}
{"mode": "train", "epoch": 29, "iter": 50, "lr": 0.0, "memory": 8624, "data_time": 0.21514, "stage0_loss_cls": 0.34412, "stage0_pos_acc": 96.0, "stage0_loss_bbox": 0.29485, "stage0_loss_iou": 0.53168, "stage0_loss_global": 0.06019, "stage0_loss_mask": 0.50054, "stage1_loss_cls": 0.1961, "stage1_pos_acc": 97.0, "stage1_loss_bbox": 0.20052, "stage1_loss_iou": 0.3583, "stage1_loss_global": 0.06034, "stage1_loss_mask": 0.47553, "stage2_loss_cls": 0.12839, "stage2_pos_acc": 97.25, "stage2_loss_bbox": 0.19543, "stage2_loss_iou": 0.34854, "stage2_loss_global": 0.06075, "stage2_loss_mask": 0.47458, "stage3_loss_cls": 0.092, "stage3_pos_acc": 97.25, "stage3_loss_bbox": 0.19257, "stage3_loss_iou": 0.34519, "stage3_loss_global": 0.06188, "stage3_loss_mask": 0.47808, "stage4_loss_cls": 0.08264, "stage4_pos_acc": 97.25, "stage4_loss_bbox": 0.19272, "stage4_loss_iou": 0.34319, "stage4_loss_global": 0.06285, "stage4_loss_mask": 0.47585, "stage5_loss_cls": 0.08253, "stage5_pos_acc": 97.5, "stage5_loss_bbox": 0.19029, "stage5_loss_iou": 0.34048, "stage5_loss_global": 0.0643, "stage5_loss_mask": 0.47787, "loss": 7.71231, "grad_norm": 215.43409, "time": 1.3263}
{"mode": "train", "epoch": 30, "iter": 50, "lr": 0.0, "memory": 8624, "data_time": 0.22154, "stage0_loss_cls": 0.3368, "stage0_pos_acc": 94.75, "stage0_loss_bbox": 0.29889, "stage0_loss_iou": 0.53348, "stage0_loss_global": 0.0799, "stage0_loss_mask": 0.48287, "stage1_loss_cls": 0.21607, "stage1_pos_acc": 96.75, "stage1_loss_bbox": 0.2015, "stage1_loss_iou": 0.35905, "stage1_loss_global": 0.08154, "stage1_loss_mask": 0.45751, "stage2_loss_cls": 0.12392, "stage2_pos_acc": 96.25, "stage2_loss_bbox": 0.20527, "stage2_loss_iou": 0.35812, "stage2_loss_global": 0.08026, "stage2_loss_mask": 0.4569, "stage3_loss_cls": 0.09549, "stage3_pos_acc": 96.5, "stage3_loss_bbox": 0.19679, "stage3_loss_iou": 0.34568, "stage3_loss_global": 0.08319, "stage3_loss_mask": 0.43748, "stage4_loss_cls": 0.08275, "stage4_pos_acc": 97.0, "stage4_loss_bbox": 0.19737, "stage4_loss_iou": 0.34536, "stage4_loss_global": 0.0855, "stage4_loss_mask": 0.44613, "stage5_loss_cls": 0.07735, "stage5_pos_acc": 96.75, "stage5_loss_bbox": 0.19575, "stage5_loss_iou": 0.34349, "stage5_loss_global": 0.08361, "stage5_loss_mask": 0.44765, "loss": 7.73567, "grad_norm": 498.50249, "time": 1.33095}
{"mode": "train", "epoch": 31, "iter": 50, "lr": 0.0, "memory": 8624, "data_time": 0.22042, "stage0_loss_cls": 0.34294, "stage0_pos_acc": 96.75, "stage0_loss_bbox": 0.29216, "stage0_loss_iou": 0.52443, "stage0_loss_global": 0.08303, "stage0_loss_mask": 0.48615, "stage1_loss_cls": 0.2101, "stage1_pos_acc": 96.5, "stage1_loss_bbox": 0.20298, "stage1_loss_iou": 0.35711, "stage1_loss_global": 0.0829, "stage1_loss_mask": 0.47683, "stage2_loss_cls": 0.13717, "stage2_pos_acc": 96.0, "stage2_loss_bbox": 0.19408, "stage2_loss_iou": 0.3472, "stage2_loss_global": 0.08553, "stage2_loss_mask": 0.46063, "stage3_loss_cls": 0.09783, "stage3_pos_acc": 96.0, "stage3_loss_bbox": 0.1921, "stage3_loss_iou": 0.34019, "stage3_loss_global": 0.08387, "stage3_loss_mask": 0.45992, "stage4_loss_cls": 0.08664, "stage4_pos_acc": 96.25, "stage4_loss_bbox": 0.18797, "stage4_loss_iou": 0.3328, "stage4_loss_global": 0.08228, "stage4_loss_mask": 0.45983, "stage5_loss_cls": 0.07947, "stage5_pos_acc": 96.75, "stage5_loss_bbox": 0.18748, "stage5_loss_iou": 0.33143, "stage5_loss_global": 0.0799, "stage5_loss_mask": 0.46183, "loss": 7.74679, "grad_norm": 222.87792, "time": 1.34025}
{"mode": "train", "epoch": 32, "iter": 50, "lr": 0.0, "memory": 8624, "data_time": 0.2177, "stage0_loss_cls": 0.3222, "stage0_pos_acc": 96.75, "stage0_loss_bbox": 0.29345, "stage0_loss_iou": 0.52398, "stage0_loss_global": 0.04608, "stage0_loss_mask": 0.4867, "stage1_loss_cls": 0.20148, "stage1_pos_acc": 98.0, "stage1_loss_bbox": 0.20354, "stage1_loss_iou": 0.35747, "stage1_loss_global": 0.04514, "stage1_loss_mask": 0.46459, "stage2_loss_cls": 0.11975, "stage2_pos_acc": 97.5, "stage2_loss_bbox": 0.19341, "stage2_loss_iou": 0.33953, "stage2_loss_global": 0.04387, "stage2_loss_mask": 0.46086, "stage3_loss_cls": 0.08564, "stage3_pos_acc": 97.5, "stage3_loss_bbox": 0.19151, "stage3_loss_iou": 0.33581, "stage3_loss_global": 0.04427, "stage3_loss_mask": 0.45941, "stage4_loss_cls": 0.0762, "stage4_pos_acc": 97.75, "stage4_loss_bbox": 0.18525, "stage4_loss_iou": 0.33014, "stage4_loss_global": 0.04207, "stage4_loss_mask": 0.45924, "stage5_loss_cls": 0.07647, "stage5_pos_acc": 98.0, "stage5_loss_bbox": 0.18384, "stage5_loss_iou": 0.32812, "stage5_loss_global": 0.04355, "stage5_loss_mask": 0.46102, "loss": 7.40457, "grad_norm": 163.17955, "time": 1.32151}
{"mode": "train", "epoch": 33, "iter": 50, "lr": 0.0, "memory": 8624, "data_time": 0.22039, "stage0_loss_cls": 0.31628, "stage0_pos_acc": 96.0, "stage0_loss_bbox": 0.27166, "stage0_loss_iou": 0.50106, "stage0_loss_global": 0.08179, "stage0_loss_mask": 0.46115, "stage1_loss_cls": 0.19962, "stage1_pos_acc": 96.25, "stage1_loss_bbox": 0.18712, "stage1_loss_iou": 0.33599, "stage1_loss_global": 0.08761, "stage1_loss_mask": 0.44327, "stage2_loss_cls": 0.11467, "stage2_pos_acc": 96.75, "stage2_loss_bbox": 0.1855, "stage2_loss_iou": 0.33328, "stage2_loss_global": 0.08679, "stage2_loss_mask": 0.44015, "stage3_loss_cls": 0.08116, "stage3_pos_acc": 96.75, "stage3_loss_bbox": 0.18485, "stage3_loss_iou": 0.33136, "stage3_loss_global": 0.08621, "stage3_loss_mask": 0.44358, "stage4_loss_cls": 0.0756, "stage4_pos_acc": 96.75, "stage4_loss_bbox": 0.18217, "stage4_loss_iou": 0.3275, "stage4_loss_global": 0.08956, "stage4_loss_mask": 0.44356, "stage5_loss_cls": 0.06519, "stage5_pos_acc": 97.0, "stage5_loss_bbox": 0.18166, "stage5_loss_iou": 0.32668, "stage5_loss_global": 0.09283, "stage5_loss_mask": 0.44377, "loss": 7.40161, "grad_norm": 282.23311, "time": 1.3336}
{"mode": "train", "epoch": 34, "iter": 50, "lr": 0.0, "memory": 8624, "data_time": 0.21923, "stage0_loss_cls": 0.30199, "stage0_pos_acc": 96.25, "stage0_loss_bbox": 0.28354, "stage0_loss_iou": 0.51731, "stage0_loss_global": 0.0559, "stage0_loss_mask": 0.46865, "stage1_loss_cls": 0.19307, "stage1_pos_acc": 98.0, "stage1_loss_bbox": 0.19757, "stage1_loss_iou": 0.34931, "stage1_loss_global": 0.05557, "stage1_loss_mask": 0.4487, "stage2_loss_cls": 0.12247, "stage2_pos_acc": 97.75, "stage2_loss_bbox": 0.18898, "stage2_loss_iou": 0.34035, "stage2_loss_global": 0.05449, "stage2_loss_mask": 0.44826, "stage3_loss_cls": 0.09226, "stage3_pos_acc": 98.25, "stage3_loss_bbox": 0.18787, "stage3_loss_iou": 0.3336, "stage3_loss_global": 0.05432, "stage3_loss_mask": 0.44949, "stage4_loss_cls": 0.07076, "stage4_pos_acc": 98.25, "stage4_loss_bbox": 0.18727, "stage4_loss_iou": 0.33162, "stage4_loss_global": 0.05366, "stage4_loss_mask": 0.44467, "stage5_loss_cls": 0.0685, "stage5_pos_acc": 98.25, "stage5_loss_bbox": 0.18738, "stage5_loss_iou": 0.33164, "stage5_loss_global": 0.05265, "stage5_loss_mask": 0.44462, "loss": 7.31649, "grad_norm": 197.95363, "time": 1.33261}
{"mode": "train", "epoch": 35, "iter": 50, "lr": 0.0, "memory": 8624, "data_time": 0.21754, "stage0_loss_cls": 0.31379, "stage0_pos_acc": 96.0, "stage0_loss_bbox": 0.27334, "stage0_loss_iou": 0.49569, "stage0_loss_global": 0.05547, "stage0_loss_mask": 0.45503, "stage1_loss_cls": 0.16812, "stage1_pos_acc": 97.0, "stage1_loss_bbox": 0.20786, "stage1_loss_iou": 0.36112, "stage1_loss_global": 0.0558, "stage1_loss_mask": 0.48414, "stage2_loss_cls": 0.10287, "stage2_pos_acc": 98.0, "stage2_loss_bbox": 0.20066, "stage2_loss_iou": 0.34606, "stage2_loss_global": 0.05173, "stage2_loss_mask": 0.47163, "stage3_loss_cls": 0.07816, "stage3_pos_acc": 97.5, "stage3_loss_bbox": 0.19425, "stage3_loss_iou": 0.33938, "stage3_loss_global": 0.05337, "stage3_loss_mask": 0.47736, "stage4_loss_cls": 0.06732, "stage4_pos_acc": 97.5, "stage4_loss_bbox": 0.1921, "stage4_loss_iou": 0.3352, "stage4_loss_global": 0.05346, "stage4_loss_mask": 0.45688, "stage5_loss_cls": 0.06486, "stage5_pos_acc": 97.25, "stage5_loss_bbox": 0.19181, "stage5_loss_iou": 0.3349, "stage5_loss_global": 0.05397, "stage5_loss_mask": 0.47836, "loss": 7.4147, "grad_norm": 208.54793, "time": 1.32288}
{"mode": "train", "epoch": 36, "iter": 50, "lr": 0.0, "memory": 8624, "data_time": 0.22211, "stage0_loss_cls": 0.28658, "stage0_pos_acc": 96.5, "stage0_loss_bbox": 0.26295, "stage0_loss_iou": 0.48651, "stage0_loss_global": 0.05874, "stage0_loss_mask": 0.44974, "stage1_loss_cls": 0.17352, "stage1_pos_acc": 97.75, "stage1_loss_bbox": 0.18926, "stage1_loss_iou": 0.34075, "stage1_loss_global": 0.05433, "stage1_loss_mask": 0.44267, "stage2_loss_cls": 0.11151, "stage2_pos_acc": 97.0, "stage2_loss_bbox": 0.18382, "stage2_loss_iou": 0.33126, "stage2_loss_global": 0.0544, "stage2_loss_mask": 0.43282, "stage3_loss_cls": 0.07795, "stage3_pos_acc": 97.25, "stage3_loss_bbox": 0.18166, "stage3_loss_iou": 0.32434, "stage3_loss_global": 0.05252, "stage3_loss_mask": 0.43849, "stage4_loss_cls": 0.06872, "stage4_pos_acc": 96.75, "stage4_loss_bbox": 0.1792, "stage4_loss_iou": 0.32021, "stage4_loss_global": 0.05112, "stage4_loss_mask": 0.43764, "stage5_loss_cls": 0.06795, "stage5_pos_acc": 97.0, "stage5_loss_bbox": 0.1778, "stage5_loss_iou": 0.31936, "stage5_loss_global": 0.04928, "stage5_loss_mask": 0.44134, "loss": 7.04645, "grad_norm": 267.55894, "time": 1.32484}
