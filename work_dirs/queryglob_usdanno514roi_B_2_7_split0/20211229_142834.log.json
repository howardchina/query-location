{"env_info": "sys.platform: linux\nPython: 3.8.10 (default, Jun  4 2021, 15:09:15) [GCC 7.5.0]\nCUDA available: True\nGPU 0,1,2,3: NVIDIA TITAN Xp\nCUDA_HOME: /usr/local/cuda\nNVCC: Cuda compilation tools, release 10.2, V10.2.89\nGCC: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609\nPyTorch: 1.7.0\nPyTorch compiling details: PyTorch built with:\n  - GCC 7.3\n  - C++ Version: 201402\n  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 10.2\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75\n  - CuDNN 7.6.5\n  - Magma 2.5.2\n  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n\nTorchVision: 0.8.1\nOpenCV: 4.5.3\nMMCV: 1.3.18\nMMCV Compiler: GCC 7.3\nMMCV CUDA Compiler: 10.2\nMMDetection: 2.12.0+170db93", "config": "dataset_type = 'AnatomyDataset'\ndata_root = '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi'\nsplit = 'split_0'\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\nalbu_train_transforms = [\n    dict(\n        type='OneOf',\n        transforms=[\n            dict(\n                type='Affine',\n                translate_percent=0.0,\n                rotate=90,\n                fit_output=True,\n                p=0.25),\n            dict(\n                type='Affine',\n                translate_percent=0.0,\n                rotate=180,\n                fit_output=True,\n                p=0.25),\n            dict(\n                type='Affine',\n                translate_percent=0.0,\n                rotate=270,\n                fit_output=True,\n                p=0.25)\n        ],\n        p=0.75)\n]\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n    dict(type='LoadAnatomy'),\n    dict(type='RandomFlip', flip_ratio=0.5),\n    dict(\n        type='Albu',\n        transforms=[\n            dict(\n                type='OneOf',\n                transforms=[\n                    dict(\n                        type='Affine',\n                        translate_percent=0.0,\n                        rotate=90,\n                        fit_output=True,\n                        p=0.25),\n                    dict(\n                        type='Affine',\n                        translate_percent=0.0,\n                        rotate=180,\n                        fit_output=True,\n                        p=0.25),\n                    dict(\n                        type='Affine',\n                        translate_percent=0.0,\n                        rotate=270,\n                        fit_output=True,\n                        p=0.25)\n                ],\n                p=0.75)\n        ],\n        bbox_params=dict(\n            type='BboxParams',\n            format='pascal_voc',\n            label_fields=['gt_labels'],\n            min_visibility=0.0,\n            filter_lost_elements=True),\n        keymap=dict(img='image', gt_masks='masks', gt_bboxes='bboxes'),\n        update_pad_shape=False,\n        skip_img_without_anno=True),\n    dict(\n        type='Resize',\n        img_scale=[(1333, 480), (1333, 512), (1333, 544), (1333, 576),\n                   (1333, 608), (1333, 640), (1333, 672), (1333, 704),\n                   (1333, 736), (1333, 768), (1333, 800)],\n        multiscale_mode='value',\n        keep_ratio=True),\n    dict(\n        type='Normalize',\n        mean=[123.675, 116.28, 103.53],\n        std=[58.395, 57.12, 57.375],\n        to_rgb=True),\n    dict(type='Pad', size_divisor=32),\n    dict(type='DefaultFormatBundle'),\n    dict(type='FormatAnatomyBundle'),\n    dict(\n        type='Collect',\n        keys=['img', 'anatomy', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnatomy'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(1333, 800),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='FormatAnatomyBundle'),\n            dict(type='Collect', keys=['img', 'anatomy'])\n        ])\n]\ndata = dict(\n    samples_per_gpu=2,\n    workers_per_gpu=2,\n    train=dict(\n        type='AnatomyDataset',\n        ann_file=\n        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/annotations/train_anno_crop_split_0.json',\n        img_prefix=\n        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/images/',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n            dict(type='LoadAnatomy'),\n            dict(type='RandomFlip', flip_ratio=0.5),\n            dict(\n                type='Albu',\n                transforms=[\n                    dict(\n                        type='OneOf',\n                        transforms=[\n                            dict(\n                                type='Affine',\n                                translate_percent=0.0,\n                                rotate=90,\n                                fit_output=True,\n                                p=0.25),\n                            dict(\n                                type='Affine',\n                                translate_percent=0.0,\n                                rotate=180,\n                                fit_output=True,\n                                p=0.25),\n                            dict(\n                                type='Affine',\n                                translate_percent=0.0,\n                                rotate=270,\n                                fit_output=True,\n                                p=0.25)\n                        ],\n                        p=0.75)\n                ],\n                bbox_params=dict(\n                    type='BboxParams',\n                    format='pascal_voc',\n                    label_fields=['gt_labels'],\n                    min_visibility=0.0,\n                    filter_lost_elements=True),\n                keymap=dict(img='image', gt_masks='masks', gt_bboxes='bboxes'),\n                update_pad_shape=False,\n                skip_img_without_anno=True),\n            dict(\n                type='Resize',\n                img_scale=[(1333, 480), (1333, 512), (1333, 544), (1333, 576),\n                           (1333, 608), (1333, 640), (1333, 672), (1333, 704),\n                           (1333, 736), (1333, 768), (1333, 800)],\n                multiscale_mode='value',\n                keep_ratio=True),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='DefaultFormatBundle'),\n            dict(type='FormatAnatomyBundle'),\n            dict(\n                type='Collect',\n                keys=['img', 'anatomy', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n        ],\n        classes=('lmym', 'GIST')),\n    val=dict(\n        type='AnatomyDataset',\n        ann_file=\n        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/annotations/val_anno_crop_split_0.json',\n        img_prefix=\n        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/images/',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnatomy'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(1333, 800),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='Pad', size_divisor=32),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='FormatAnatomyBundle'),\n                    dict(type='Collect', keys=['img', 'anatomy'])\n                ])\n        ],\n        classes=('lmym', 'GIST')),\n    test=dict(\n        type='AnatomyDataset',\n        ann_file=\n        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/annotations/val_anno_crop_split_0.json',\n        img_prefix=\n        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/images/',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnatomy'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(1333, 800),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='Pad', size_divisor=32),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='FormatAnatomyBundle'),\n                    dict(type='Collect', keys=['img', 'anatomy'])\n                ])\n        ],\n        classes=('lmym', 'GIST')))\nevaluation = dict(metric=['bbox', 'segm', 'glob'])\noptimizer = dict(type='AdamW', lr=2.5e-05, weight_decay=0.0001)\noptimizer_config = dict(grad_clip=dict(max_norm=1, norm_type=2))\nlr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=1000,\n    warmup_ratio=0.001,\n    step=[27, 33])\nrunner = dict(type='EpochBasedRunner', max_epochs=36)\ncheckpoint_config = dict(interval=1)\nlog_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\ncustom_hooks = [dict(type='NumClassCheckHook')]\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = 'work_dirs/pretrained/queryInst/queryinst_r101_300_queries-860dc5d5.pth'\nresume_from = None\nworkflow = [('train', 1)]\nnum_stages = 6\nnum_proposals = 300\nmodel = dict(\n    type='QueryGlob',\n    pretrained='torchvision://resnet101',\n    backbone=dict(\n        type='ResNet',\n        depth=101,\n        num_stages=4,\n        out_indices=(0, 1, 2, 3),\n        frozen_stages=1,\n        norm_cfg=dict(type='BN', requires_grad=True),\n        norm_eval=True,\n        style='pytorch'),\n    neck=dict(\n        type='FPN',\n        in_channels=[256, 512, 1024, 2048],\n        out_channels=256,\n        start_level=0,\n        add_extra_convs='on_input',\n        num_outs=4),\n    rpn_head=dict(\n        type='GlobalEmbeddingRPNHead',\n        num_proposals=300,\n        dim_global=7,\n        proposal_feature_channel=256),\n    roi_head=dict(\n        type='QueryGlobRoIHead',\n        num_stages=6,\n        stage_loss_weights=[1, 1, 1, 1, 1, 1],\n        proposal_feature_channel=256,\n        bbox_roi_extractor=dict(\n            type='SingleRoIExtractor',\n            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=2),\n            out_channels=256,\n            featmap_strides=[4, 8, 16, 32]),\n        mask_roi_extractor=dict(\n            type='SingleRoIExtractor',\n            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=2),\n            out_channels=256,\n            featmap_strides=[4, 8, 16, 32]),\n        bbox_head=[\n            dict(\n                type='GlobDIIHead',\n                num_classes=2,\n                num_ffn_fcs=2,\n                num_heads=8,\n                num_cls_fcs=2,\n                num_glb_fcs=2,\n                num_reg_fcs=3,\n                feedforward_channels=2048,\n                in_channels=256,\n                dropout=0.0,\n                ffn_act_cfg=dict(type='ReLU', inplace=True),\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=7,\n                    with_proj=True,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n                loss_cls=dict(\n                    type='FocalLoss',\n                    use_sigmoid=True,\n                    gamma=2.0,\n                    alpha=0.25,\n                    loss_weight=2.0),\n                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    clip_border=False,\n                    target_means=[0.0, 0.0, 0.0, 0.0],\n                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n            dict(\n                type='GlobDIIHead',\n                num_classes=2,\n                num_ffn_fcs=2,\n                num_heads=8,\n                num_cls_fcs=2,\n                num_glb_fcs=2,\n                num_reg_fcs=3,\n                feedforward_channels=2048,\n                in_channels=256,\n                dropout=0.0,\n                ffn_act_cfg=dict(type='ReLU', inplace=True),\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=7,\n                    with_proj=True,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n                loss_cls=dict(\n                    type='FocalLoss',\n                    use_sigmoid=True,\n                    gamma=2.0,\n                    alpha=0.25,\n                    loss_weight=2.0),\n                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    clip_border=False,\n                    target_means=[0.0, 0.0, 0.0, 0.0],\n                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n            dict(\n                type='GlobDIIHead',\n                num_classes=2,\n                num_ffn_fcs=2,\n                num_heads=8,\n                num_cls_fcs=2,\n                num_glb_fcs=2,\n                num_reg_fcs=3,\n                feedforward_channels=2048,\n                in_channels=256,\n                dropout=0.0,\n                ffn_act_cfg=dict(type='ReLU', inplace=True),\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=7,\n                    with_proj=True,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n                loss_cls=dict(\n                    type='FocalLoss',\n                    use_sigmoid=True,\n                    gamma=2.0,\n                    alpha=0.25,\n                    loss_weight=2.0),\n                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    clip_border=False,\n                    target_means=[0.0, 0.0, 0.0, 0.0],\n                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n            dict(\n                type='GlobDIIHead',\n                num_classes=2,\n                num_ffn_fcs=2,\n                num_heads=8,\n                num_cls_fcs=2,\n                num_glb_fcs=2,\n                num_reg_fcs=3,\n                feedforward_channels=2048,\n                in_channels=256,\n                dropout=0.0,\n                ffn_act_cfg=dict(type='ReLU', inplace=True),\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=7,\n                    with_proj=True,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n                loss_cls=dict(\n                    type='FocalLoss',\n                    use_sigmoid=True,\n                    gamma=2.0,\n                    alpha=0.25,\n                    loss_weight=2.0),\n                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    clip_border=False,\n                    target_means=[0.0, 0.0, 0.0, 0.0],\n                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n            dict(\n                type='GlobDIIHead',\n                num_classes=2,\n                num_ffn_fcs=2,\n                num_heads=8,\n                num_cls_fcs=2,\n                num_glb_fcs=2,\n                num_reg_fcs=3,\n                feedforward_channels=2048,\n                in_channels=256,\n                dropout=0.0,\n                ffn_act_cfg=dict(type='ReLU', inplace=True),\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=7,\n                    with_proj=True,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n                loss_cls=dict(\n                    type='FocalLoss',\n                    use_sigmoid=True,\n                    gamma=2.0,\n                    alpha=0.25,\n                    loss_weight=2.0),\n                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    clip_border=False,\n                    target_means=[0.0, 0.0, 0.0, 0.0],\n                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n            dict(\n                type='GlobDIIHead',\n                num_classes=2,\n                num_ffn_fcs=2,\n                num_heads=8,\n                num_cls_fcs=2,\n                num_glb_fcs=2,\n                num_reg_fcs=3,\n                feedforward_channels=2048,\n                in_channels=256,\n                dropout=0.0,\n                ffn_act_cfg=dict(type='ReLU', inplace=True),\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=7,\n                    with_proj=True,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n                loss_cls=dict(\n                    type='FocalLoss',\n                    use_sigmoid=True,\n                    gamma=2.0,\n                    alpha=0.25,\n                    loss_weight=2.0),\n                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    clip_border=False,\n                    target_means=[0.0, 0.0, 0.0, 0.0],\n                    target_stds=[0.5, 0.5, 1.0, 1.0]))\n        ],\n        mask_head=[\n            dict(\n                type='DynamicMaskHead',\n                num_classes=2,\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=14,\n                    with_proj=False,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                dropout=0.0,\n                num_convs=4,\n                roi_feat_size=14,\n                in_channels=256,\n                conv_kernel_size=3,\n                conv_out_channels=256,\n                class_agnostic=False,\n                norm_cfg=dict(type='BN'),\n                upsample_cfg=dict(type='deconv', scale_factor=2),\n                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n            dict(\n                type='DynamicMaskHead',\n                num_classes=2,\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=14,\n                    with_proj=False,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                dropout=0.0,\n                num_convs=4,\n                roi_feat_size=14,\n                in_channels=256,\n                conv_kernel_size=3,\n                conv_out_channels=256,\n                class_agnostic=False,\n                norm_cfg=dict(type='BN'),\n                upsample_cfg=dict(type='deconv', scale_factor=2),\n                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n            dict(\n                type='DynamicMaskHead',\n                num_classes=2,\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=14,\n                    with_proj=False,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                dropout=0.0,\n                num_convs=4,\n                roi_feat_size=14,\n                in_channels=256,\n                conv_kernel_size=3,\n                conv_out_channels=256,\n                class_agnostic=False,\n                norm_cfg=dict(type='BN'),\n                upsample_cfg=dict(type='deconv', scale_factor=2),\n                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n            dict(\n                type='DynamicMaskHead',\n                num_classes=2,\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=14,\n                    with_proj=False,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                dropout=0.0,\n                num_convs=4,\n                roi_feat_size=14,\n                in_channels=256,\n                conv_kernel_size=3,\n                conv_out_channels=256,\n                class_agnostic=False,\n                norm_cfg=dict(type='BN'),\n                upsample_cfg=dict(type='deconv', scale_factor=2),\n                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n            dict(\n                type='DynamicMaskHead',\n                num_classes=2,\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=14,\n                    with_proj=False,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                dropout=0.0,\n                num_convs=4,\n                roi_feat_size=14,\n                in_channels=256,\n                conv_kernel_size=3,\n                conv_out_channels=256,\n                class_agnostic=False,\n                norm_cfg=dict(type='BN'),\n                upsample_cfg=dict(type='deconv', scale_factor=2),\n                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n            dict(\n                type='DynamicMaskHead',\n                num_classes=2,\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=14,\n                    with_proj=False,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                dropout=0.0,\n                num_convs=4,\n                roi_feat_size=14,\n                in_channels=256,\n                conv_kernel_size=3,\n                conv_out_channels=256,\n                class_agnostic=False,\n                norm_cfg=dict(type='BN'),\n                upsample_cfg=dict(type='deconv', scale_factor=2),\n                loss_dice=dict(type='DiceLoss', loss_weight=8.0))\n        ]),\n    train_cfg=dict(\n        rpn=None,\n        rcnn=[\n            dict(\n                assigner=dict(\n                    type='HungarianAssigner',\n                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n                                  weight=2.0)),\n                sampler=dict(type='PseudoSampler'),\n                pos_weight=1,\n                mask_size=28,\n                debug=False),\n            dict(\n                assigner=dict(\n                    type='HungarianAssigner',\n                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n                                  weight=2.0)),\n                sampler=dict(type='PseudoSampler'),\n                pos_weight=1,\n                mask_size=28,\n                debug=False),\n            dict(\n                assigner=dict(\n                    type='HungarianAssigner',\n                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n                                  weight=2.0)),\n                sampler=dict(type='PseudoSampler'),\n                pos_weight=1,\n                mask_size=28,\n                debug=False),\n            dict(\n                assigner=dict(\n                    type='HungarianAssigner',\n                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n                                  weight=2.0)),\n                sampler=dict(type='PseudoSampler'),\n                pos_weight=1,\n                mask_size=28,\n                debug=False),\n            dict(\n                assigner=dict(\n                    type='HungarianAssigner',\n                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n                                  weight=2.0)),\n                sampler=dict(type='PseudoSampler'),\n                pos_weight=1,\n                mask_size=28,\n                debug=False),\n            dict(\n                assigner=dict(\n                    type='HungarianAssigner',\n                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n                                  weight=2.0)),\n                sampler=dict(type='PseudoSampler'),\n                pos_weight=1,\n                mask_size=28,\n                debug=False)\n        ]),\n    test_cfg=dict(\n        rpn=None,\n        rcnn=dict(\n            max_per_img=300,\n            mask_thr_binary=0.5,\n            nms=dict(type='nms', iou_threshold=0.7))))\ntotal_epochs = 36\nmin_values = (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)\nclasses = ('lmym', 'GIST')\ngpu_ids = range(0, 4)\nwork_dir = './work_dirs/queryglob_usdanno514roi_B_2_7_split0'\n", "seed": null, "exp_name": "queryglob_usdanno514roi_B_2_7_split0.py"}
{"mode": "train", "epoch": 1, "iter": 50, "lr": 0.0, "memory": 8079, "data_time": 0.21533, "stage0_loss_cls": 2.22566, "stage0_pos_acc": 52.25, "stage0_loss_bbox": 0.65066, "stage0_loss_iou": 1.0033, "stage0_loss_global": 0.81645, "stage0_loss_mask": 2.3543, "stage1_loss_cls": 2.53545, "stage1_pos_acc": 51.0, "stage1_loss_bbox": 0.55115, "stage1_loss_iou": 0.88694, "stage1_loss_global": 1.21339, "stage1_loss_mask": 2.48577, "stage2_loss_cls": 2.48217, "stage2_pos_acc": 57.5, "stage2_loss_bbox": 0.5652, "stage2_loss_iou": 0.88488, "stage2_loss_global": 1.0896, "stage2_loss_mask": 2.22763, "stage3_loss_cls": 2.21336, "stage3_pos_acc": 52.25, "stage3_loss_bbox": 0.56265, "stage3_loss_iou": 0.87143, "stage3_loss_global": 0.68411, "stage3_loss_mask": 3.84639, "stage4_loss_cls": 2.35704, "stage4_pos_acc": 56.0, "stage4_loss_bbox": 0.5793, "stage4_loss_iou": 0.88799, "stage4_loss_global": 0.75959, "stage4_loss_mask": 2.4705, "stage5_loss_cls": 2.12584, "stage5_pos_acc": 51.5, "stage5_loss_bbox": 0.58006, "stage5_loss_iou": 0.8868, "stage5_loss_global": 0.60847, "stage5_loss_mask": 3.39008, "loss": 44.79615, "grad_norm": 225.59995, "time": 1.33387}
{"mode": "train", "epoch": 2, "iter": 50, "lr": 0.0, "memory": 8583, "data_time": 0.21537, "stage0_loss_cls": 2.05803, "stage0_pos_acc": 54.5, "stage0_loss_bbox": 0.55371, "stage0_loss_iou": 0.88296, "stage0_loss_global": 0.62752, "stage0_loss_mask": 2.42544, "stage1_loss_cls": 2.3001, "stage1_pos_acc": 51.5, "stage1_loss_bbox": 0.42489, "stage1_loss_iou": 0.70572, "stage1_loss_global": 0.86512, "stage1_loss_mask": 2.25642, "stage2_loss_cls": 2.2929, "stage2_pos_acc": 59.5, "stage2_loss_bbox": 0.40914, "stage2_loss_iou": 0.68344, "stage2_loss_global": 0.66561, "stage2_loss_mask": 1.8391, "stage3_loss_cls": 1.99259, "stage3_pos_acc": 57.25, "stage3_loss_bbox": 0.41122, "stage3_loss_iou": 0.66882, "stage3_loss_global": 0.58442, "stage3_loss_mask": 3.49278, "stage4_loss_cls": 2.00164, "stage4_pos_acc": 54.25, "stage4_loss_bbox": 0.41736, "stage4_loss_iou": 0.67016, "stage4_loss_global": 0.60974, "stage4_loss_mask": 2.10471, "stage5_loss_cls": 1.83815, "stage5_pos_acc": 51.5, "stage5_loss_bbox": 0.40546, "stage5_loss_iou": 0.65165, "stage5_loss_global": 0.52622, "stage5_loss_mask": 3.11778, "loss": 38.48278, "grad_norm": 215.63445, "time": 1.3268}
{"mode": "train", "epoch": 3, "iter": 50, "lr": 0.0, "memory": 8608, "data_time": 0.21802, "stage0_loss_cls": 1.65543, "stage0_pos_acc": 55.25, "stage0_loss_bbox": 0.47961, "stage0_loss_iou": 0.77791, "stage0_loss_global": 0.5045, "stage0_loss_mask": 2.2818, "stage1_loss_cls": 1.84212, "stage1_pos_acc": 50.5, "stage1_loss_bbox": 0.31506, "stage1_loss_iou": 0.55459, "stage1_loss_global": 0.56701, "stage1_loss_mask": 1.8899, "stage2_loss_cls": 1.72854, "stage2_pos_acc": 62.0, "stage2_loss_bbox": 0.30719, "stage2_loss_iou": 0.53903, "stage2_loss_global": 0.52398, "stage2_loss_mask": 1.49705, "stage3_loss_cls": 1.70176, "stage3_pos_acc": 63.75, "stage3_loss_bbox": 0.31645, "stage3_loss_iou": 0.54394, "stage3_loss_global": 0.51172, "stage3_loss_mask": 3.12149, "stage4_loss_cls": 1.44277, "stage4_pos_acc": 54.0, "stage4_loss_bbox": 0.31718, "stage4_loss_iou": 0.53845, "stage4_loss_global": 0.49579, "stage4_loss_mask": 1.74796, "stage5_loss_cls": 1.40675, "stage5_pos_acc": 56.0, "stage5_loss_bbox": 0.31031, "stage5_loss_iou": 0.52802, "stage5_loss_global": 0.49378, "stage5_loss_mask": 2.69376, "loss": 31.63385, "grad_norm": 163.20831, "time": 1.36114}
{"mode": "train", "epoch": 4, "iter": 50, "lr": 1e-05, "memory": 8608, "data_time": 0.22225, "stage0_loss_cls": 1.34276, "stage0_pos_acc": 61.0, "stage0_loss_bbox": 0.44227, "stage0_loss_iou": 0.73345, "stage0_loss_global": 0.46724, "stage0_loss_mask": 1.88942, "stage1_loss_cls": 1.45828, "stage1_pos_acc": 55.25, "stage1_loss_bbox": 0.27929, "stage1_loss_iou": 0.48425, "stage1_loss_global": 0.47746, "stage1_loss_mask": 1.52309, "stage2_loss_cls": 1.29415, "stage2_pos_acc": 63.0, "stage2_loss_bbox": 0.25963, "stage2_loss_iou": 0.45486, "stage2_loss_global": 0.46789, "stage2_loss_mask": 1.18357, "stage3_loss_cls": 1.36623, "stage3_pos_acc": 74.25, "stage3_loss_bbox": 0.27397, "stage3_loss_iou": 0.47599, "stage3_loss_global": 0.45697, "stage3_loss_mask": 2.55863, "stage4_loss_cls": 1.17665, "stage4_pos_acc": 68.25, "stage4_loss_bbox": 0.26091, "stage4_loss_iou": 0.45572, "stage4_loss_global": 0.46082, "stage4_loss_mask": 1.4026, "stage5_loss_cls": 1.14921, "stage5_pos_acc": 62.0, "stage5_loss_bbox": 0.25834, "stage5_loss_iou": 0.45037, "stage5_loss_global": 0.44899, "stage5_loss_mask": 2.25273, "loss": 26.20572, "grad_norm": 133.37731, "time": 1.33735}
{"mode": "train", "epoch": 5, "iter": 50, "lr": 1e-05, "memory": 8608, "data_time": 0.21576, "stage0_loss_cls": 1.23358, "stage0_pos_acc": 65.25, "stage0_loss_bbox": 0.3982, "stage0_loss_iou": 0.68054, "stage0_loss_global": 0.45359, "stage0_loss_mask": 1.60723, "stage1_loss_cls": 1.2576, "stage1_pos_acc": 64.5, "stage1_loss_bbox": 0.23254, "stage1_loss_iou": 0.42077, "stage1_loss_global": 0.45367, "stage1_loss_mask": 1.26366, "stage2_loss_cls": 1.12239, "stage2_pos_acc": 65.25, "stage2_loss_bbox": 0.23024, "stage2_loss_iou": 0.4113, "stage2_loss_global": 0.45987, "stage2_loss_mask": 1.01824, "stage3_loss_cls": 1.09328, "stage3_pos_acc": 85.25, "stage3_loss_bbox": 0.24725, "stage3_loss_iou": 0.43473, "stage3_loss_global": 0.4467, "stage3_loss_mask": 2.08571, "stage4_loss_cls": 0.94302, "stage4_pos_acc": 77.25, "stage4_loss_bbox": 0.2415, "stage4_loss_iou": 0.42464, "stage4_loss_global": 0.44851, "stage4_loss_mask": 1.18091, "stage5_loss_cls": 0.93566, "stage5_pos_acc": 75.0, "stage5_loss_bbox": 0.23761, "stage5_loss_iou": 0.42211, "stage5_loss_global": 0.44324, "stage5_loss_mask": 1.83361, "loss": 22.66192, "grad_norm": 128.72721, "time": 1.33395}
{"mode": "train", "epoch": 6, "iter": 50, "lr": 1e-05, "memory": 8608, "data_time": 0.21953, "stage0_loss_cls": 1.13748, "stage0_pos_acc": 65.25, "stage0_loss_bbox": 0.38493, "stage0_loss_iou": 0.65362, "stage0_loss_global": 0.43956, "stage0_loss_mask": 1.34333, "stage1_loss_cls": 1.10974, "stage1_pos_acc": 67.0, "stage1_loss_bbox": 0.2239, "stage1_loss_iou": 0.39552, "stage1_loss_global": 0.4443, "stage1_loss_mask": 1.05951, "stage2_loss_cls": 0.94908, "stage2_pos_acc": 67.0, "stage2_loss_bbox": 0.23297, "stage2_loss_iou": 0.40674, "stage2_loss_global": 0.44418, "stage2_loss_mask": 0.86462, "stage3_loss_cls": 0.88888, "stage3_pos_acc": 94.0, "stage3_loss_bbox": 0.24163, "stage3_loss_iou": 0.41442, "stage3_loss_global": 0.43808, "stage3_loss_mask": 1.69071, "stage4_loss_cls": 0.74401, "stage4_pos_acc": 83.25, "stage4_loss_bbox": 0.24558, "stage4_loss_iou": 0.41841, "stage4_loss_global": 0.43571, "stage4_loss_mask": 1.00724, "stage5_loss_cls": 0.72758, "stage5_pos_acc": 71.5, "stage5_loss_bbox": 0.247, "stage5_loss_iou": 0.42369, "stage5_loss_global": 0.42337, "stage5_loss_mask": 1.50738, "loss": 19.94319, "grad_norm": 126.62249, "time": 1.33341}
{"mode": "train", "epoch": 7, "iter": 50, "lr": 1e-05, "memory": 8635, "data_time": 0.21387, "stage0_loss_cls": 1.08613, "stage0_pos_acc": 62.25, "stage0_loss_bbox": 0.34306, "stage0_loss_iou": 0.59775, "stage0_loss_global": 0.44676, "stage0_loss_mask": 1.14341, "stage1_loss_cls": 0.99906, "stage1_pos_acc": 70.25, "stage1_loss_bbox": 0.21013, "stage1_loss_iou": 0.37863, "stage1_loss_global": 0.44182, "stage1_loss_mask": 0.89649, "stage2_loss_cls": 0.75529, "stage2_pos_acc": 64.25, "stage2_loss_bbox": 0.23103, "stage2_loss_iou": 0.41581, "stage2_loss_global": 0.44644, "stage2_loss_mask": 0.77524, "stage3_loss_cls": 0.76848, "stage3_pos_acc": 97.5, "stage3_loss_bbox": 0.23225, "stage3_loss_iou": 0.40451, "stage3_loss_global": 0.44175, "stage3_loss_mask": 1.37278, "stage4_loss_cls": 0.63379, "stage4_pos_acc": 73.5, "stage4_loss_bbox": 0.24109, "stage4_loss_iou": 0.42341, "stage4_loss_global": 0.43962, "stage4_loss_mask": 0.90114, "stage5_loss_cls": 0.56322, "stage5_pos_acc": 69.25, "stage5_loss_bbox": 0.25234, "stage5_loss_iou": 0.44105, "stage5_loss_global": 0.43788, "stage5_loss_mask": 1.27912, "loss": 17.9995, "grad_norm": 160.33322, "time": 1.32594}
{"mode": "train", "epoch": 8, "iter": 50, "lr": 1e-05, "memory": 8635, "data_time": 0.22021, "stage0_loss_cls": 0.98598, "stage0_pos_acc": 71.5, "stage0_loss_bbox": 0.32857, "stage0_loss_iou": 0.57275, "stage0_loss_global": 0.45012, "stage0_loss_mask": 0.99766, "stage1_loss_cls": 0.88723, "stage1_pos_acc": 71.0, "stage1_loss_bbox": 0.21746, "stage1_loss_iou": 0.39327, "stage1_loss_global": 0.44099, "stage1_loss_mask": 0.79107, "stage2_loss_cls": 0.64722, "stage2_pos_acc": 67.75, "stage2_loss_bbox": 0.23756, "stage2_loss_iou": 0.42245, "stage2_loss_global": 0.42909, "stage2_loss_mask": 0.70948, "stage3_loss_cls": 0.70077, "stage3_pos_acc": 96.75, "stage3_loss_bbox": 0.22404, "stage3_loss_iou": 0.39583, "stage3_loss_global": 0.42933, "stage3_loss_mask": 1.15387, "stage4_loss_cls": 0.52661, "stage4_pos_acc": 70.25, "stage4_loss_bbox": 0.23774, "stage4_loss_iou": 0.41751, "stage4_loss_global": 0.43226, "stage4_loss_mask": 0.80248, "stage5_loss_cls": 0.49369, "stage5_pos_acc": 69.25, "stage5_loss_bbox": 0.2431, "stage5_loss_iou": 0.42761, "stage5_loss_global": 0.45349, "stage5_loss_mask": 1.06624, "loss": 16.51549, "grad_norm": 131.98312, "time": 1.33786}
{"mode": "train", "epoch": 9, "iter": 50, "lr": 1e-05, "memory": 8635, "data_time": 0.21817, "stage0_loss_cls": 0.912, "stage0_pos_acc": 74.0, "stage0_loss_bbox": 0.31997, "stage0_loss_iou": 0.55875, "stage0_loss_global": 0.42958, "stage0_loss_mask": 0.87696, "stage1_loss_cls": 0.82086, "stage1_pos_acc": 76.0, "stage1_loss_bbox": 0.22008, "stage1_loss_iou": 0.38595, "stage1_loss_global": 0.41029, "stage1_loss_mask": 0.71259, "stage2_loss_cls": 0.56727, "stage2_pos_acc": 75.75, "stage2_loss_bbox": 0.23114, "stage2_loss_iou": 0.40767, "stage2_loss_global": 0.37547, "stage2_loss_mask": 0.6574, "stage3_loss_cls": 0.59671, "stage3_pos_acc": 95.25, "stage3_loss_bbox": 0.23075, "stage3_loss_iou": 0.39947, "stage3_loss_global": 0.37453, "stage3_loss_mask": 0.97501, "stage4_loss_cls": 0.45587, "stage4_pos_acc": 72.75, "stage4_loss_bbox": 0.24187, "stage4_loss_iou": 0.42064, "stage4_loss_global": 0.36433, "stage4_loss_mask": 0.71196, "stage5_loss_cls": 0.43422, "stage5_pos_acc": 77.5, "stage5_loss_bbox": 0.24505, "stage5_loss_iou": 0.42517, "stage5_loss_global": 0.36331, "stage5_loss_mask": 0.90413, "loss": 15.02899, "grad_norm": 153.59075, "time": 1.32604}
{"mode": "train", "epoch": 10, "iter": 50, "lr": 1e-05, "memory": 8635, "data_time": 0.21794, "stage0_loss_cls": 0.87815, "stage0_pos_acc": 77.0, "stage0_loss_bbox": 0.31463, "stage0_loss_iou": 0.54778, "stage0_loss_global": 0.38879, "stage0_loss_mask": 0.77343, "stage1_loss_cls": 0.74371, "stage1_pos_acc": 76.5, "stage1_loss_bbox": 0.21509, "stage1_loss_iou": 0.38606, "stage1_loss_global": 0.33883, "stage1_loss_mask": 0.67168, "stage2_loss_cls": 0.49897, "stage2_pos_acc": 80.0, "stage2_loss_bbox": 0.23042, "stage2_loss_iou": 0.40619, "stage2_loss_global": 0.30013, "stage2_loss_mask": 0.62985, "stage3_loss_cls": 0.52161, "stage3_pos_acc": 97.75, "stage3_loss_bbox": 0.22454, "stage3_loss_iou": 0.38982, "stage3_loss_global": 0.29453, "stage3_loss_mask": 0.86165, "stage4_loss_cls": 0.39109, "stage4_pos_acc": 80.5, "stage4_loss_bbox": 0.23626, "stage4_loss_iou": 0.41262, "stage4_loss_global": 0.29607, "stage4_loss_mask": 0.67847, "stage5_loss_cls": 0.36276, "stage5_pos_acc": 84.5, "stage5_loss_bbox": 0.24163, "stage5_loss_iou": 0.41518, "stage5_loss_global": 0.28997, "stage5_loss_mask": 0.81246, "loss": 13.75236, "grad_norm": 205.43665, "time": 1.34209}
{"mode": "train", "epoch": 11, "iter": 50, "lr": 1e-05, "memory": 8635, "data_time": 0.2195, "stage0_loss_cls": 0.81614, "stage0_pos_acc": 86.5, "stage0_loss_bbox": 0.31329, "stage0_loss_iou": 0.55688, "stage0_loss_global": 0.31619, "stage0_loss_mask": 0.75835, "stage1_loss_cls": 0.66239, "stage1_pos_acc": 84.5, "stage1_loss_bbox": 0.22409, "stage1_loss_iou": 0.39833, "stage1_loss_global": 0.28455, "stage1_loss_mask": 0.63751, "stage2_loss_cls": 0.44271, "stage2_pos_acc": 86.5, "stage2_loss_bbox": 0.23257, "stage2_loss_iou": 0.41254, "stage2_loss_global": 0.27503, "stage2_loss_mask": 0.59961, "stage3_loss_cls": 0.47392, "stage3_pos_acc": 97.5, "stage3_loss_bbox": 0.22251, "stage3_loss_iou": 0.39154, "stage3_loss_global": 0.26432, "stage3_loss_mask": 0.79271, "stage4_loss_cls": 0.33798, "stage4_pos_acc": 86.0, "stage4_loss_bbox": 0.23792, "stage4_loss_iou": 0.41319, "stage4_loss_global": 0.25997, "stage4_loss_mask": 0.64632, "stage5_loss_cls": 0.33354, "stage5_pos_acc": 88.0, "stage5_loss_bbox": 0.23769, "stage5_loss_iou": 0.41044, "stage5_loss_global": 0.25967, "stage5_loss_mask": 0.76288, "loss": 12.97477, "grad_norm": 272.09235, "time": 1.34553}
{"mode": "train", "epoch": 12, "iter": 50, "lr": 2e-05, "memory": 8635, "data_time": 0.22055, "stage0_loss_cls": 0.76575, "stage0_pos_acc": 88.75, "stage0_loss_bbox": 0.31059, "stage0_loss_iou": 0.54233, "stage0_loss_global": 0.216, "stage0_loss_mask": 0.72204, "stage1_loss_cls": 0.58386, "stage1_pos_acc": 89.25, "stage1_loss_bbox": 0.24231, "stage1_loss_iou": 0.41203, "stage1_loss_global": 0.17562, "stage1_loss_mask": 0.63409, "stage2_loss_cls": 0.40352, "stage2_pos_acc": 89.25, "stage2_loss_bbox": 0.24087, "stage2_loss_iou": 0.41257, "stage2_loss_global": 0.15773, "stage2_loss_mask": 0.59872, "stage3_loss_cls": 0.41579, "stage3_pos_acc": 96.75, "stage3_loss_bbox": 0.23665, "stage3_loss_iou": 0.40091, "stage3_loss_global": 0.15245, "stage3_loss_mask": 0.75647, "stage4_loss_cls": 0.29614, "stage4_pos_acc": 91.25, "stage4_loss_bbox": 0.24775, "stage4_loss_iou": 0.41447, "stage4_loss_global": 0.15008, "stage4_loss_mask": 0.61346, "stage5_loss_cls": 0.2753, "stage5_pos_acc": 90.75, "stage5_loss_bbox": 0.255, "stage5_loss_iou": 0.42211, "stage5_loss_global": 0.14845, "stage5_loss_mask": 0.70909, "loss": 11.91214, "grad_norm": 239.35174, "time": 1.34294}
{"mode": "train", "epoch": 13, "iter": 50, "lr": 2e-05, "memory": 8635, "data_time": 0.2199, "stage0_loss_cls": 0.76816, "stage0_pos_acc": 84.0, "stage0_loss_bbox": 0.31144, "stage0_loss_iou": 0.54273, "stage0_loss_global": 0.24895, "stage0_loss_mask": 0.68077, "stage1_loss_cls": 0.58069, "stage1_pos_acc": 83.75, "stage1_loss_bbox": 0.22832, "stage1_loss_iou": 0.40659, "stage1_loss_global": 0.25726, "stage1_loss_mask": 0.61793, "stage2_loss_cls": 0.40944, "stage2_pos_acc": 83.75, "stage2_loss_bbox": 0.22605, "stage2_loss_iou": 0.40127, "stage2_loss_global": 0.26397, "stage2_loss_mask": 0.58836, "stage3_loss_cls": 0.43066, "stage3_pos_acc": 92.0, "stage3_loss_bbox": 0.22193, "stage3_loss_iou": 0.3891, "stage3_loss_global": 0.2787, "stage3_loss_mask": 0.71455, "stage4_loss_cls": 0.32763, "stage4_pos_acc": 86.0, "stage4_loss_bbox": 0.22649, "stage4_loss_iou": 0.39547, "stage4_loss_global": 0.28051, "stage4_loss_mask": 0.60808, "stage5_loss_cls": 0.32394, "stage5_pos_acc": 86.75, "stage5_loss_bbox": 0.227, "stage5_loss_iou": 0.39615, "stage5_loss_global": 0.28402, "stage5_loss_mask": 0.68193, "loss": 12.31808, "grad_norm": 339.11419, "time": 1.34947}
{"mode": "train", "epoch": 14, "iter": 50, "lr": 2e-05, "memory": 8635, "data_time": 0.22664, "stage0_loss_cls": 0.70312, "stage0_pos_acc": 93.0, "stage0_loss_bbox": 0.32487, "stage0_loss_iou": 0.57937, "stage0_loss_global": 0.14864, "stage0_loss_mask": 0.67949, "stage1_loss_cls": 0.51709, "stage1_pos_acc": 91.75, "stage1_loss_bbox": 0.23269, "stage1_loss_iou": 0.41375, "stage1_loss_global": 0.13394, "stage1_loss_mask": 0.61173, "stage2_loss_cls": 0.35129, "stage2_pos_acc": 92.0, "stage2_loss_bbox": 0.22909, "stage2_loss_iou": 0.409, "stage2_loss_global": 0.13232, "stage2_loss_mask": 0.58184, "stage3_loss_cls": 0.35257, "stage3_pos_acc": 95.5, "stage3_loss_bbox": 0.22437, "stage3_loss_iou": 0.40388, "stage3_loss_global": 0.13225, "stage3_loss_mask": 0.67959, "stage4_loss_cls": 0.27092, "stage4_pos_acc": 93.5, "stage4_loss_bbox": 0.22959, "stage4_loss_iou": 0.40733, "stage4_loss_global": 0.13294, "stage4_loss_mask": 0.58606, "stage5_loss_cls": 0.24831, "stage5_pos_acc": 93.0, "stage5_loss_bbox": 0.23287, "stage5_loss_iou": 0.40898, "stage5_loss_global": 0.13404, "stage5_loss_mask": 0.65365, "loss": 11.14559, "grad_norm": 256.10773, "time": 1.36068}
{"mode": "train", "epoch": 15, "iter": 50, "lr": 2e-05, "memory": 8635, "data_time": 0.21648, "stage0_loss_cls": 0.70655, "stage0_pos_acc": 92.75, "stage0_loss_bbox": 0.31492, "stage0_loss_iou": 0.5542, "stage0_loss_global": 0.19079, "stage0_loss_mask": 0.65661, "stage1_loss_cls": 0.5249, "stage1_pos_acc": 91.0, "stage1_loss_bbox": 0.22806, "stage1_loss_iou": 0.40361, "stage1_loss_global": 0.19169, "stage1_loss_mask": 0.58051, "stage2_loss_cls": 0.34572, "stage2_pos_acc": 90.25, "stage2_loss_bbox": 0.23093, "stage2_loss_iou": 0.40288, "stage2_loss_global": 0.18914, "stage2_loss_mask": 0.5838, "stage3_loss_cls": 0.32589, "stage3_pos_acc": 92.25, "stage3_loss_bbox": 0.22753, "stage3_loss_iou": 0.39726, "stage3_loss_global": 0.19152, "stage3_loss_mask": 0.65043, "stage4_loss_cls": 0.27316, "stage4_pos_acc": 92.25, "stage4_loss_bbox": 0.22886, "stage4_loss_iou": 0.39855, "stage4_loss_global": 0.19248, "stage4_loss_mask": 0.57952, "stage5_loss_cls": 0.25496, "stage5_pos_acc": 92.0, "stage5_loss_bbox": 0.2339, "stage5_loss_iou": 0.40316, "stage5_loss_global": 0.19854, "stage5_loss_mask": 0.63422, "loss": 11.29431, "grad_norm": 213.44412, "time": 1.33048}
{"mode": "train", "epoch": 16, "iter": 50, "lr": 2e-05, "memory": 8635, "data_time": 0.21791, "stage0_loss_cls": 0.693, "stage0_pos_acc": 94.0, "stage0_loss_bbox": 0.30777, "stage0_loss_iou": 0.54141, "stage0_loss_global": 0.1022, "stage0_loss_mask": 0.59721, "stage1_loss_cls": 0.46513, "stage1_pos_acc": 94.25, "stage1_loss_bbox": 0.22276, "stage1_loss_iou": 0.39391, "stage1_loss_global": 0.09641, "stage1_loss_mask": 0.55788, "stage2_loss_cls": 0.29233, "stage2_pos_acc": 96.25, "stage2_loss_bbox": 0.22178, "stage2_loss_iou": 0.38777, "stage2_loss_global": 0.09131, "stage2_loss_mask": 0.54766, "stage3_loss_cls": 0.25208, "stage3_pos_acc": 97.25, "stage3_loss_bbox": 0.22441, "stage3_loss_iou": 0.38783, "stage3_loss_global": 0.095, "stage3_loss_mask": 0.61843, "stage4_loss_cls": 0.23597, "stage4_pos_acc": 97.0, "stage4_loss_bbox": 0.21964, "stage4_loss_iou": 0.38195, "stage4_loss_global": 0.09001, "stage4_loss_mask": 0.56312, "stage5_loss_cls": 0.2232, "stage5_pos_acc": 96.0, "stage5_loss_bbox": 0.22313, "stage5_loss_iou": 0.38636, "stage5_loss_global": 0.088, "stage5_loss_mask": 0.61094, "loss": 10.11861, "grad_norm": 177.51639, "time": 1.34805}
{"mode": "train", "epoch": 17, "iter": 50, "lr": 2e-05, "memory": 8635, "data_time": 0.21741, "stage0_loss_cls": 0.65388, "stage0_pos_acc": 92.5, "stage0_loss_bbox": 0.30901, "stage0_loss_iou": 0.53691, "stage0_loss_global": 0.12628, "stage0_loss_mask": 0.58658, "stage1_loss_cls": 0.44937, "stage1_pos_acc": 92.25, "stage1_loss_bbox": 0.22409, "stage1_loss_iou": 0.38787, "stage1_loss_global": 0.12806, "stage1_loss_mask": 0.54068, "stage2_loss_cls": 0.27904, "stage2_pos_acc": 92.0, "stage2_loss_bbox": 0.2248, "stage2_loss_iou": 0.38593, "stage2_loss_global": 0.13784, "stage2_loss_mask": 0.53231, "stage3_loss_cls": 0.24674, "stage3_pos_acc": 90.25, "stage3_loss_bbox": 0.22303, "stage3_loss_iou": 0.38425, "stage3_loss_global": 0.13603, "stage3_loss_mask": 0.58744, "stage4_loss_cls": 0.21565, "stage4_pos_acc": 92.5, "stage4_loss_bbox": 0.22067, "stage4_loss_iou": 0.38121, "stage4_loss_global": 0.1493, "stage4_loss_mask": 0.54598, "stage5_loss_cls": 0.21142, "stage5_pos_acc": 93.25, "stage5_loss_bbox": 0.22421, "stage5_loss_iou": 0.38377, "stage5_loss_global": 0.15343, "stage5_loss_mask": 0.58068, "loss": 10.14646, "grad_norm": 286.86397, "time": 1.35455}
{"mode": "train", "epoch": 18, "iter": 50, "lr": 2e-05, "memory": 8635, "data_time": 0.21875, "stage0_loss_cls": 0.6466, "stage0_pos_acc": 95.75, "stage0_loss_bbox": 0.3117, "stage0_loss_iou": 0.55829, "stage0_loss_global": 0.08413, "stage0_loss_mask": 0.60952, "stage1_loss_cls": 0.4283, "stage1_pos_acc": 95.5, "stage1_loss_bbox": 0.22258, "stage1_loss_iou": 0.3911, "stage1_loss_global": 0.08312, "stage1_loss_mask": 0.5374, "stage2_loss_cls": 0.2655, "stage2_pos_acc": 96.25, "stage2_loss_bbox": 0.21523, "stage2_loss_iou": 0.38017, "stage2_loss_global": 0.07889, "stage2_loss_mask": 0.53097, "stage3_loss_cls": 0.22991, "stage3_pos_acc": 96.75, "stage3_loss_bbox": 0.21785, "stage3_loss_iou": 0.38181, "stage3_loss_global": 0.0799, "stage3_loss_mask": 0.58565, "stage4_loss_cls": 0.22536, "stage4_pos_acc": 96.25, "stage4_loss_bbox": 0.21117, "stage4_loss_iou": 0.37069, "stage4_loss_global": 0.08296, "stage4_loss_mask": 0.52615, "stage5_loss_cls": 0.21941, "stage5_pos_acc": 95.75, "stage5_loss_bbox": 0.21108, "stage5_loss_iou": 0.37327, "stage5_loss_global": 0.08172, "stage5_loss_mask": 0.56143, "loss": 9.70186, "grad_norm": 193.86156, "time": 1.34703}
{"mode": "train", "epoch": 19, "iter": 50, "lr": 2e-05, "memory": 8635, "data_time": 0.22128, "stage0_loss_cls": 0.60004, "stage0_pos_acc": 93.5, "stage0_loss_bbox": 0.31913, "stage0_loss_iou": 0.56213, "stage0_loss_global": 0.1056, "stage0_loss_mask": 0.57889, "stage1_loss_cls": 0.41175, "stage1_pos_acc": 96.0, "stage1_loss_bbox": 0.22574, "stage1_loss_iou": 0.39764, "stage1_loss_global": 0.11017, "stage1_loss_mask": 0.55121, "stage2_loss_cls": 0.27003, "stage2_pos_acc": 95.25, "stage2_loss_bbox": 0.22775, "stage2_loss_iou": 0.39854, "stage2_loss_global": 0.10915, "stage2_loss_mask": 0.54432, "stage3_loss_cls": 0.23629, "stage3_pos_acc": 94.0, "stage3_loss_bbox": 0.22647, "stage3_loss_iou": 0.39658, "stage3_loss_global": 0.1131, "stage3_loss_mask": 0.59855, "stage4_loss_cls": 0.19837, "stage4_pos_acc": 94.0, "stage4_loss_bbox": 0.22973, "stage4_loss_iou": 0.39963, "stage4_loss_global": 0.11447, "stage4_loss_mask": 0.5696, "stage5_loss_cls": 0.18314, "stage5_pos_acc": 94.25, "stage5_loss_bbox": 0.23228, "stage5_loss_iou": 0.40194, "stage5_loss_global": 0.12088, "stage5_loss_mask": 0.58956, "loss": 10.02268, "grad_norm": 284.26178, "time": 1.33997}
{"mode": "train", "epoch": 20, "iter": 50, "lr": 3e-05, "memory": 8635, "data_time": 0.22031, "stage0_loss_cls": 0.55417, "stage0_pos_acc": 94.25, "stage0_loss_bbox": 0.33416, "stage0_loss_iou": 0.58426, "stage0_loss_global": 0.07348, "stage0_loss_mask": 0.59684, "stage1_loss_cls": 0.37472, "stage1_pos_acc": 95.25, "stage1_loss_bbox": 0.25236, "stage1_loss_iou": 0.4371, "stage1_loss_global": 0.07315, "stage1_loss_mask": 0.56487, "stage2_loss_cls": 0.23917, "stage2_pos_acc": 96.25, "stage2_loss_bbox": 0.23333, "stage2_loss_iou": 0.40696, "stage2_loss_global": 0.07421, "stage2_loss_mask": 0.54618, "stage3_loss_cls": 0.19152, "stage3_pos_acc": 96.5, "stage3_loss_bbox": 0.2265, "stage3_loss_iou": 0.39635, "stage3_loss_global": 0.07907, "stage3_loss_mask": 0.56888, "stage4_loss_cls": 0.17342, "stage4_pos_acc": 96.75, "stage4_loss_bbox": 0.22638, "stage4_loss_iou": 0.39518, "stage4_loss_global": 0.07808, "stage4_loss_mask": 0.54515, "stage5_loss_cls": 0.16445, "stage5_pos_acc": 96.25, "stage5_loss_bbox": 0.22716, "stage5_loss_iou": 0.39761, "stage5_loss_global": 0.0773, "stage5_loss_mask": 0.58672, "loss": 9.6787, "grad_norm": 218.90538, "time": 1.32855}
{"mode": "train", "epoch": 21, "iter": 50, "lr": 3e-05, "memory": 8635, "data_time": 0.21417, "stage0_loss_cls": 0.58212, "stage0_pos_acc": 94.25, "stage0_loss_bbox": 0.32136, "stage0_loss_iou": 0.56379, "stage0_loss_global": 0.07459, "stage0_loss_mask": 0.51292, "stage1_loss_cls": 0.35616, "stage1_pos_acc": 96.0, "stage1_loss_bbox": 0.24162, "stage1_loss_iou": 0.4076, "stage1_loss_global": 0.07636, "stage1_loss_mask": 0.52566, "stage2_loss_cls": 0.21226, "stage2_pos_acc": 96.5, "stage2_loss_bbox": 0.23535, "stage2_loss_iou": 0.39424, "stage2_loss_global": 0.07197, "stage2_loss_mask": 0.52515, "stage3_loss_cls": 0.1955, "stage3_pos_acc": 96.25, "stage3_loss_bbox": 0.23201, "stage3_loss_iou": 0.3897, "stage3_loss_global": 0.07198, "stage3_loss_mask": 0.55376, "stage4_loss_cls": 0.16889, "stage4_pos_acc": 97.5, "stage4_loss_bbox": 0.23024, "stage4_loss_iou": 0.38621, "stage4_loss_global": 0.06927, "stage4_loss_mask": 0.51845, "stage5_loss_cls": 0.15966, "stage5_pos_acc": 97.75, "stage5_loss_bbox": 0.2298, "stage5_loss_iou": 0.38645, "stage5_loss_global": 0.07183, "stage5_loss_mask": 0.54017, "loss": 9.30505, "grad_norm": 231.84375, "time": 1.34805}
{"mode": "train", "epoch": 22, "iter": 50, "lr": 3e-05, "memory": 8635, "data_time": 0.22265, "stage0_loss_cls": 0.53604, "stage0_pos_acc": 95.5, "stage0_loss_bbox": 0.3231, "stage0_loss_iou": 0.57278, "stage0_loss_global": 0.11268, "stage0_loss_mask": 0.57381, "stage1_loss_cls": 0.33957, "stage1_pos_acc": 95.25, "stage1_loss_bbox": 0.23528, "stage1_loss_iou": 0.41265, "stage1_loss_global": 0.11825, "stage1_loss_mask": 0.53777, "stage2_loss_cls": 0.2312, "stage2_pos_acc": 95.25, "stage2_loss_bbox": 0.24013, "stage2_loss_iou": 0.41198, "stage2_loss_global": 0.11728, "stage2_loss_mask": 0.54518, "stage3_loss_cls": 0.21265, "stage3_pos_acc": 95.0, "stage3_loss_bbox": 0.23719, "stage3_loss_iou": 0.40862, "stage3_loss_global": 0.12254, "stage3_loss_mask": 0.56801, "stage4_loss_cls": 0.18073, "stage4_pos_acc": 95.5, "stage4_loss_bbox": 0.23737, "stage4_loss_iou": 0.40693, "stage4_loss_global": 0.12228, "stage4_loss_mask": 0.57452, "stage5_loss_cls": 0.16957, "stage5_pos_acc": 95.25, "stage5_loss_bbox": 0.24065, "stage5_loss_iou": 0.41207, "stage5_loss_global": 0.13743, "stage5_loss_mask": 0.59477, "loss": 9.93299, "grad_norm": 640.05702, "time": 1.34057}
{"mode": "train", "epoch": 23, "iter": 50, "lr": 3e-05, "memory": 8635, "data_time": 0.22039, "stage0_loss_cls": 0.5046, "stage0_pos_acc": 96.0, "stage0_loss_bbox": 0.3264, "stage0_loss_iou": 0.57193, "stage0_loss_global": 0.09378, "stage0_loss_mask": 0.51414, "stage1_loss_cls": 0.34549, "stage1_pos_acc": 96.75, "stage1_loss_bbox": 0.22335, "stage1_loss_iou": 0.3955, "stage1_loss_global": 0.09365, "stage1_loss_mask": 0.49904, "stage2_loss_cls": 0.21819, "stage2_pos_acc": 97.25, "stage2_loss_bbox": 0.22024, "stage2_loss_iou": 0.38459, "stage2_loss_global": 0.08766, "stage2_loss_mask": 0.50155, "stage3_loss_cls": 0.1852, "stage3_pos_acc": 96.75, "stage3_loss_bbox": 0.21526, "stage3_loss_iou": 0.37503, "stage3_loss_global": 0.08171, "stage3_loss_mask": 0.51484, "stage4_loss_cls": 0.15699, "stage4_pos_acc": 96.5, "stage4_loss_bbox": 0.22215, "stage4_loss_iou": 0.38196, "stage4_loss_global": 0.0827, "stage4_loss_mask": 0.51742, "stage5_loss_cls": 0.15416, "stage5_pos_acc": 97.25, "stage5_loss_bbox": 0.21818, "stage5_loss_iou": 0.37908, "stage5_loss_global": 0.08559, "stage5_loss_mask": 0.53181, "loss": 9.08219, "grad_norm": 442.65652, "time": 1.33549}
{"mode": "train", "epoch": 24, "iter": 50, "lr": 3e-05, "memory": 8635, "data_time": 0.21944, "stage0_loss_cls": 0.4792, "stage0_pos_acc": 95.25, "stage0_loss_bbox": 0.33557, "stage0_loss_iou": 0.59228, "stage0_loss_global": 0.08672, "stage0_loss_mask": 0.54658, "stage1_loss_cls": 0.34707, "stage1_pos_acc": 96.75, "stage1_loss_bbox": 0.21616, "stage1_loss_iou": 0.38351, "stage1_loss_global": 0.08645, "stage1_loss_mask": 0.48979, "stage2_loss_cls": 0.15979, "stage2_pos_acc": 96.75, "stage2_loss_bbox": 0.2229, "stage2_loss_iou": 0.38425, "stage2_loss_global": 0.07878, "stage2_loss_mask": 0.50704, "stage3_loss_cls": 0.12914, "stage3_pos_acc": 97.0, "stage3_loss_bbox": 0.21725, "stage3_loss_iou": 0.3765, "stage3_loss_global": 0.07562, "stage3_loss_mask": 0.52078, "stage4_loss_cls": 0.1272, "stage4_pos_acc": 96.75, "stage4_loss_bbox": 0.21466, "stage4_loss_iou": 0.37223, "stage4_loss_global": 0.07062, "stage4_loss_mask": 0.49704, "stage5_loss_cls": 0.11909, "stage5_pos_acc": 96.25, "stage5_loss_bbox": 0.21601, "stage5_loss_iou": 0.37354, "stage5_loss_global": 0.07074, "stage5_loss_mask": 0.5093, "loss": 8.80581, "grad_norm": 322.74583, "time": 1.326}
{"mode": "train", "epoch": 25, "iter": 50, "lr": 3e-05, "memory": 8635, "data_time": 0.22312, "stage0_loss_cls": 0.43111, "stage0_pos_acc": 94.75, "stage0_loss_bbox": 0.31215, "stage0_loss_iou": 0.53899, "stage0_loss_global": 0.06604, "stage0_loss_mask": 0.52792, "stage1_loss_cls": 0.26884, "stage1_pos_acc": 97.25, "stage1_loss_bbox": 0.23076, "stage1_loss_iou": 0.39046, "stage1_loss_global": 0.06539, "stage1_loss_mask": 0.49898, "stage2_loss_cls": 0.18172, "stage2_pos_acc": 96.25, "stage2_loss_bbox": 0.21932, "stage2_loss_iou": 0.37502, "stage2_loss_global": 0.06797, "stage2_loss_mask": 0.49489, "stage3_loss_cls": 0.13613, "stage3_pos_acc": 96.75, "stage3_loss_bbox": 0.21727, "stage3_loss_iou": 0.37094, "stage3_loss_global": 0.0663, "stage3_loss_mask": 0.51218, "stage4_loss_cls": 0.12067, "stage4_pos_acc": 97.25, "stage4_loss_bbox": 0.21707, "stage4_loss_iou": 0.3698, "stage4_loss_global": 0.07203, "stage4_loss_mask": 0.4922, "stage5_loss_cls": 0.1186, "stage5_pos_acc": 97.0, "stage5_loss_bbox": 0.21848, "stage5_loss_iou": 0.36978, "stage5_loss_global": 0.07372, "stage5_loss_mask": 0.50565, "loss": 8.53039, "grad_norm": 215.73161, "time": 1.33452}
{"mode": "train", "epoch": 26, "iter": 50, "lr": 3e-05, "memory": 8635, "data_time": 0.21829, "stage0_loss_cls": 0.41619, "stage0_pos_acc": 94.0, "stage0_loss_bbox": 0.33644, "stage0_loss_iou": 0.59193, "stage0_loss_global": 0.07727, "stage0_loss_mask": 0.54107, "stage1_loss_cls": 0.27097, "stage1_pos_acc": 98.0, "stage1_loss_bbox": 0.23375, "stage1_loss_iou": 0.40287, "stage1_loss_global": 0.07826, "stage1_loss_mask": 0.53318, "stage2_loss_cls": 0.17299, "stage2_pos_acc": 98.0, "stage2_loss_bbox": 0.22272, "stage2_loss_iou": 0.38465, "stage2_loss_global": 0.07873, "stage2_loss_mask": 0.51413, "stage3_loss_cls": 0.13557, "stage3_pos_acc": 97.5, "stage3_loss_bbox": 0.2249, "stage3_loss_iou": 0.38765, "stage3_loss_global": 0.07639, "stage3_loss_mask": 0.54108, "stage4_loss_cls": 0.12399, "stage4_pos_acc": 97.5, "stage4_loss_bbox": 0.22447, "stage4_loss_iou": 0.38889, "stage4_loss_global": 0.07749, "stage4_loss_mask": 0.52045, "stage5_loss_cls": 0.12531, "stage5_pos_acc": 97.75, "stage5_loss_bbox": 0.22273, "stage5_loss_iou": 0.38788, "stage5_loss_global": 0.08029, "stage5_loss_mask": 0.52549, "loss": 8.89775, "grad_norm": 183.80436, "time": 1.34904}
{"mode": "train", "epoch": 27, "iter": 50, "lr": 3e-05, "memory": 8635, "data_time": 0.21554, "stage0_loss_cls": 0.38615, "stage0_pos_acc": 93.0, "stage0_loss_bbox": 0.32353, "stage0_loss_iou": 0.58426, "stage0_loss_global": 0.10611, "stage0_loss_mask": 0.52842, "stage1_loss_cls": 0.25314, "stage1_pos_acc": 95.25, "stage1_loss_bbox": 0.22118, "stage1_loss_iou": 0.39065, "stage1_loss_global": 0.10482, "stage1_loss_mask": 0.5093, "stage2_loss_cls": 0.16388, "stage2_pos_acc": 95.5, "stage2_loss_bbox": 0.21443, "stage2_loss_iou": 0.37195, "stage2_loss_global": 0.10218, "stage2_loss_mask": 0.49024, "stage3_loss_cls": 0.1486, "stage3_pos_acc": 96.25, "stage3_loss_bbox": 0.21608, "stage3_loss_iou": 0.37442, "stage3_loss_global": 0.09636, "stage3_loss_mask": 0.49969, "stage4_loss_cls": 0.11833, "stage4_pos_acc": 95.25, "stage4_loss_bbox": 0.2216, "stage4_loss_iou": 0.37848, "stage4_loss_global": 0.09167, "stage4_loss_mask": 0.48976, "stage5_loss_cls": 0.12521, "stage5_pos_acc": 96.0, "stage5_loss_bbox": 0.22013, "stage5_loss_iou": 0.37598, "stage5_loss_global": 0.09272, "stage5_loss_mask": 0.50024, "loss": 8.69953, "grad_norm": 503.92334, "time": 1.32635}
{"mode": "train", "epoch": 28, "iter": 50, "lr": 0.0, "memory": 8635, "data_time": 0.21835, "stage0_loss_cls": 0.31009, "stage0_pos_acc": 97.5, "stage0_loss_bbox": 0.31042, "stage0_loss_iou": 0.55224, "stage0_loss_global": 0.04241, "stage0_loss_mask": 0.51385, "stage1_loss_cls": 0.22027, "stage1_pos_acc": 98.0, "stage1_loss_bbox": 0.22147, "stage1_loss_iou": 0.37997, "stage1_loss_global": 0.04542, "stage1_loss_mask": 0.50704, "stage2_loss_cls": 0.13569, "stage2_pos_acc": 97.0, "stage2_loss_bbox": 0.21037, "stage2_loss_iou": 0.3624, "stage2_loss_global": 0.04297, "stage2_loss_mask": 0.48384, "stage3_loss_cls": 0.097, "stage3_pos_acc": 98.25, "stage3_loss_bbox": 0.20651, "stage3_loss_iou": 0.35483, "stage3_loss_global": 0.04098, "stage3_loss_mask": 0.4876, "stage4_loss_cls": 0.07558, "stage4_pos_acc": 98.25, "stage4_loss_bbox": 0.20931, "stage4_loss_iou": 0.35667, "stage4_loss_global": 0.03989, "stage4_loss_mask": 0.48864, "stage5_loss_cls": 0.0724, "stage5_pos_acc": 98.5, "stage5_loss_bbox": 0.21101, "stage5_loss_iou": 0.35699, "stage5_loss_global": 0.04133, "stage5_loss_mask": 0.49366, "loss": 7.87085, "grad_norm": 127.59053, "time": 1.32167}
{"mode": "train", "epoch": 29, "iter": 50, "lr": 0.0, "memory": 8635, "data_time": 0.22123, "stage0_loss_cls": 0.32493, "stage0_pos_acc": 97.0, "stage0_loss_bbox": 0.28834, "stage0_loss_iou": 0.52165, "stage0_loss_global": 0.04375, "stage0_loss_mask": 0.49837, "stage1_loss_cls": 0.21272, "stage1_pos_acc": 98.25, "stage1_loss_bbox": 0.20786, "stage1_loss_iou": 0.36959, "stage1_loss_global": 0.04289, "stage1_loss_mask": 0.48801, "stage2_loss_cls": 0.13434, "stage2_pos_acc": 98.25, "stage2_loss_bbox": 0.19575, "stage2_loss_iou": 0.34852, "stage2_loss_global": 0.0382, "stage2_loss_mask": 0.46895, "stage3_loss_cls": 0.09781, "stage3_pos_acc": 98.75, "stage3_loss_bbox": 0.19449, "stage3_loss_iou": 0.34463, "stage3_loss_global": 0.03814, "stage3_loss_mask": 0.4815, "stage4_loss_cls": 0.09051, "stage4_pos_acc": 98.5, "stage4_loss_bbox": 0.19089, "stage4_loss_iou": 0.34029, "stage4_loss_global": 0.03608, "stage4_loss_mask": 0.46372, "stage5_loss_cls": 0.07615, "stage5_pos_acc": 98.5, "stage5_loss_bbox": 0.194, "stage5_loss_iou": 0.34172, "stage5_loss_global": 0.03809, "stage5_loss_mask": 0.47889, "loss": 7.59077, "grad_norm": 169.62624, "time": 1.33188}
{"mode": "train", "epoch": 30, "iter": 50, "lr": 0.0, "memory": 8635, "data_time": 0.21891, "stage0_loss_cls": 0.29145, "stage0_pos_acc": 99.0, "stage0_loss_bbox": 0.2859, "stage0_loss_iou": 0.51387, "stage0_loss_global": 0.0456, "stage0_loss_mask": 0.52214, "stage1_loss_cls": 0.19441, "stage1_pos_acc": 98.25, "stage1_loss_bbox": 0.21353, "stage1_loss_iou": 0.37864, "stage1_loss_global": 0.04233, "stage1_loss_mask": 0.49651, "stage2_loss_cls": 0.11134, "stage2_pos_acc": 98.25, "stage2_loss_bbox": 0.19584, "stage2_loss_iou": 0.35409, "stage2_loss_global": 0.03836, "stage2_loss_mask": 0.47447, "stage3_loss_cls": 0.08578, "stage3_pos_acc": 98.75, "stage3_loss_bbox": 0.1964, "stage3_loss_iou": 0.35277, "stage3_loss_global": 0.03271, "stage3_loss_mask": 0.48498, "stage4_loss_cls": 0.06722, "stage4_pos_acc": 98.75, "stage4_loss_bbox": 0.19626, "stage4_loss_iou": 0.35162, "stage4_loss_global": 0.02853, "stage4_loss_mask": 0.47582, "stage5_loss_cls": 0.06219, "stage5_pos_acc": 99.0, "stage5_loss_bbox": 0.19681, "stage5_loss_iou": 0.35146, "stage5_loss_global": 0.02703, "stage5_loss_mask": 0.48919, "loss": 7.55726, "grad_norm": 118.11478, "time": 1.34113}
{"mode": "train", "epoch": 31, "iter": 50, "lr": 0.0, "memory": 8635, "data_time": 0.21442, "stage0_loss_cls": 0.30538, "stage0_pos_acc": 97.75, "stage0_loss_bbox": 0.27198, "stage0_loss_iou": 0.49599, "stage0_loss_global": 0.03337, "stage0_loss_mask": 0.48535, "stage1_loss_cls": 0.1817, "stage1_pos_acc": 99.0, "stage1_loss_bbox": 0.2123, "stage1_loss_iou": 0.368, "stage1_loss_global": 0.03142, "stage1_loss_mask": 0.48456, "stage2_loss_cls": 0.09121, "stage2_pos_acc": 99.0, "stage2_loss_bbox": 0.2046, "stage2_loss_iou": 0.35235, "stage2_loss_global": 0.02899, "stage2_loss_mask": 0.47241, "stage3_loss_cls": 0.0612, "stage3_pos_acc": 99.0, "stage3_loss_bbox": 0.20468, "stage3_loss_iou": 0.34814, "stage3_loss_global": 0.02508, "stage3_loss_mask": 0.4858, "stage4_loss_cls": 0.05072, "stage4_pos_acc": 99.0, "stage4_loss_bbox": 0.20092, "stage4_loss_iou": 0.3437, "stage4_loss_global": 0.02278, "stage4_loss_mask": 0.47593, "stage5_loss_cls": 0.04159, "stage5_pos_acc": 99.25, "stage5_loss_bbox": 0.2024, "stage5_loss_iou": 0.34431, "stage5_loss_global": 0.02202, "stage5_loss_mask": 0.48895, "loss": 7.33783, "grad_norm": 116.29382, "time": 1.34945}
{"mode": "train", "epoch": 32, "iter": 50, "lr": 0.0, "memory": 8635, "data_time": 0.21852, "stage0_loss_cls": 0.3018, "stage0_pos_acc": 97.75, "stage0_loss_bbox": 0.28093, "stage0_loss_iou": 0.51067, "stage0_loss_global": 0.0561, "stage0_loss_mask": 0.50401, "stage1_loss_cls": 0.17806, "stage1_pos_acc": 98.75, "stage1_loss_bbox": 0.21777, "stage1_loss_iou": 0.38116, "stage1_loss_global": 0.05396, "stage1_loss_mask": 0.50102, "stage2_loss_cls": 0.11318, "stage2_pos_acc": 98.5, "stage2_loss_bbox": 0.20151, "stage2_loss_iou": 0.35582, "stage2_loss_global": 0.04677, "stage2_loss_mask": 0.48329, "stage3_loss_cls": 0.07442, "stage3_pos_acc": 99.0, "stage3_loss_bbox": 0.20751, "stage3_loss_iou": 0.3589, "stage3_loss_global": 0.0366, "stage3_loss_mask": 0.48862, "stage4_loss_cls": 0.05295, "stage4_pos_acc": 98.75, "stage4_loss_bbox": 0.20756, "stage4_loss_iou": 0.36331, "stage4_loss_global": 0.0318, "stage4_loss_mask": 0.50443, "stage5_loss_cls": 0.04937, "stage5_pos_acc": 99.25, "stage5_loss_bbox": 0.20755, "stage5_loss_iou": 0.36451, "stage5_loss_global": 0.03158, "stage5_loss_mask": 0.5149, "loss": 7.68005, "grad_norm": 122.7394, "time": 1.32638}
{"mode": "train", "epoch": 33, "iter": 50, "lr": 0.0, "memory": 8635, "data_time": 0.21938, "stage0_loss_cls": 0.27108, "stage0_pos_acc": 98.5, "stage0_loss_bbox": 0.26741, "stage0_loss_iou": 0.4827, "stage0_loss_global": 0.0519, "stage0_loss_mask": 0.47786, "stage1_loss_cls": 0.17098, "stage1_pos_acc": 98.75, "stage1_loss_bbox": 0.20438, "stage1_loss_iou": 0.35969, "stage1_loss_global": 0.05138, "stage1_loss_mask": 0.47334, "stage2_loss_cls": 0.10081, "stage2_pos_acc": 98.5, "stage2_loss_bbox": 0.18967, "stage2_loss_iou": 0.33828, "stage2_loss_global": 0.04665, "stage2_loss_mask": 0.4645, "stage3_loss_cls": 0.07279, "stage3_pos_acc": 98.5, "stage3_loss_bbox": 0.1885, "stage3_loss_iou": 0.33589, "stage3_loss_global": 0.04309, "stage3_loss_mask": 0.47682, "stage4_loss_cls": 0.05442, "stage4_pos_acc": 98.5, "stage4_loss_bbox": 0.19006, "stage4_loss_iou": 0.33751, "stage4_loss_global": 0.04065, "stage4_loss_mask": 0.47014, "stage5_loss_cls": 0.04295, "stage5_pos_acc": 98.5, "stage5_loss_bbox": 0.19163, "stage5_loss_iou": 0.33958, "stage5_loss_global": 0.03982, "stage5_loss_mask": 0.48957, "loss": 7.26406, "grad_norm": 119.25302, "time": 1.32472}
{"mode": "train", "epoch": 34, "iter": 50, "lr": 0.0, "memory": 8635, "data_time": 0.21985, "stage0_loss_cls": 0.26143, "stage0_pos_acc": 98.5, "stage0_loss_bbox": 0.26745, "stage0_loss_iou": 0.4941, "stage0_loss_global": 0.02773, "stage0_loss_mask": 0.48654, "stage1_loss_cls": 0.16409, "stage1_pos_acc": 99.25, "stage1_loss_bbox": 0.20048, "stage1_loss_iou": 0.3601, "stage1_loss_global": 0.02758, "stage1_loss_mask": 0.47396, "stage2_loss_cls": 0.08908, "stage2_pos_acc": 99.25, "stage2_loss_bbox": 0.18922, "stage2_loss_iou": 0.34033, "stage2_loss_global": 0.02493, "stage2_loss_mask": 0.46517, "stage3_loss_cls": 0.05545, "stage3_pos_acc": 99.5, "stage3_loss_bbox": 0.1898, "stage3_loss_iou": 0.33935, "stage3_loss_global": 0.02092, "stage3_loss_mask": 0.47507, "stage4_loss_cls": 0.04393, "stage4_pos_acc": 99.25, "stage4_loss_bbox": 0.18816, "stage4_loss_iou": 0.33697, "stage4_loss_global": 0.0188, "stage4_loss_mask": 0.45933, "stage5_loss_cls": 0.03624, "stage5_pos_acc": 99.5, "stage5_loss_bbox": 0.1871, "stage5_loss_iou": 0.33497, "stage5_loss_global": 0.01766, "stage5_loss_mask": 0.47219, "loss": 7.04816, "grad_norm": 111.19483, "time": 1.34724}
{"mode": "train", "epoch": 35, "iter": 50, "lr": 0.0, "memory": 8635, "data_time": 0.2141, "stage0_loss_cls": 0.26865, "stage0_pos_acc": 99.0, "stage0_loss_bbox": 0.26779, "stage0_loss_iou": 0.49212, "stage0_loss_global": 0.0321, "stage0_loss_mask": 0.48327, "stage1_loss_cls": 0.17347, "stage1_pos_acc": 99.0, "stage1_loss_bbox": 0.19425, "stage1_loss_iou": 0.34569, "stage1_loss_global": 0.02953, "stage1_loss_mask": 0.46478, "stage2_loss_cls": 0.09916, "stage2_pos_acc": 98.75, "stage2_loss_bbox": 0.18938, "stage2_loss_iou": 0.33592, "stage2_loss_global": 0.02726, "stage2_loss_mask": 0.44992, "stage3_loss_cls": 0.06893, "stage3_pos_acc": 99.25, "stage3_loss_bbox": 0.19022, "stage3_loss_iou": 0.33529, "stage3_loss_global": 0.02209, "stage3_loss_mask": 0.46577, "stage4_loss_cls": 0.05458, "stage4_pos_acc": 99.25, "stage4_loss_bbox": 0.1908, "stage4_loss_iou": 0.33399, "stage4_loss_global": 0.02169, "stage4_loss_mask": 0.46097, "stage5_loss_cls": 0.04097, "stage5_pos_acc": 99.25, "stage5_loss_bbox": 0.19468, "stage5_loss_iou": 0.33916, "stage5_loss_global": 0.02081, "stage5_loss_mask": 0.48357, "loss": 7.07684, "grad_norm": 286.22755, "time": 1.3166}
{"mode": "train", "epoch": 36, "iter": 50, "lr": 0.0, "memory": 8635, "data_time": 0.21931, "stage0_loss_cls": 0.27324, "stage0_pos_acc": 96.75, "stage0_loss_bbox": 0.26279, "stage0_loss_iou": 0.47908, "stage0_loss_global": 0.03521, "stage0_loss_mask": 0.46877, "stage1_loss_cls": 0.15122, "stage1_pos_acc": 99.25, "stage1_loss_bbox": 0.20963, "stage1_loss_iou": 0.36246, "stage1_loss_global": 0.03257, "stage1_loss_mask": 0.48592, "stage2_loss_cls": 0.09833, "stage2_pos_acc": 99.0, "stage2_loss_bbox": 0.19081, "stage2_loss_iou": 0.3353, "stage2_loss_global": 0.02877, "stage2_loss_mask": 0.46388, "stage3_loss_cls": 0.0588, "stage3_pos_acc": 99.25, "stage3_loss_bbox": 0.19343, "stage3_loss_iou": 0.33736, "stage3_loss_global": 0.02439, "stage3_loss_mask": 0.47386, "stage4_loss_cls": 0.04821, "stage4_pos_acc": 99.0, "stage4_loss_bbox": 0.1922, "stage4_loss_iou": 0.33604, "stage4_loss_global": 0.02364, "stage4_loss_mask": 0.46773, "stage5_loss_cls": 0.04024, "stage5_pos_acc": 99.0, "stage5_loss_bbox": 0.19106, "stage5_loss_iou": 0.33448, "stage5_loss_global": 0.02273, "stage5_loss_mask": 0.475, "loss": 7.09717, "grad_norm": 109.26653, "time": 1.32657}
