2021-12-29 14:28:34,691 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.10 (default, Jun  4 2021, 15:09:15) [GCC 7.5.0]
CUDA available: True
GPU 0,1,2,3: NVIDIA TITAN Xp
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 10.2, V10.2.89
GCC: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
PyTorch: 1.7.0
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.8.1
OpenCV: 4.5.3
MMCV: 1.3.18
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 10.2
MMDetection: 2.12.0+170db93
------------------------------------------------------------

2021-12-29 14:28:37,517 - mmdet - INFO - Distributed training: True
2021-12-29 14:28:40,396 - mmdet - INFO - Config:
dataset_type = 'AnatomyDataset'
data_root = '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi'
split = 'split_0'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
albu_train_transforms = [
    dict(
        type='OneOf',
        transforms=[
            dict(
                type='Affine',
                translate_percent=0.0,
                rotate=90,
                fit_output=True,
                p=0.25),
            dict(
                type='Affine',
                translate_percent=0.0,
                rotate=180,
                fit_output=True,
                p=0.25),
            dict(
                type='Affine',
                translate_percent=0.0,
                rotate=270,
                fit_output=True,
                p=0.25)
        ],
        p=0.75)
]
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
    dict(type='LoadAnatomy'),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='Albu',
        transforms=[
            dict(
                type='OneOf',
                transforms=[
                    dict(
                        type='Affine',
                        translate_percent=0.0,
                        rotate=90,
                        fit_output=True,
                        p=0.25),
                    dict(
                        type='Affine',
                        translate_percent=0.0,
                        rotate=180,
                        fit_output=True,
                        p=0.25),
                    dict(
                        type='Affine',
                        translate_percent=0.0,
                        rotate=270,
                        fit_output=True,
                        p=0.25)
                ],
                p=0.75)
        ],
        bbox_params=dict(
            type='BboxParams',
            format='pascal_voc',
            label_fields=['gt_labels'],
            min_visibility=0.0,
            filter_lost_elements=True),
        keymap=dict(img='image', gt_masks='masks', gt_bboxes='bboxes'),
        update_pad_shape=False,
        skip_img_without_anno=True),
    dict(
        type='Resize',
        img_scale=[(1333, 480), (1333, 512), (1333, 544), (1333, 576),
                   (1333, 608), (1333, 640), (1333, 672), (1333, 704),
                   (1333, 736), (1333, 768), (1333, 800)],
        multiscale_mode='value',
        keep_ratio=True),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='FormatAnatomyBundle'),
    dict(
        type='Collect',
        keys=['img', 'anatomy', 'gt_bboxes', 'gt_labels', 'gt_masks'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnatomy'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1333, 800),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='FormatAnatomyBundle'),
            dict(type='Collect', keys=['img', 'anatomy'])
        ])
]
data = dict(
    samples_per_gpu=2,
    workers_per_gpu=2,
    train=dict(
        type='AnatomyDataset',
        ann_file=
        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/annotations/train_anno_crop_split_0.json',
        img_prefix=
        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/images/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),
            dict(type='LoadAnatomy'),
            dict(type='RandomFlip', flip_ratio=0.5),
            dict(
                type='Albu',
                transforms=[
                    dict(
                        type='OneOf',
                        transforms=[
                            dict(
                                type='Affine',
                                translate_percent=0.0,
                                rotate=90,
                                fit_output=True,
                                p=0.25),
                            dict(
                                type='Affine',
                                translate_percent=0.0,
                                rotate=180,
                                fit_output=True,
                                p=0.25),
                            dict(
                                type='Affine',
                                translate_percent=0.0,
                                rotate=270,
                                fit_output=True,
                                p=0.25)
                        ],
                        p=0.75)
                ],
                bbox_params=dict(
                    type='BboxParams',
                    format='pascal_voc',
                    label_fields=['gt_labels'],
                    min_visibility=0.0,
                    filter_lost_elements=True),
                keymap=dict(img='image', gt_masks='masks', gt_bboxes='bboxes'),
                update_pad_shape=False,
                skip_img_without_anno=True),
            dict(
                type='Resize',
                img_scale=[(1333, 480), (1333, 512), (1333, 544), (1333, 576),
                           (1333, 608), (1333, 640), (1333, 672), (1333, 704),
                           (1333, 736), (1333, 768), (1333, 800)],
                multiscale_mode='value',
                keep_ratio=True),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='DefaultFormatBundle'),
            dict(type='FormatAnatomyBundle'),
            dict(
                type='Collect',
                keys=['img', 'anatomy', 'gt_bboxes', 'gt_labels', 'gt_masks'])
        ],
        classes=('lmym', 'GIST')),
    val=dict(
        type='AnatomyDataset',
        ann_file=
        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/annotations/val_anno_crop_split_0.json',
        img_prefix=
        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/images/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnatomy'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1333, 800),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='FormatAnatomyBundle'),
                    dict(type='Collect', keys=['img', 'anatomy'])
                ])
        ],
        classes=('lmym', 'GIST')),
    test=dict(
        type='AnatomyDataset',
        ann_file=
        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/annotations/val_anno_crop_split_0.json',
        img_prefix=
        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/images/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnatomy'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1333, 800),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='FormatAnatomyBundle'),
                    dict(type='Collect', keys=['img', 'anatomy'])
                ])
        ],
        classes=('lmym', 'GIST')))
evaluation = dict(metric=['bbox', 'segm', 'glob'])
optimizer = dict(type='AdamW', lr=2.5e-05, weight_decay=0.0001)
optimizer_config = dict(grad_clip=dict(max_norm=1, norm_type=2))
lr_config = dict(
    policy='step',
    warmup='linear',
    warmup_iters=1000,
    warmup_ratio=0.001,
    step=[27, 33])
runner = dict(type='EpochBasedRunner', max_epochs=36)
checkpoint_config = dict(interval=1)
log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])
custom_hooks = [dict(type='NumClassCheckHook')]
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = 'work_dirs/pretrained/queryInst/queryinst_r101_300_queries-860dc5d5.pth'
resume_from = None
workflow = [('train', 1)]
num_stages = 6
num_proposals = 300
model = dict(
    type='QueryGlob',
    pretrained='torchvision://resnet101',
    backbone=dict(
        type='ResNet',
        depth=101,
        num_stages=4,
        out_indices=(0, 1, 2, 3),
        frozen_stages=1,
        norm_cfg=dict(type='BN', requires_grad=True),
        norm_eval=True,
        style='pytorch'),
    neck=dict(
        type='FPN',
        in_channels=[256, 512, 1024, 2048],
        out_channels=256,
        start_level=0,
        add_extra_convs='on_input',
        num_outs=4),
    rpn_head=dict(
        type='GlobalEmbeddingRPNHead',
        num_proposals=300,
        dim_global=7,
        proposal_feature_channel=256),
    roi_head=dict(
        type='QueryGlobRoIHead',
        num_stages=6,
        stage_loss_weights=[1, 1, 1, 1, 1, 1],
        proposal_feature_channel=256,
        bbox_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=2),
            out_channels=256,
            featmap_strides=[4, 8, 16, 32]),
        mask_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=2),
            out_channels=256,
            featmap_strides=[4, 8, 16, 32]),
        bbox_head=[
            dict(
                type='GlobDIIHead',
                num_classes=2,
                num_ffn_fcs=2,
                num_heads=8,
                num_cls_fcs=2,
                num_glb_fcs=2,
                num_reg_fcs=3,
                feedforward_channels=2048,
                in_channels=256,
                dropout=0.0,
                ffn_act_cfg=dict(type='ReLU', inplace=True),
                dynamic_conv_cfg=dict(
                    type='DynamicConv',
                    in_channels=256,
                    feat_channels=64,
                    out_channels=256,
                    input_feat_shape=7,
                    with_proj=True,
                    act_cfg=dict(type='ReLU', inplace=True),
                    norm_cfg=dict(type='LN')),
                loss_bbox=dict(type='L1Loss', loss_weight=5.0),
                loss_iou=dict(type='GIoULoss', loss_weight=2.0),
                loss_cls=dict(
                    type='FocalLoss',
                    use_sigmoid=True,
                    gamma=2.0,
                    alpha=0.25,
                    loss_weight=2.0),
                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    clip_border=False,
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.5, 0.5, 1.0, 1.0])),
            dict(
                type='GlobDIIHead',
                num_classes=2,
                num_ffn_fcs=2,
                num_heads=8,
                num_cls_fcs=2,
                num_glb_fcs=2,
                num_reg_fcs=3,
                feedforward_channels=2048,
                in_channels=256,
                dropout=0.0,
                ffn_act_cfg=dict(type='ReLU', inplace=True),
                dynamic_conv_cfg=dict(
                    type='DynamicConv',
                    in_channels=256,
                    feat_channels=64,
                    out_channels=256,
                    input_feat_shape=7,
                    with_proj=True,
                    act_cfg=dict(type='ReLU', inplace=True),
                    norm_cfg=dict(type='LN')),
                loss_bbox=dict(type='L1Loss', loss_weight=5.0),
                loss_iou=dict(type='GIoULoss', loss_weight=2.0),
                loss_cls=dict(
                    type='FocalLoss',
                    use_sigmoid=True,
                    gamma=2.0,
                    alpha=0.25,
                    loss_weight=2.0),
                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    clip_border=False,
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.5, 0.5, 1.0, 1.0])),
            dict(
                type='GlobDIIHead',
                num_classes=2,
                num_ffn_fcs=2,
                num_heads=8,
                num_cls_fcs=2,
                num_glb_fcs=2,
                num_reg_fcs=3,
                feedforward_channels=2048,
                in_channels=256,
                dropout=0.0,
                ffn_act_cfg=dict(type='ReLU', inplace=True),
                dynamic_conv_cfg=dict(
                    type='DynamicConv',
                    in_channels=256,
                    feat_channels=64,
                    out_channels=256,
                    input_feat_shape=7,
                    with_proj=True,
                    act_cfg=dict(type='ReLU', inplace=True),
                    norm_cfg=dict(type='LN')),
                loss_bbox=dict(type='L1Loss', loss_weight=5.0),
                loss_iou=dict(type='GIoULoss', loss_weight=2.0),
                loss_cls=dict(
                    type='FocalLoss',
                    use_sigmoid=True,
                    gamma=2.0,
                    alpha=0.25,
                    loss_weight=2.0),
                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    clip_border=False,
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.5, 0.5, 1.0, 1.0])),
            dict(
                type='GlobDIIHead',
                num_classes=2,
                num_ffn_fcs=2,
                num_heads=8,
                num_cls_fcs=2,
                num_glb_fcs=2,
                num_reg_fcs=3,
                feedforward_channels=2048,
                in_channels=256,
                dropout=0.0,
                ffn_act_cfg=dict(type='ReLU', inplace=True),
                dynamic_conv_cfg=dict(
                    type='DynamicConv',
                    in_channels=256,
                    feat_channels=64,
                    out_channels=256,
                    input_feat_shape=7,
                    with_proj=True,
                    act_cfg=dict(type='ReLU', inplace=True),
                    norm_cfg=dict(type='LN')),
                loss_bbox=dict(type='L1Loss', loss_weight=5.0),
                loss_iou=dict(type='GIoULoss', loss_weight=2.0),
                loss_cls=dict(
                    type='FocalLoss',
                    use_sigmoid=True,
                    gamma=2.0,
                    alpha=0.25,
                    loss_weight=2.0),
                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    clip_border=False,
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.5, 0.5, 1.0, 1.0])),
            dict(
                type='GlobDIIHead',
                num_classes=2,
                num_ffn_fcs=2,
                num_heads=8,
                num_cls_fcs=2,
                num_glb_fcs=2,
                num_reg_fcs=3,
                feedforward_channels=2048,
                in_channels=256,
                dropout=0.0,
                ffn_act_cfg=dict(type='ReLU', inplace=True),
                dynamic_conv_cfg=dict(
                    type='DynamicConv',
                    in_channels=256,
                    feat_channels=64,
                    out_channels=256,
                    input_feat_shape=7,
                    with_proj=True,
                    act_cfg=dict(type='ReLU', inplace=True),
                    norm_cfg=dict(type='LN')),
                loss_bbox=dict(type='L1Loss', loss_weight=5.0),
                loss_iou=dict(type='GIoULoss', loss_weight=2.0),
                loss_cls=dict(
                    type='FocalLoss',
                    use_sigmoid=True,
                    gamma=2.0,
                    alpha=0.25,
                    loss_weight=2.0),
                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    clip_border=False,
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.5, 0.5, 1.0, 1.0])),
            dict(
                type='GlobDIIHead',
                num_classes=2,
                num_ffn_fcs=2,
                num_heads=8,
                num_cls_fcs=2,
                num_glb_fcs=2,
                num_reg_fcs=3,
                feedforward_channels=2048,
                in_channels=256,
                dropout=0.0,
                ffn_act_cfg=dict(type='ReLU', inplace=True),
                dynamic_conv_cfg=dict(
                    type='DynamicConv',
                    in_channels=256,
                    feat_channels=64,
                    out_channels=256,
                    input_feat_shape=7,
                    with_proj=True,
                    act_cfg=dict(type='ReLU', inplace=True),
                    norm_cfg=dict(type='LN')),
                loss_bbox=dict(type='L1Loss', loss_weight=5.0),
                loss_iou=dict(type='GIoULoss', loss_weight=2.0),
                loss_cls=dict(
                    type='FocalLoss',
                    use_sigmoid=True,
                    gamma=2.0,
                    alpha=0.25,
                    loss_weight=2.0),
                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    clip_border=False,
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.5, 0.5, 1.0, 1.0]))
        ],
        mask_head=[
            dict(
                type='DynamicMaskHead',
                num_classes=2,
                dynamic_conv_cfg=dict(
                    type='DynamicConv',
                    in_channels=256,
                    feat_channels=64,
                    out_channels=256,
                    input_feat_shape=14,
                    with_proj=False,
                    act_cfg=dict(type='ReLU', inplace=True),
                    norm_cfg=dict(type='LN')),
                dropout=0.0,
                num_convs=4,
                roi_feat_size=14,
                in_channels=256,
                conv_kernel_size=3,
                conv_out_channels=256,
                class_agnostic=False,
                norm_cfg=dict(type='BN'),
                upsample_cfg=dict(type='deconv', scale_factor=2),
                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),
            dict(
                type='DynamicMaskHead',
                num_classes=2,
                dynamic_conv_cfg=dict(
                    type='DynamicConv',
                    in_channels=256,
                    feat_channels=64,
                    out_channels=256,
                    input_feat_shape=14,
                    with_proj=False,
                    act_cfg=dict(type='ReLU', inplace=True),
                    norm_cfg=dict(type='LN')),
                dropout=0.0,
                num_convs=4,
                roi_feat_size=14,
                in_channels=256,
                conv_kernel_size=3,
                conv_out_channels=256,
                class_agnostic=False,
                norm_cfg=dict(type='BN'),
                upsample_cfg=dict(type='deconv', scale_factor=2),
                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),
            dict(
                type='DynamicMaskHead',
                num_classes=2,
                dynamic_conv_cfg=dict(
                    type='DynamicConv',
                    in_channels=256,
                    feat_channels=64,
                    out_channels=256,
                    input_feat_shape=14,
                    with_proj=False,
                    act_cfg=dict(type='ReLU', inplace=True),
                    norm_cfg=dict(type='LN')),
                dropout=0.0,
                num_convs=4,
                roi_feat_size=14,
                in_channels=256,
                conv_kernel_size=3,
                conv_out_channels=256,
                class_agnostic=False,
                norm_cfg=dict(type='BN'),
                upsample_cfg=dict(type='deconv', scale_factor=2),
                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),
            dict(
                type='DynamicMaskHead',
                num_classes=2,
                dynamic_conv_cfg=dict(
                    type='DynamicConv',
                    in_channels=256,
                    feat_channels=64,
                    out_channels=256,
                    input_feat_shape=14,
                    with_proj=False,
                    act_cfg=dict(type='ReLU', inplace=True),
                    norm_cfg=dict(type='LN')),
                dropout=0.0,
                num_convs=4,
                roi_feat_size=14,
                in_channels=256,
                conv_kernel_size=3,
                conv_out_channels=256,
                class_agnostic=False,
                norm_cfg=dict(type='BN'),
                upsample_cfg=dict(type='deconv', scale_factor=2),
                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),
            dict(
                type='DynamicMaskHead',
                num_classes=2,
                dynamic_conv_cfg=dict(
                    type='DynamicConv',
                    in_channels=256,
                    feat_channels=64,
                    out_channels=256,
                    input_feat_shape=14,
                    with_proj=False,
                    act_cfg=dict(type='ReLU', inplace=True),
                    norm_cfg=dict(type='LN')),
                dropout=0.0,
                num_convs=4,
                roi_feat_size=14,
                in_channels=256,
                conv_kernel_size=3,
                conv_out_channels=256,
                class_agnostic=False,
                norm_cfg=dict(type='BN'),
                upsample_cfg=dict(type='deconv', scale_factor=2),
                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),
            dict(
                type='DynamicMaskHead',
                num_classes=2,
                dynamic_conv_cfg=dict(
                    type='DynamicConv',
                    in_channels=256,
                    feat_channels=64,
                    out_channels=256,
                    input_feat_shape=14,
                    with_proj=False,
                    act_cfg=dict(type='ReLU', inplace=True),
                    norm_cfg=dict(type='LN')),
                dropout=0.0,
                num_convs=4,
                roi_feat_size=14,
                in_channels=256,
                conv_kernel_size=3,
                conv_out_channels=256,
                class_agnostic=False,
                norm_cfg=dict(type='BN'),
                upsample_cfg=dict(type='deconv', scale_factor=2),
                loss_dice=dict(type='DiceLoss', loss_weight=8.0))
        ]),
    train_cfg=dict(
        rpn=None,
        rcnn=[
            dict(
                assigner=dict(
                    type='HungarianAssigner',
                    cls_cost=dict(type='FocalLossCost', weight=2.0),
                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),
                    iou_cost=dict(type='IoUCost', iou_mode='giou',
                                  weight=2.0)),
                sampler=dict(type='PseudoSampler'),
                pos_weight=1,
                mask_size=28,
                debug=False),
            dict(
                assigner=dict(
                    type='HungarianAssigner',
                    cls_cost=dict(type='FocalLossCost', weight=2.0),
                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),
                    iou_cost=dict(type='IoUCost', iou_mode='giou',
                                  weight=2.0)),
                sampler=dict(type='PseudoSampler'),
                pos_weight=1,
                mask_size=28,
                debug=False),
            dict(
                assigner=dict(
                    type='HungarianAssigner',
                    cls_cost=dict(type='FocalLossCost', weight=2.0),
                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),
                    iou_cost=dict(type='IoUCost', iou_mode='giou',
                                  weight=2.0)),
                sampler=dict(type='PseudoSampler'),
                pos_weight=1,
                mask_size=28,
                debug=False),
            dict(
                assigner=dict(
                    type='HungarianAssigner',
                    cls_cost=dict(type='FocalLossCost', weight=2.0),
                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),
                    iou_cost=dict(type='IoUCost', iou_mode='giou',
                                  weight=2.0)),
                sampler=dict(type='PseudoSampler'),
                pos_weight=1,
                mask_size=28,
                debug=False),
            dict(
                assigner=dict(
                    type='HungarianAssigner',
                    cls_cost=dict(type='FocalLossCost', weight=2.0),
                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),
                    iou_cost=dict(type='IoUCost', iou_mode='giou',
                                  weight=2.0)),
                sampler=dict(type='PseudoSampler'),
                pos_weight=1,
                mask_size=28,
                debug=False),
            dict(
                assigner=dict(
                    type='HungarianAssigner',
                    cls_cost=dict(type='FocalLossCost', weight=2.0),
                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),
                    iou_cost=dict(type='IoUCost', iou_mode='giou',
                                  weight=2.0)),
                sampler=dict(type='PseudoSampler'),
                pos_weight=1,
                mask_size=28,
                debug=False)
        ]),
    test_cfg=dict(
        rpn=None,
        rcnn=dict(
            max_per_img=300,
            mask_thr_binary=0.5,
            nms=dict(type='nms', iou_threshold=0.7))))
total_epochs = 36
min_values = (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)
classes = ('lmym', 'GIST')
gpu_ids = range(0, 4)
work_dir = './work_dirs/queryglob_usdanno514roi_B_2_7_split0'

2021-12-29 14:28:42,350 - mmdet - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet101'}
2021-12-29 14:28:42,857 - mmdet - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
2021-12-29 14:28:42,884 - mmdet - INFO - initialize GlobDIIHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}]
2021-12-29 14:28:43,005 - mmdet - INFO - initialize GlobDIIHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}]
2021-12-29 14:28:43,127 - mmdet - INFO - initialize GlobDIIHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}]
2021-12-29 14:28:43,246 - mmdet - INFO - initialize GlobDIIHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}]
2021-12-29 14:28:43,364 - mmdet - INFO - initialize GlobDIIHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}]
2021-12-29 14:28:43,482 - mmdet - INFO - initialize GlobDIIHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}]
Name of parameter - Initialization information

backbone.conv1.weight - torch.Size([64, 3, 7, 7]): 
PretrainedInit: load from torchvision://resnet101 

backbone.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet101 

backbone.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer1.0.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer1.0.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer1.0.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer1.0.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer1.0.bn3.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer1.0.bn3.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer1.0.downsample.1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer1.0.downsample.1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer1.1.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer1.1.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer1.1.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer1.1.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer1.1.bn3.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer1.1.bn3.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer1.2.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer1.2.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer1.2.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer1.2.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer1.2.bn3.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer1.2.bn3.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.0.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.0.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.0.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.0.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.0.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.0.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.0.downsample.1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.0.downsample.1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.1.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.1.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.1.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.1.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.1.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.1.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.2.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.2.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.2.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.2.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.2.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.2.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.3.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.3.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.3.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.3.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.3.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer2.3.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.0.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.0.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.0.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.0.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.0.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.0.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.0.downsample.1.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.0.downsample.1.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.1.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.1.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.1.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.1.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.1.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.1.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.2.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.2.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.2.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.2.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.2.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.2.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.3.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.3.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.3.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.3.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.3.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.3.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.4.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.4.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.4.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.4.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.4.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.4.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.5.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.5.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.5.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.5.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.5.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.5.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.6.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.6.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.6.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.6.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.6.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.6.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.6.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.6.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.6.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.7.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.7.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.7.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.7.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.7.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.7.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.7.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.7.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.7.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.8.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.8.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.8.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.8.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.8.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.8.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.8.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.8.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.8.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.9.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.9.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.9.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.9.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.9.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.9.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.9.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.9.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.9.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.10.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.10.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.10.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.10.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.10.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.10.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.10.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.10.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.10.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.11.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.11.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.11.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.11.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.11.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.11.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.11.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.11.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.11.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.12.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.12.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.12.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.12.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.12.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.12.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.12.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.12.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.12.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.13.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.13.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.13.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.13.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.13.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.13.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.13.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.13.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.13.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.14.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.14.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.14.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.14.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.14.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.14.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.14.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.14.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.14.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.15.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.15.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.15.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.15.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.15.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.15.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.15.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.15.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.15.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.16.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.16.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.16.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.16.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.16.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.16.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.16.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.16.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.16.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.17.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.17.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.17.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.17.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.17.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.17.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.17.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.17.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.17.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.18.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.18.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.18.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.18.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.18.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.18.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.18.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.18.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.18.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.19.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.19.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.19.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.19.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.19.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.19.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.19.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.19.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.19.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.20.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.20.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.20.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.20.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.20.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.20.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.20.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.20.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.20.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.21.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.21.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.21.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.21.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.21.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.21.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.21.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.21.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.21.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.22.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.22.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.22.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.22.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.22.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.22.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.22.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.22.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer3.22.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer4.0.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer4.0.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer4.0.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer4.0.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer4.0.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer4.0.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer4.0.downsample.1.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer4.0.downsample.1.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer4.1.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer4.1.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer4.1.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer4.1.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer4.1.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer4.1.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer4.2.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer4.2.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer4.2.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer4.2.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer4.2.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet101 

backbone.layer4.2.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet101 

neck.lateral_convs.0.conv.weight - torch.Size([256, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

neck.lateral_convs.1.conv.weight - torch.Size([256, 512, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

neck.lateral_convs.2.conv.weight - torch.Size([256, 1024, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

neck.lateral_convs.3.conv.weight - torch.Size([256, 2048, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

rpn_head.init_proposal_bboxes.weight - torch.Size([300, 4]): 
Initialized by user-defined `init_weights` in GlobalEmbeddingRPNHead  

rpn_head.init_proposal_features.weight - torch.Size([300, 256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

rpn_head.global_features_embed.weight - torch.Size([7, 256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.fc_cls.weight - torch.Size([2, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.0.fc_cls.bias - torch.Size([2]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.0.fc_reg.weight - torch.Size([4, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.0.fc_reg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.0.attention.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.0.attention.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.attention.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.0.attention.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.attention_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.attention_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.global_attention.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.0.global_attention.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.global_attention.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.0.global_attention.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.global_attention_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.global_attention_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.instance_interactive_conv.dynamic_layer.weight - torch.Size([32768, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.0.instance_interactive_conv.dynamic_layer.bias - torch.Size([32768]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.instance_interactive_conv.norm_in.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.instance_interactive_conv.norm_in.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.instance_interactive_conv.norm_out.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.instance_interactive_conv.norm_out.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.instance_interactive_conv.fc_layer.weight - torch.Size([256, 12544]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.0.instance_interactive_conv.fc_layer.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.instance_interactive_conv.fc_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.instance_interactive_conv.fc_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.instance_interactive_conv_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.instance_interactive_conv_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.0.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.0.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.ffn_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.ffn_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.global_ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.0.global_ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.global_ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.0.global_ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.global_ffn_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.global_ffn_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.cls_fcs.0.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.0.cls_fcs.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.cls_fcs.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.cls_fcs.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.0.cls_fcs.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.cls_fcs.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.reg_fcs.0.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.0.reg_fcs.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.reg_fcs.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.reg_fcs.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.0.reg_fcs.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.reg_fcs.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.reg_fcs.6.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.0.reg_fcs.7.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.reg_fcs.7.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.glb_fcs.0.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.0.glb_fcs.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.glb_fcs.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.glb_fcs.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.0.glb_fcs.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.glb_fcs.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.0.fc_glb.weight - torch.Size([2, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.0.fc_glb.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.fc_cls.weight - torch.Size([2, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.1.fc_cls.bias - torch.Size([2]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.1.fc_reg.weight - torch.Size([4, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.1.fc_reg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.1.attention.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.1.attention.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.attention.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.1.attention.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.attention_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.attention_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.global_attention.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.1.global_attention.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.global_attention.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.1.global_attention.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.global_attention_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.global_attention_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.instance_interactive_conv.dynamic_layer.weight - torch.Size([32768, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.1.instance_interactive_conv.dynamic_layer.bias - torch.Size([32768]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.instance_interactive_conv.norm_in.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.instance_interactive_conv.norm_in.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.instance_interactive_conv.norm_out.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.instance_interactive_conv.norm_out.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.instance_interactive_conv.fc_layer.weight - torch.Size([256, 12544]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.1.instance_interactive_conv.fc_layer.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.instance_interactive_conv.fc_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.instance_interactive_conv.fc_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.instance_interactive_conv_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.instance_interactive_conv_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.1.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.1.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.ffn_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.ffn_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.global_ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.1.global_ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.global_ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.1.global_ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.global_ffn_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.global_ffn_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.cls_fcs.0.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.1.cls_fcs.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.cls_fcs.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.cls_fcs.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.1.cls_fcs.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.cls_fcs.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.reg_fcs.0.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.1.reg_fcs.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.reg_fcs.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.reg_fcs.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.1.reg_fcs.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.reg_fcs.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.reg_fcs.6.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.1.reg_fcs.7.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.reg_fcs.7.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.glb_fcs.0.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.1.glb_fcs.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.glb_fcs.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.glb_fcs.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.1.glb_fcs.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.glb_fcs.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.1.fc_glb.weight - torch.Size([2, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.1.fc_glb.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.fc_cls.weight - torch.Size([2, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.2.fc_cls.bias - torch.Size([2]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.2.fc_reg.weight - torch.Size([4, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.2.fc_reg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.2.attention.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.2.attention.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.attention.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.2.attention.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.attention_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.attention_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.global_attention.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.2.global_attention.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.global_attention.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.2.global_attention.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.global_attention_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.global_attention_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.instance_interactive_conv.dynamic_layer.weight - torch.Size([32768, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.2.instance_interactive_conv.dynamic_layer.bias - torch.Size([32768]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.instance_interactive_conv.norm_in.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.instance_interactive_conv.norm_in.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.instance_interactive_conv.norm_out.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.instance_interactive_conv.norm_out.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.instance_interactive_conv.fc_layer.weight - torch.Size([256, 12544]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.2.instance_interactive_conv.fc_layer.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.instance_interactive_conv.fc_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.instance_interactive_conv.fc_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.instance_interactive_conv_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.instance_interactive_conv_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.2.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.2.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.ffn_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.ffn_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.global_ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.2.global_ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.global_ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.2.global_ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.global_ffn_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.global_ffn_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.cls_fcs.0.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.2.cls_fcs.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.cls_fcs.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.cls_fcs.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.2.cls_fcs.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.cls_fcs.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.reg_fcs.0.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.2.reg_fcs.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.reg_fcs.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.reg_fcs.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.2.reg_fcs.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.reg_fcs.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.reg_fcs.6.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.2.reg_fcs.7.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.reg_fcs.7.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.glb_fcs.0.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.2.glb_fcs.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.glb_fcs.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.glb_fcs.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.2.glb_fcs.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.glb_fcs.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.2.fc_glb.weight - torch.Size([2, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.2.fc_glb.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.fc_cls.weight - torch.Size([2, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.3.fc_cls.bias - torch.Size([2]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.3.fc_reg.weight - torch.Size([4, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.3.fc_reg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.3.attention.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.3.attention.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.attention.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.3.attention.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.attention_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.attention_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.global_attention.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.3.global_attention.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.global_attention.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.3.global_attention.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.global_attention_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.global_attention_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.instance_interactive_conv.dynamic_layer.weight - torch.Size([32768, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.3.instance_interactive_conv.dynamic_layer.bias - torch.Size([32768]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.instance_interactive_conv.norm_in.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.instance_interactive_conv.norm_in.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.instance_interactive_conv.norm_out.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.instance_interactive_conv.norm_out.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.instance_interactive_conv.fc_layer.weight - torch.Size([256, 12544]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.3.instance_interactive_conv.fc_layer.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.instance_interactive_conv.fc_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.instance_interactive_conv.fc_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.instance_interactive_conv_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.instance_interactive_conv_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.3.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.3.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.ffn_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.ffn_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.global_ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.3.global_ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.global_ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.3.global_ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.global_ffn_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.global_ffn_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.cls_fcs.0.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.3.cls_fcs.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.cls_fcs.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.cls_fcs.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.3.cls_fcs.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.cls_fcs.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.reg_fcs.0.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.3.reg_fcs.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.reg_fcs.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.reg_fcs.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.3.reg_fcs.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.reg_fcs.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.reg_fcs.6.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.3.reg_fcs.7.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.reg_fcs.7.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.glb_fcs.0.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.3.glb_fcs.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.glb_fcs.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.glb_fcs.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.3.glb_fcs.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.glb_fcs.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.3.fc_glb.weight - torch.Size([2, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.3.fc_glb.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.fc_cls.weight - torch.Size([2, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.4.fc_cls.bias - torch.Size([2]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.4.fc_reg.weight - torch.Size([4, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.4.fc_reg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.4.attention.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.4.attention.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.attention.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.4.attention.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.attention_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.attention_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.global_attention.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.4.global_attention.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.global_attention.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.4.global_attention.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.global_attention_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.global_attention_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.instance_interactive_conv.dynamic_layer.weight - torch.Size([32768, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.4.instance_interactive_conv.dynamic_layer.bias - torch.Size([32768]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.instance_interactive_conv.norm_in.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.instance_interactive_conv.norm_in.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.instance_interactive_conv.norm_out.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.instance_interactive_conv.norm_out.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.instance_interactive_conv.fc_layer.weight - torch.Size([256, 12544]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.4.instance_interactive_conv.fc_layer.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.instance_interactive_conv.fc_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.instance_interactive_conv.fc_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.instance_interactive_conv_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.instance_interactive_conv_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.4.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.4.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.ffn_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.ffn_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.global_ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.4.global_ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.global_ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.4.global_ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.global_ffn_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.global_ffn_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.cls_fcs.0.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.4.cls_fcs.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.cls_fcs.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.cls_fcs.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.4.cls_fcs.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.cls_fcs.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.reg_fcs.0.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.4.reg_fcs.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.reg_fcs.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.reg_fcs.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.4.reg_fcs.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.reg_fcs.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.reg_fcs.6.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.4.reg_fcs.7.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.reg_fcs.7.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.glb_fcs.0.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.4.glb_fcs.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.glb_fcs.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.glb_fcs.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.4.glb_fcs.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.glb_fcs.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.4.fc_glb.weight - torch.Size([2, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.4.fc_glb.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.fc_cls.weight - torch.Size([2, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.5.fc_cls.bias - torch.Size([2]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.5.fc_reg.weight - torch.Size([4, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.5.fc_reg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.5.attention.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.5.attention.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.attention.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.5.attention.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.attention_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.attention_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.global_attention.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.5.global_attention.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.global_attention.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.5.global_attention.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.global_attention_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.global_attention_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.instance_interactive_conv.dynamic_layer.weight - torch.Size([32768, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.5.instance_interactive_conv.dynamic_layer.bias - torch.Size([32768]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.instance_interactive_conv.norm_in.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.instance_interactive_conv.norm_in.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.instance_interactive_conv.norm_out.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.instance_interactive_conv.norm_out.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.instance_interactive_conv.fc_layer.weight - torch.Size([256, 12544]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.5.instance_interactive_conv.fc_layer.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.instance_interactive_conv.fc_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.instance_interactive_conv.fc_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.instance_interactive_conv_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.instance_interactive_conv_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.5.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.5.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.ffn_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.ffn_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.global_ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.5.global_ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.global_ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.5.global_ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.global_ffn_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.global_ffn_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.cls_fcs.0.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.5.cls_fcs.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.cls_fcs.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.cls_fcs.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.5.cls_fcs.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.cls_fcs.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.reg_fcs.0.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.5.reg_fcs.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.reg_fcs.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.reg_fcs.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.5.reg_fcs.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.reg_fcs.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.reg_fcs.6.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.5.reg_fcs.7.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.reg_fcs.7.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.glb_fcs.0.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.5.glb_fcs.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.glb_fcs.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.glb_fcs.3.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.5.glb_fcs.4.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.glb_fcs.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.bbox_head.5.fc_glb.weight - torch.Size([2, 256]): 
Initialized by user-defined `init_weights` in GlobDIIHead  

roi_head.bbox_head.5.fc_glb.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.0.convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.0.convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.0.convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.0.convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.0.convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.0.convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.0.convs.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.0.convs.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.0.convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.0.convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.0.convs.2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.0.convs.2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.0.convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.0.convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.0.convs.3.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.0.convs.3.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.0.upsample.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.0.upsample.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.0.conv_logits.weight - torch.Size([2, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.0.conv_logits.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.0.instance_interactive_conv.dynamic_layer.weight - torch.Size([32768, 256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.0.instance_interactive_conv.dynamic_layer.bias - torch.Size([32768]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.0.instance_interactive_conv.norm_in.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.0.instance_interactive_conv.norm_in.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.0.instance_interactive_conv.norm_out.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.0.instance_interactive_conv.norm_out.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.1.convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.1.convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.1.convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.1.convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.1.convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.1.convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.1.convs.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.1.convs.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.1.convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.1.convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.1.convs.2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.1.convs.2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.1.convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.1.convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.1.convs.3.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.1.convs.3.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.1.upsample.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.1.upsample.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.1.conv_logits.weight - torch.Size([2, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.1.conv_logits.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.1.instance_interactive_conv.dynamic_layer.weight - torch.Size([32768, 256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.1.instance_interactive_conv.dynamic_layer.bias - torch.Size([32768]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.1.instance_interactive_conv.norm_in.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.1.instance_interactive_conv.norm_in.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.1.instance_interactive_conv.norm_out.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.1.instance_interactive_conv.norm_out.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.2.convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.2.convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.2.convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.2.convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.2.convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.2.convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.2.convs.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.2.convs.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.2.convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.2.convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.2.convs.2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.2.convs.2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.2.convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.2.convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.2.convs.3.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.2.convs.3.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.2.upsample.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.2.upsample.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.2.conv_logits.weight - torch.Size([2, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.2.conv_logits.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.2.instance_interactive_conv.dynamic_layer.weight - torch.Size([32768, 256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.2.instance_interactive_conv.dynamic_layer.bias - torch.Size([32768]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.2.instance_interactive_conv.norm_in.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.2.instance_interactive_conv.norm_in.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.2.instance_interactive_conv.norm_out.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.2.instance_interactive_conv.norm_out.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.3.convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.3.convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.3.convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.3.convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.3.convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.3.convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.3.convs.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.3.convs.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.3.convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.3.convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.3.convs.2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.3.convs.2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.3.convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.3.convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.3.convs.3.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.3.convs.3.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.3.upsample.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.3.upsample.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.3.conv_logits.weight - torch.Size([2, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.3.conv_logits.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.3.instance_interactive_conv.dynamic_layer.weight - torch.Size([32768, 256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.3.instance_interactive_conv.dynamic_layer.bias - torch.Size([32768]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.3.instance_interactive_conv.norm_in.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.3.instance_interactive_conv.norm_in.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.3.instance_interactive_conv.norm_out.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.3.instance_interactive_conv.norm_out.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.4.convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.4.convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.4.convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.4.convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.4.convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.4.convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.4.convs.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.4.convs.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.4.convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.4.convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.4.convs.2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.4.convs.2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.4.convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.4.convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.4.convs.3.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.4.convs.3.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.4.upsample.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.4.upsample.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.4.conv_logits.weight - torch.Size([2, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.4.conv_logits.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.4.instance_interactive_conv.dynamic_layer.weight - torch.Size([32768, 256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.4.instance_interactive_conv.dynamic_layer.bias - torch.Size([32768]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.4.instance_interactive_conv.norm_in.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.4.instance_interactive_conv.norm_in.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.4.instance_interactive_conv.norm_out.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.4.instance_interactive_conv.norm_out.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.5.convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.5.convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.5.convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.5.convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.5.convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.5.convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.5.convs.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.5.convs.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.5.convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.5.convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.5.convs.2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.5.convs.2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.5.convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.5.convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.5.convs.3.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.5.convs.3.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.5.upsample.weight - torch.Size([256, 256, 2, 2]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.5.upsample.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.5.conv_logits.weight - torch.Size([2, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.5.conv_logits.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.5.instance_interactive_conv.dynamic_layer.weight - torch.Size([32768, 256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.5.instance_interactive_conv.dynamic_layer.bias - torch.Size([32768]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.5.instance_interactive_conv.norm_in.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.5.instance_interactive_conv.norm_in.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.5.instance_interactive_conv.norm_out.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  

roi_head.mask_head.5.instance_interactive_conv.norm_out.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of QueryGlob  
2021-12-29 14:28:45,347 - mmdet - INFO - load checkpoint from local path: work_dirs/pretrained/queryInst/queryinst_r101_300_queries-860dc5d5.pth
2021-12-29 14:28:48,278 - mmdet - WARNING - The model and loaded state dict do not match exactly

size mismatch for roi_head.bbox_head.0.fc_cls.weight: copying a param with shape torch.Size([80, 256]) from checkpoint, the shape in current model is torch.Size([2, 256]).
size mismatch for roi_head.bbox_head.0.fc_cls.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([2]).
size mismatch for roi_head.bbox_head.1.fc_cls.weight: copying a param with shape torch.Size([80, 256]) from checkpoint, the shape in current model is torch.Size([2, 256]).
size mismatch for roi_head.bbox_head.1.fc_cls.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([2]).
size mismatch for roi_head.bbox_head.2.fc_cls.weight: copying a param with shape torch.Size([80, 256]) from checkpoint, the shape in current model is torch.Size([2, 256]).
size mismatch for roi_head.bbox_head.2.fc_cls.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([2]).
size mismatch for roi_head.bbox_head.3.fc_cls.weight: copying a param with shape torch.Size([80, 256]) from checkpoint, the shape in current model is torch.Size([2, 256]).
size mismatch for roi_head.bbox_head.3.fc_cls.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([2]).
size mismatch for roi_head.bbox_head.4.fc_cls.weight: copying a param with shape torch.Size([80, 256]) from checkpoint, the shape in current model is torch.Size([2, 256]).
size mismatch for roi_head.bbox_head.4.fc_cls.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([2]).
size mismatch for roi_head.bbox_head.5.fc_cls.weight: copying a param with shape torch.Size([80, 256]) from checkpoint, the shape in current model is torch.Size([2, 256]).
size mismatch for roi_head.bbox_head.5.fc_cls.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([2]).
size mismatch for roi_head.mask_head.0.conv_logits.weight: copying a param with shape torch.Size([80, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 256, 1, 1]).
size mismatch for roi_head.mask_head.0.conv_logits.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([2]).
size mismatch for roi_head.mask_head.1.conv_logits.weight: copying a param with shape torch.Size([80, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 256, 1, 1]).
size mismatch for roi_head.mask_head.1.conv_logits.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([2]).
size mismatch for roi_head.mask_head.2.conv_logits.weight: copying a param with shape torch.Size([80, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 256, 1, 1]).
size mismatch for roi_head.mask_head.2.conv_logits.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([2]).
size mismatch for roi_head.mask_head.3.conv_logits.weight: copying a param with shape torch.Size([80, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 256, 1, 1]).
size mismatch for roi_head.mask_head.3.conv_logits.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([2]).
size mismatch for roi_head.mask_head.4.conv_logits.weight: copying a param with shape torch.Size([80, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 256, 1, 1]).
size mismatch for roi_head.mask_head.4.conv_logits.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([2]).
size mismatch for roi_head.mask_head.5.conv_logits.weight: copying a param with shape torch.Size([80, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2, 256, 1, 1]).
size mismatch for roi_head.mask_head.5.conv_logits.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([2]).
missing keys in source state_dict: rpn_head.global_features_embed.weight, roi_head.bbox_head.0.global_attention.attn.in_proj_weight, roi_head.bbox_head.0.global_attention.attn.in_proj_bias, roi_head.bbox_head.0.global_attention.attn.out_proj.weight, roi_head.bbox_head.0.global_attention.attn.out_proj.bias, roi_head.bbox_head.0.global_attention_norm.weight, roi_head.bbox_head.0.global_attention_norm.bias, roi_head.bbox_head.0.global_ffn.layers.0.0.weight, roi_head.bbox_head.0.global_ffn.layers.0.0.bias, roi_head.bbox_head.0.global_ffn.layers.1.weight, roi_head.bbox_head.0.global_ffn.layers.1.bias, roi_head.bbox_head.0.global_ffn_norm.weight, roi_head.bbox_head.0.global_ffn_norm.bias, roi_head.bbox_head.0.cls_fcs.3.weight, roi_head.bbox_head.0.cls_fcs.4.weight, roi_head.bbox_head.0.cls_fcs.4.bias, roi_head.bbox_head.0.glb_fcs.0.weight, roi_head.bbox_head.0.glb_fcs.1.weight, roi_head.bbox_head.0.glb_fcs.1.bias, roi_head.bbox_head.0.glb_fcs.3.weight, roi_head.bbox_head.0.glb_fcs.4.weight, roi_head.bbox_head.0.glb_fcs.4.bias, roi_head.bbox_head.0.fc_glb.weight, roi_head.bbox_head.0.fc_glb.bias, roi_head.bbox_head.1.global_attention.attn.in_proj_weight, roi_head.bbox_head.1.global_attention.attn.in_proj_bias, roi_head.bbox_head.1.global_attention.attn.out_proj.weight, roi_head.bbox_head.1.global_attention.attn.out_proj.bias, roi_head.bbox_head.1.global_attention_norm.weight, roi_head.bbox_head.1.global_attention_norm.bias, roi_head.bbox_head.1.global_ffn.layers.0.0.weight, roi_head.bbox_head.1.global_ffn.layers.0.0.bias, roi_head.bbox_head.1.global_ffn.layers.1.weight, roi_head.bbox_head.1.global_ffn.layers.1.bias, roi_head.bbox_head.1.global_ffn_norm.weight, roi_head.bbox_head.1.global_ffn_norm.bias, roi_head.bbox_head.1.cls_fcs.3.weight, roi_head.bbox_head.1.cls_fcs.4.weight, roi_head.bbox_head.1.cls_fcs.4.bias, roi_head.bbox_head.1.glb_fcs.0.weight, roi_head.bbox_head.1.glb_fcs.1.weight, roi_head.bbox_head.1.glb_fcs.1.bias, roi_head.bbox_head.1.glb_fcs.3.weight, roi_head.bbox_head.1.glb_fcs.4.weight, roi_head.bbox_head.1.glb_fcs.4.bias, roi_head.bbox_head.1.fc_glb.weight, roi_head.bbox_head.1.fc_glb.bias, roi_head.bbox_head.2.global_attention.attn.in_proj_weight, roi_head.bbox_head.2.global_attention.attn.in_proj_bias, roi_head.bbox_head.2.global_attention.attn.out_proj.weight, roi_head.bbox_head.2.global_attention.attn.out_proj.bias, roi_head.bbox_head.2.global_attention_norm.weight, roi_head.bbox_head.2.global_attention_norm.bias, roi_head.bbox_head.2.global_ffn.layers.0.0.weight, roi_head.bbox_head.2.global_ffn.layers.0.0.bias, roi_head.bbox_head.2.global_ffn.layers.1.weight, roi_head.bbox_head.2.global_ffn.layers.1.bias, roi_head.bbox_head.2.global_ffn_norm.weight, roi_head.bbox_head.2.global_ffn_norm.bias, roi_head.bbox_head.2.cls_fcs.3.weight, roi_head.bbox_head.2.cls_fcs.4.weight, roi_head.bbox_head.2.cls_fcs.4.bias, roi_head.bbox_head.2.glb_fcs.0.weight, roi_head.bbox_head.2.glb_fcs.1.weight, roi_head.bbox_head.2.glb_fcs.1.bias, roi_head.bbox_head.2.glb_fcs.3.weight, roi_head.bbox_head.2.glb_fcs.4.weight, roi_head.bbox_head.2.glb_fcs.4.bias, roi_head.bbox_head.2.fc_glb.weight, roi_head.bbox_head.2.fc_glb.bias, roi_head.bbox_head.3.global_attention.attn.in_proj_weight, roi_head.bbox_head.3.global_attention.attn.in_proj_bias, roi_head.bbox_head.3.global_attention.attn.out_proj.weight, roi_head.bbox_head.3.global_attention.attn.out_proj.bias, roi_head.bbox_head.3.global_attention_norm.weight, roi_head.bbox_head.3.global_attention_norm.bias, roi_head.bbox_head.3.global_ffn.layers.0.0.weight, roi_head.bbox_head.3.global_ffn.layers.0.0.bias, roi_head.bbox_head.3.global_ffn.layers.1.weight, roi_head.bbox_head.3.global_ffn.layers.1.bias, roi_head.bbox_head.3.global_ffn_norm.weight, roi_head.bbox_head.3.global_ffn_norm.bias, roi_head.bbox_head.3.cls_fcs.3.weight, roi_head.bbox_head.3.cls_fcs.4.weight, roi_head.bbox_head.3.cls_fcs.4.bias, roi_head.bbox_head.3.glb_fcs.0.weight, roi_head.bbox_head.3.glb_fcs.1.weight, roi_head.bbox_head.3.glb_fcs.1.bias, roi_head.bbox_head.3.glb_fcs.3.weight, roi_head.bbox_head.3.glb_fcs.4.weight, roi_head.bbox_head.3.glb_fcs.4.bias, roi_head.bbox_head.3.fc_glb.weight, roi_head.bbox_head.3.fc_glb.bias, roi_head.bbox_head.4.global_attention.attn.in_proj_weight, roi_head.bbox_head.4.global_attention.attn.in_proj_bias, roi_head.bbox_head.4.global_attention.attn.out_proj.weight, roi_head.bbox_head.4.global_attention.attn.out_proj.bias, roi_head.bbox_head.4.global_attention_norm.weight, roi_head.bbox_head.4.global_attention_norm.bias, roi_head.bbox_head.4.global_ffn.layers.0.0.weight, roi_head.bbox_head.4.global_ffn.layers.0.0.bias, roi_head.bbox_head.4.global_ffn.layers.1.weight, roi_head.bbox_head.4.global_ffn.layers.1.bias, roi_head.bbox_head.4.global_ffn_norm.weight, roi_head.bbox_head.4.global_ffn_norm.bias, roi_head.bbox_head.4.cls_fcs.3.weight, roi_head.bbox_head.4.cls_fcs.4.weight, roi_head.bbox_head.4.cls_fcs.4.bias, roi_head.bbox_head.4.glb_fcs.0.weight, roi_head.bbox_head.4.glb_fcs.1.weight, roi_head.bbox_head.4.glb_fcs.1.bias, roi_head.bbox_head.4.glb_fcs.3.weight, roi_head.bbox_head.4.glb_fcs.4.weight, roi_head.bbox_head.4.glb_fcs.4.bias, roi_head.bbox_head.4.fc_glb.weight, roi_head.bbox_head.4.fc_glb.bias, roi_head.bbox_head.5.global_attention.attn.in_proj_weight, roi_head.bbox_head.5.global_attention.attn.in_proj_bias, roi_head.bbox_head.5.global_attention.attn.out_proj.weight, roi_head.bbox_head.5.global_attention.attn.out_proj.bias, roi_head.bbox_head.5.global_attention_norm.weight, roi_head.bbox_head.5.global_attention_norm.bias, roi_head.bbox_head.5.global_ffn.layers.0.0.weight, roi_head.bbox_head.5.global_ffn.layers.0.0.bias, roi_head.bbox_head.5.global_ffn.layers.1.weight, roi_head.bbox_head.5.global_ffn.layers.1.bias, roi_head.bbox_head.5.global_ffn_norm.weight, roi_head.bbox_head.5.global_ffn_norm.bias, roi_head.bbox_head.5.cls_fcs.3.weight, roi_head.bbox_head.5.cls_fcs.4.weight, roi_head.bbox_head.5.cls_fcs.4.bias, roi_head.bbox_head.5.glb_fcs.0.weight, roi_head.bbox_head.5.glb_fcs.1.weight, roi_head.bbox_head.5.glb_fcs.1.bias, roi_head.bbox_head.5.glb_fcs.3.weight, roi_head.bbox_head.5.glb_fcs.4.weight, roi_head.bbox_head.5.glb_fcs.4.bias, roi_head.bbox_head.5.fc_glb.weight, roi_head.bbox_head.5.fc_glb.bias

2021-12-29 14:28:48,316 - mmdet - INFO - Start running, host: user@ubuntu, work_dir: /mnt/home1/workspace2/QueryInst/work_dirs/queryglob_usdanno514roi_B_2_7_split0
2021-12-29 14:28:48,316 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) DistSamplerSeedHook                
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) DistSamplerSeedHook                
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2021-12-29 14:28:48,317 - mmdet - INFO - workflow: [('train', 1)], max: 36 epochs
2021-12-29 14:28:48,317 - mmdet - INFO - Checkpoints will be saved to /mnt/home1/workspace2/QueryInst/work_dirs/queryglob_usdanno514roi_B_2_7_split0 by HardDiskBackend.
2021-12-29 14:29:55,021 - mmdet - INFO - Epoch [1][50/52]	lr: 1.249e-06, eta: 0:40:30, time: 1.334, data_time: 0.215, memory: 8079, stage0_loss_cls: 2.2257, stage0_pos_acc: 52.2500, stage0_loss_bbox: 0.6507, stage0_loss_iou: 1.0033, stage0_loss_global: 0.8165, stage0_loss_mask: 2.3543, stage1_loss_cls: 2.5355, stage1_pos_acc: 51.0000, stage1_loss_bbox: 0.5512, stage1_loss_iou: 0.8869, stage1_loss_global: 1.2134, stage1_loss_mask: 2.4858, stage2_loss_cls: 2.4822, stage2_pos_acc: 57.5000, stage2_loss_bbox: 0.5652, stage2_loss_iou: 0.8849, stage2_loss_global: 1.0896, stage2_loss_mask: 2.2276, stage3_loss_cls: 2.2134, stage3_pos_acc: 52.2500, stage3_loss_bbox: 0.5626, stage3_loss_iou: 0.8714, stage3_loss_global: 0.6841, stage3_loss_mask: 3.8464, stage4_loss_cls: 2.3570, stage4_pos_acc: 56.0000, stage4_loss_bbox: 0.5793, stage4_loss_iou: 0.8880, stage4_loss_global: 0.7596, stage4_loss_mask: 2.4705, stage5_loss_cls: 2.1258, stage5_pos_acc: 51.5000, stage5_loss_bbox: 0.5801, stage5_loss_iou: 0.8868, stage5_loss_global: 0.6085, stage5_loss_mask: 3.3901, loss: 44.7962, grad_norm: 225.5999
2021-12-29 14:29:57,708 - mmdet - INFO - Saving checkpoint at 1 epochs
2021-12-29 14:31:13,189 - mmdet - INFO - Epoch [2][50/52]	lr: 2.547e-06, eta: 0:38:28, time: 1.327, data_time: 0.215, memory: 8583, stage0_loss_cls: 2.0580, stage0_pos_acc: 54.5000, stage0_loss_bbox: 0.5537, stage0_loss_iou: 0.8830, stage0_loss_global: 0.6275, stage0_loss_mask: 2.4254, stage1_loss_cls: 2.3001, stage1_pos_acc: 51.5000, stage1_loss_bbox: 0.4249, stage1_loss_iou: 0.7057, stage1_loss_global: 0.8651, stage1_loss_mask: 2.2564, stage2_loss_cls: 2.2929, stage2_pos_acc: 59.5000, stage2_loss_bbox: 0.4091, stage2_loss_iou: 0.6834, stage2_loss_global: 0.6656, stage2_loss_mask: 1.8391, stage3_loss_cls: 1.9926, stage3_pos_acc: 57.2500, stage3_loss_bbox: 0.4112, stage3_loss_iou: 0.6688, stage3_loss_global: 0.5844, stage3_loss_mask: 3.4928, stage4_loss_cls: 2.0016, stage4_pos_acc: 54.2500, stage4_loss_bbox: 0.4174, stage4_loss_iou: 0.6702, stage4_loss_global: 0.6097, stage4_loss_mask: 2.1047, stage5_loss_cls: 1.8382, stage5_pos_acc: 51.5000, stage5_loss_bbox: 0.4055, stage5_loss_iou: 0.6517, stage5_loss_global: 0.5262, stage5_loss_mask: 3.1178, loss: 38.4828, grad_norm: 215.6345
2021-12-29 14:31:15,846 - mmdet - INFO - Saving checkpoint at 2 epochs
2021-12-29 14:32:32,641 - mmdet - INFO - Epoch [3][50/52]	lr: 3.846e-06, eta: 0:37:23, time: 1.361, data_time: 0.218, memory: 8608, stage0_loss_cls: 1.6554, stage0_pos_acc: 55.2500, stage0_loss_bbox: 0.4796, stage0_loss_iou: 0.7779, stage0_loss_global: 0.5045, stage0_loss_mask: 2.2818, stage1_loss_cls: 1.8421, stage1_pos_acc: 50.5000, stage1_loss_bbox: 0.3151, stage1_loss_iou: 0.5546, stage1_loss_global: 0.5670, stage1_loss_mask: 1.8899, stage2_loss_cls: 1.7285, stage2_pos_acc: 62.0000, stage2_loss_bbox: 0.3072, stage2_loss_iou: 0.5390, stage2_loss_global: 0.5240, stage2_loss_mask: 1.4970, stage3_loss_cls: 1.7018, stage3_pos_acc: 63.7500, stage3_loss_bbox: 0.3165, stage3_loss_iou: 0.5439, stage3_loss_global: 0.5117, stage3_loss_mask: 3.1215, stage4_loss_cls: 1.4428, stage4_pos_acc: 54.0000, stage4_loss_bbox: 0.3172, stage4_loss_iou: 0.5384, stage4_loss_global: 0.4958, stage4_loss_mask: 1.7480, stage5_loss_cls: 1.4068, stage5_pos_acc: 56.0000, stage5_loss_bbox: 0.3103, stage5_loss_iou: 0.5280, stage5_loss_global: 0.4938, stage5_loss_mask: 2.6938, loss: 31.6339, grad_norm: 163.2083
2021-12-29 14:32:35,255 - mmdet - INFO - Saving checkpoint at 3 epochs
2021-12-29 14:33:50,595 - mmdet - INFO - Epoch [4][50/52]	lr: 5.145e-06, eta: 0:36:07, time: 1.337, data_time: 0.222, memory: 8608, stage0_loss_cls: 1.3428, stage0_pos_acc: 61.0000, stage0_loss_bbox: 0.4423, stage0_loss_iou: 0.7334, stage0_loss_global: 0.4672, stage0_loss_mask: 1.8894, stage1_loss_cls: 1.4583, stage1_pos_acc: 55.2500, stage1_loss_bbox: 0.2793, stage1_loss_iou: 0.4842, stage1_loss_global: 0.4775, stage1_loss_mask: 1.5231, stage2_loss_cls: 1.2941, stage2_pos_acc: 63.0000, stage2_loss_bbox: 0.2596, stage2_loss_iou: 0.4549, stage2_loss_global: 0.4679, stage2_loss_mask: 1.1836, stage3_loss_cls: 1.3662, stage3_pos_acc: 74.2500, stage3_loss_bbox: 0.2740, stage3_loss_iou: 0.4760, stage3_loss_global: 0.4570, stage3_loss_mask: 2.5586, stage4_loss_cls: 1.1766, stage4_pos_acc: 68.2500, stage4_loss_bbox: 0.2609, stage4_loss_iou: 0.4557, stage4_loss_global: 0.4608, stage4_loss_mask: 1.4026, stage5_loss_cls: 1.1492, stage5_pos_acc: 62.0000, stage5_loss_bbox: 0.2583, stage5_loss_iou: 0.4504, stage5_loss_global: 0.4490, stage5_loss_mask: 2.2527, loss: 26.2057, grad_norm: 133.3773
2021-12-29 14:33:53,262 - mmdet - INFO - Saving checkpoint at 4 epochs
2021-12-29 14:35:08,476 - mmdet - INFO - Epoch [5][50/52]	lr: 6.444e-06, eta: 0:34:53, time: 1.334, data_time: 0.216, memory: 8608, stage0_loss_cls: 1.2336, stage0_pos_acc: 65.2500, stage0_loss_bbox: 0.3982, stage0_loss_iou: 0.6805, stage0_loss_global: 0.4536, stage0_loss_mask: 1.6072, stage1_loss_cls: 1.2576, stage1_pos_acc: 64.5000, stage1_loss_bbox: 0.2325, stage1_loss_iou: 0.4208, stage1_loss_global: 0.4537, stage1_loss_mask: 1.2637, stage2_loss_cls: 1.1224, stage2_pos_acc: 65.2500, stage2_loss_bbox: 0.2302, stage2_loss_iou: 0.4113, stage2_loss_global: 0.4599, stage2_loss_mask: 1.0182, stage3_loss_cls: 1.0933, stage3_pos_acc: 85.2500, stage3_loss_bbox: 0.2472, stage3_loss_iou: 0.4347, stage3_loss_global: 0.4467, stage3_loss_mask: 2.0857, stage4_loss_cls: 0.9430, stage4_pos_acc: 77.2500, stage4_loss_bbox: 0.2415, stage4_loss_iou: 0.4246, stage4_loss_global: 0.4485, stage4_loss_mask: 1.1809, stage5_loss_cls: 0.9357, stage5_pos_acc: 75.0000, stage5_loss_bbox: 0.2376, stage5_loss_iou: 0.4221, stage5_loss_global: 0.4432, stage5_loss_mask: 1.8336, loss: 22.6619, grad_norm: 128.7272
2021-12-29 14:35:11,071 - mmdet - INFO - Saving checkpoint at 5 epochs
2021-12-29 14:36:26,400 - mmdet - INFO - Epoch [6][50/52]	lr: 7.742e-06, eta: 0:33:42, time: 1.333, data_time: 0.220, memory: 8608, stage0_loss_cls: 1.1375, stage0_pos_acc: 65.2500, stage0_loss_bbox: 0.3849, stage0_loss_iou: 0.6536, stage0_loss_global: 0.4396, stage0_loss_mask: 1.3433, stage1_loss_cls: 1.1097, stage1_pos_acc: 67.0000, stage1_loss_bbox: 0.2239, stage1_loss_iou: 0.3955, stage1_loss_global: 0.4443, stage1_loss_mask: 1.0595, stage2_loss_cls: 0.9491, stage2_pos_acc: 67.0000, stage2_loss_bbox: 0.2330, stage2_loss_iou: 0.4067, stage2_loss_global: 0.4442, stage2_loss_mask: 0.8646, stage3_loss_cls: 0.8889, stage3_pos_acc: 94.0000, stage3_loss_bbox: 0.2416, stage3_loss_iou: 0.4144, stage3_loss_global: 0.4381, stage3_loss_mask: 1.6907, stage4_loss_cls: 0.7440, stage4_pos_acc: 83.2500, stage4_loss_bbox: 0.2456, stage4_loss_iou: 0.4184, stage4_loss_global: 0.4357, stage4_loss_mask: 1.0072, stage5_loss_cls: 0.7276, stage5_pos_acc: 71.5000, stage5_loss_bbox: 0.2470, stage5_loss_iou: 0.4237, stage5_loss_global: 0.4234, stage5_loss_mask: 1.5074, loss: 19.9432, grad_norm: 126.6225
2021-12-29 14:36:29,030 - mmdet - INFO - Saving checkpoint at 6 epochs
2021-12-29 14:37:43,769 - mmdet - INFO - Epoch [7][50/52]	lr: 9.041e-06, eta: 0:32:30, time: 1.326, data_time: 0.214, memory: 8635, stage0_loss_cls: 1.0861, stage0_pos_acc: 62.2500, stage0_loss_bbox: 0.3431, stage0_loss_iou: 0.5978, stage0_loss_global: 0.4468, stage0_loss_mask: 1.1434, stage1_loss_cls: 0.9991, stage1_pos_acc: 70.2500, stage1_loss_bbox: 0.2101, stage1_loss_iou: 0.3786, stage1_loss_global: 0.4418, stage1_loss_mask: 0.8965, stage2_loss_cls: 0.7553, stage2_pos_acc: 64.2500, stage2_loss_bbox: 0.2310, stage2_loss_iou: 0.4158, stage2_loss_global: 0.4464, stage2_loss_mask: 0.7752, stage3_loss_cls: 0.7685, stage3_pos_acc: 97.5000, stage3_loss_bbox: 0.2322, stage3_loss_iou: 0.4045, stage3_loss_global: 0.4417, stage3_loss_mask: 1.3728, stage4_loss_cls: 0.6338, stage4_pos_acc: 73.5000, stage4_loss_bbox: 0.2411, stage4_loss_iou: 0.4234, stage4_loss_global: 0.4396, stage4_loss_mask: 0.9011, stage5_loss_cls: 0.5632, stage5_pos_acc: 69.2500, stage5_loss_bbox: 0.2523, stage5_loss_iou: 0.4411, stage5_loss_global: 0.4379, stage5_loss_mask: 1.2791, loss: 17.9995, grad_norm: 160.3332
2021-12-29 14:37:46,475 - mmdet - INFO - Saving checkpoint at 7 epochs
2021-12-29 14:39:01,704 - mmdet - INFO - Epoch [8][50/52]	lr: 1.034e-05, eta: 0:31:22, time: 1.338, data_time: 0.220, memory: 8635, stage0_loss_cls: 0.9860, stage0_pos_acc: 71.5000, stage0_loss_bbox: 0.3286, stage0_loss_iou: 0.5728, stage0_loss_global: 0.4501, stage0_loss_mask: 0.9977, stage1_loss_cls: 0.8872, stage1_pos_acc: 71.0000, stage1_loss_bbox: 0.2175, stage1_loss_iou: 0.3933, stage1_loss_global: 0.4410, stage1_loss_mask: 0.7911, stage2_loss_cls: 0.6472, stage2_pos_acc: 67.7500, stage2_loss_bbox: 0.2376, stage2_loss_iou: 0.4224, stage2_loss_global: 0.4291, stage2_loss_mask: 0.7095, stage3_loss_cls: 0.7008, stage3_pos_acc: 96.7500, stage3_loss_bbox: 0.2240, stage3_loss_iou: 0.3958, stage3_loss_global: 0.4293, stage3_loss_mask: 1.1539, stage4_loss_cls: 0.5266, stage4_pos_acc: 70.2500, stage4_loss_bbox: 0.2377, stage4_loss_iou: 0.4175, stage4_loss_global: 0.4323, stage4_loss_mask: 0.8025, stage5_loss_cls: 0.4937, stage5_pos_acc: 69.2500, stage5_loss_bbox: 0.2431, stage5_loss_iou: 0.4276, stage5_loss_global: 0.4535, stage5_loss_mask: 1.0662, loss: 16.5155, grad_norm: 131.9831
2021-12-29 14:39:04,442 - mmdet - INFO - Saving checkpoint at 8 epochs
2021-12-29 14:40:19,305 - mmdet - INFO - Epoch [9][50/52]	lr: 1.164e-05, eta: 0:30:12, time: 1.326, data_time: 0.218, memory: 8635, stage0_loss_cls: 0.9120, stage0_pos_acc: 74.0000, stage0_loss_bbox: 0.3200, stage0_loss_iou: 0.5587, stage0_loss_global: 0.4296, stage0_loss_mask: 0.8770, stage1_loss_cls: 0.8209, stage1_pos_acc: 76.0000, stage1_loss_bbox: 0.2201, stage1_loss_iou: 0.3859, stage1_loss_global: 0.4103, stage1_loss_mask: 0.7126, stage2_loss_cls: 0.5673, stage2_pos_acc: 75.7500, stage2_loss_bbox: 0.2311, stage2_loss_iou: 0.4077, stage2_loss_global: 0.3755, stage2_loss_mask: 0.6574, stage3_loss_cls: 0.5967, stage3_pos_acc: 95.2500, stage3_loss_bbox: 0.2308, stage3_loss_iou: 0.3995, stage3_loss_global: 0.3745, stage3_loss_mask: 0.9750, stage4_loss_cls: 0.4559, stage4_pos_acc: 72.7500, stage4_loss_bbox: 0.2419, stage4_loss_iou: 0.4206, stage4_loss_global: 0.3643, stage4_loss_mask: 0.7120, stage5_loss_cls: 0.4342, stage5_pos_acc: 77.5000, stage5_loss_bbox: 0.2450, stage5_loss_iou: 0.4252, stage5_loss_global: 0.3633, stage5_loss_mask: 0.9041, loss: 15.0290, grad_norm: 153.5908
2021-12-29 14:40:22,018 - mmdet - INFO - Saving checkpoint at 9 epochs
2021-12-29 14:41:37,402 - mmdet - INFO - Epoch [10][50/52]	lr: 1.294e-05, eta: 0:29:05, time: 1.342, data_time: 0.218, memory: 8635, stage0_loss_cls: 0.8781, stage0_pos_acc: 77.0000, stage0_loss_bbox: 0.3146, stage0_loss_iou: 0.5478, stage0_loss_global: 0.3888, stage0_loss_mask: 0.7734, stage1_loss_cls: 0.7437, stage1_pos_acc: 76.5000, stage1_loss_bbox: 0.2151, stage1_loss_iou: 0.3861, stage1_loss_global: 0.3388, stage1_loss_mask: 0.6717, stage2_loss_cls: 0.4990, stage2_pos_acc: 80.0000, stage2_loss_bbox: 0.2304, stage2_loss_iou: 0.4062, stage2_loss_global: 0.3001, stage2_loss_mask: 0.6298, stage3_loss_cls: 0.5216, stage3_pos_acc: 97.7500, stage3_loss_bbox: 0.2245, stage3_loss_iou: 0.3898, stage3_loss_global: 0.2945, stage3_loss_mask: 0.8617, stage4_loss_cls: 0.3911, stage4_pos_acc: 80.5000, stage4_loss_bbox: 0.2363, stage4_loss_iou: 0.4126, stage4_loss_global: 0.2961, stage4_loss_mask: 0.6785, stage5_loss_cls: 0.3628, stage5_pos_acc: 84.5000, stage5_loss_bbox: 0.2416, stage5_loss_iou: 0.4152, stage5_loss_global: 0.2900, stage5_loss_mask: 0.8125, loss: 13.7524, grad_norm: 205.4366
2021-12-29 14:41:40,053 - mmdet - INFO - Saving checkpoint at 10 epochs
2021-12-29 14:42:55,689 - mmdet - INFO - Epoch [11][50/52]	lr: 1.424e-05, eta: 0:27:59, time: 1.346, data_time: 0.219, memory: 8635, stage0_loss_cls: 0.8161, stage0_pos_acc: 86.5000, stage0_loss_bbox: 0.3133, stage0_loss_iou: 0.5569, stage0_loss_global: 0.3162, stage0_loss_mask: 0.7584, stage1_loss_cls: 0.6624, stage1_pos_acc: 84.5000, stage1_loss_bbox: 0.2241, stage1_loss_iou: 0.3983, stage1_loss_global: 0.2845, stage1_loss_mask: 0.6375, stage2_loss_cls: 0.4427, stage2_pos_acc: 86.5000, stage2_loss_bbox: 0.2326, stage2_loss_iou: 0.4125, stage2_loss_global: 0.2750, stage2_loss_mask: 0.5996, stage3_loss_cls: 0.4739, stage3_pos_acc: 97.5000, stage3_loss_bbox: 0.2225, stage3_loss_iou: 0.3915, stage3_loss_global: 0.2643, stage3_loss_mask: 0.7927, stage4_loss_cls: 0.3380, stage4_pos_acc: 86.0000, stage4_loss_bbox: 0.2379, stage4_loss_iou: 0.4132, stage4_loss_global: 0.2600, stage4_loss_mask: 0.6463, stage5_loss_cls: 0.3335, stage5_pos_acc: 88.0000, stage5_loss_bbox: 0.2377, stage5_loss_iou: 0.4104, stage5_loss_global: 0.2597, stage5_loss_mask: 0.7629, loss: 12.9748, grad_norm: 272.0923
2021-12-29 14:42:58,436 - mmdet - INFO - Saving checkpoint at 11 epochs
2021-12-29 14:44:14,162 - mmdet - INFO - Epoch [12][50/52]	lr: 1.553e-05, eta: 0:26:52, time: 1.343, data_time: 0.221, memory: 8635, stage0_loss_cls: 0.7657, stage0_pos_acc: 88.7500, stage0_loss_bbox: 0.3106, stage0_loss_iou: 0.5423, stage0_loss_global: 0.2160, stage0_loss_mask: 0.7220, stage1_loss_cls: 0.5839, stage1_pos_acc: 89.2500, stage1_loss_bbox: 0.2423, stage1_loss_iou: 0.4120, stage1_loss_global: 0.1756, stage1_loss_mask: 0.6341, stage2_loss_cls: 0.4035, stage2_pos_acc: 89.2500, stage2_loss_bbox: 0.2409, stage2_loss_iou: 0.4126, stage2_loss_global: 0.1577, stage2_loss_mask: 0.5987, stage3_loss_cls: 0.4158, stage3_pos_acc: 96.7500, stage3_loss_bbox: 0.2367, stage3_loss_iou: 0.4009, stage3_loss_global: 0.1524, stage3_loss_mask: 0.7565, stage4_loss_cls: 0.2961, stage4_pos_acc: 91.2500, stage4_loss_bbox: 0.2478, stage4_loss_iou: 0.4145, stage4_loss_global: 0.1501, stage4_loss_mask: 0.6135, stage5_loss_cls: 0.2753, stage5_pos_acc: 90.7500, stage5_loss_bbox: 0.2550, stage5_loss_iou: 0.4221, stage5_loss_global: 0.1485, stage5_loss_mask: 0.7091, loss: 11.9121, grad_norm: 239.3517
2021-12-29 14:44:16,792 - mmdet - INFO - Saving checkpoint at 12 epochs
2021-12-29 14:45:32,504 - mmdet - INFO - Epoch [13][50/52]	lr: 1.683e-05, eta: 0:25:46, time: 1.349, data_time: 0.220, memory: 8635, stage0_loss_cls: 0.7682, stage0_pos_acc: 84.0000, stage0_loss_bbox: 0.3114, stage0_loss_iou: 0.5427, stage0_loss_global: 0.2489, stage0_loss_mask: 0.6808, stage1_loss_cls: 0.5807, stage1_pos_acc: 83.7500, stage1_loss_bbox: 0.2283, stage1_loss_iou: 0.4066, stage1_loss_global: 0.2573, stage1_loss_mask: 0.6179, stage2_loss_cls: 0.4094, stage2_pos_acc: 83.7500, stage2_loss_bbox: 0.2261, stage2_loss_iou: 0.4013, stage2_loss_global: 0.2640, stage2_loss_mask: 0.5884, stage3_loss_cls: 0.4307, stage3_pos_acc: 92.0000, stage3_loss_bbox: 0.2219, stage3_loss_iou: 0.3891, stage3_loss_global: 0.2787, stage3_loss_mask: 0.7145, stage4_loss_cls: 0.3276, stage4_pos_acc: 86.0000, stage4_loss_bbox: 0.2265, stage4_loss_iou: 0.3955, stage4_loss_global: 0.2805, stage4_loss_mask: 0.6081, stage5_loss_cls: 0.3239, stage5_pos_acc: 86.7500, stage5_loss_bbox: 0.2270, stage5_loss_iou: 0.3962, stage5_loss_global: 0.2840, stage5_loss_mask: 0.6819, loss: 12.3181, grad_norm: 339.1142
2021-12-29 14:45:35,182 - mmdet - INFO - Saving checkpoint at 13 epochs
2021-12-29 14:46:51,541 - mmdet - INFO - Epoch [14][50/52]	lr: 1.813e-05, eta: 0:24:40, time: 1.361, data_time: 0.227, memory: 8635, stage0_loss_cls: 0.7031, stage0_pos_acc: 93.0000, stage0_loss_bbox: 0.3249, stage0_loss_iou: 0.5794, stage0_loss_global: 0.1486, stage0_loss_mask: 0.6795, stage1_loss_cls: 0.5171, stage1_pos_acc: 91.7500, stage1_loss_bbox: 0.2327, stage1_loss_iou: 0.4137, stage1_loss_global: 0.1339, stage1_loss_mask: 0.6117, stage2_loss_cls: 0.3513, stage2_pos_acc: 92.0000, stage2_loss_bbox: 0.2291, stage2_loss_iou: 0.4090, stage2_loss_global: 0.1323, stage2_loss_mask: 0.5818, stage3_loss_cls: 0.3526, stage3_pos_acc: 95.5000, stage3_loss_bbox: 0.2244, stage3_loss_iou: 0.4039, stage3_loss_global: 0.1323, stage3_loss_mask: 0.6796, stage4_loss_cls: 0.2709, stage4_pos_acc: 93.5000, stage4_loss_bbox: 0.2296, stage4_loss_iou: 0.4073, stage4_loss_global: 0.1329, stage4_loss_mask: 0.5861, stage5_loss_cls: 0.2483, stage5_pos_acc: 93.0000, stage5_loss_bbox: 0.2329, stage5_loss_iou: 0.4090, stage5_loss_global: 0.1340, stage5_loss_mask: 0.6537, loss: 11.1456, grad_norm: 256.1077
2021-12-29 14:46:54,225 - mmdet - INFO - Saving checkpoint at 14 epochs
2021-12-29 14:48:09,654 - mmdet - INFO - Epoch [15][50/52]	lr: 1.943e-05, eta: 0:23:32, time: 1.330, data_time: 0.216, memory: 8635, stage0_loss_cls: 0.7066, stage0_pos_acc: 92.7500, stage0_loss_bbox: 0.3149, stage0_loss_iou: 0.5542, stage0_loss_global: 0.1908, stage0_loss_mask: 0.6566, stage1_loss_cls: 0.5249, stage1_pos_acc: 91.0000, stage1_loss_bbox: 0.2281, stage1_loss_iou: 0.4036, stage1_loss_global: 0.1917, stage1_loss_mask: 0.5805, stage2_loss_cls: 0.3457, stage2_pos_acc: 90.2500, stage2_loss_bbox: 0.2309, stage2_loss_iou: 0.4029, stage2_loss_global: 0.1891, stage2_loss_mask: 0.5838, stage3_loss_cls: 0.3259, stage3_pos_acc: 92.2500, stage3_loss_bbox: 0.2275, stage3_loss_iou: 0.3973, stage3_loss_global: 0.1915, stage3_loss_mask: 0.6504, stage4_loss_cls: 0.2732, stage4_pos_acc: 92.2500, stage4_loss_bbox: 0.2289, stage4_loss_iou: 0.3985, stage4_loss_global: 0.1925, stage4_loss_mask: 0.5795, stage5_loss_cls: 0.2550, stage5_pos_acc: 92.0000, stage5_loss_bbox: 0.2339, stage5_loss_iou: 0.4032, stage5_loss_global: 0.1985, stage5_loss_mask: 0.6342, loss: 11.2943, grad_norm: 213.4441
2021-12-29 14:48:12,403 - mmdet - INFO - Saving checkpoint at 15 epochs
2021-12-29 14:49:28,204 - mmdet - INFO - Epoch [16][50/52]	lr: 2.073e-05, eta: 0:22:25, time: 1.348, data_time: 0.218, memory: 8635, stage0_loss_cls: 0.6930, stage0_pos_acc: 94.0000, stage0_loss_bbox: 0.3078, stage0_loss_iou: 0.5414, stage0_loss_global: 0.1022, stage0_loss_mask: 0.5972, stage1_loss_cls: 0.4651, stage1_pos_acc: 94.2500, stage1_loss_bbox: 0.2228, stage1_loss_iou: 0.3939, stage1_loss_global: 0.0964, stage1_loss_mask: 0.5579, stage2_loss_cls: 0.2923, stage2_pos_acc: 96.2500, stage2_loss_bbox: 0.2218, stage2_loss_iou: 0.3878, stage2_loss_global: 0.0913, stage2_loss_mask: 0.5477, stage3_loss_cls: 0.2521, stage3_pos_acc: 97.2500, stage3_loss_bbox: 0.2244, stage3_loss_iou: 0.3878, stage3_loss_global: 0.0950, stage3_loss_mask: 0.6184, stage4_loss_cls: 0.2360, stage4_pos_acc: 97.0000, stage4_loss_bbox: 0.2196, stage4_loss_iou: 0.3820, stage4_loss_global: 0.0900, stage4_loss_mask: 0.5631, stage5_loss_cls: 0.2232, stage5_pos_acc: 96.0000, stage5_loss_bbox: 0.2231, stage5_loss_iou: 0.3864, stage5_loss_global: 0.0880, stage5_loss_mask: 0.6109, loss: 10.1186, grad_norm: 177.5164
2021-12-29 14:49:30,803 - mmdet - INFO - Saving checkpoint at 16 epochs
2021-12-29 14:50:46,935 - mmdet - INFO - Epoch [17][50/52]	lr: 2.203e-05, eta: 0:21:19, time: 1.355, data_time: 0.217, memory: 8635, stage0_loss_cls: 0.6539, stage0_pos_acc: 92.5000, stage0_loss_bbox: 0.3090, stage0_loss_iou: 0.5369, stage0_loss_global: 0.1263, stage0_loss_mask: 0.5866, stage1_loss_cls: 0.4494, stage1_pos_acc: 92.2500, stage1_loss_bbox: 0.2241, stage1_loss_iou: 0.3879, stage1_loss_global: 0.1281, stage1_loss_mask: 0.5407, stage2_loss_cls: 0.2790, stage2_pos_acc: 92.0000, stage2_loss_bbox: 0.2248, stage2_loss_iou: 0.3859, stage2_loss_global: 0.1378, stage2_loss_mask: 0.5323, stage3_loss_cls: 0.2467, stage3_pos_acc: 90.2500, stage3_loss_bbox: 0.2230, stage3_loss_iou: 0.3842, stage3_loss_global: 0.1360, stage3_loss_mask: 0.5874, stage4_loss_cls: 0.2156, stage4_pos_acc: 92.5000, stage4_loss_bbox: 0.2207, stage4_loss_iou: 0.3812, stage4_loss_global: 0.1493, stage4_loss_mask: 0.5460, stage5_loss_cls: 0.2114, stage5_pos_acc: 93.2500, stage5_loss_bbox: 0.2242, stage5_loss_iou: 0.3838, stage5_loss_global: 0.1534, stage5_loss_mask: 0.5807, loss: 10.1465, grad_norm: 286.8640
2021-12-29 14:50:49,633 - mmdet - INFO - Saving checkpoint at 17 epochs
2021-12-29 14:52:05,287 - mmdet - INFO - Epoch [18][50/52]	lr: 2.333e-05, eta: 0:20:12, time: 1.347, data_time: 0.219, memory: 8635, stage0_loss_cls: 0.6466, stage0_pos_acc: 95.7500, stage0_loss_bbox: 0.3117, stage0_loss_iou: 0.5583, stage0_loss_global: 0.0841, stage0_loss_mask: 0.6095, stage1_loss_cls: 0.4283, stage1_pos_acc: 95.5000, stage1_loss_bbox: 0.2226, stage1_loss_iou: 0.3911, stage1_loss_global: 0.0831, stage1_loss_mask: 0.5374, stage2_loss_cls: 0.2655, stage2_pos_acc: 96.2500, stage2_loss_bbox: 0.2152, stage2_loss_iou: 0.3802, stage2_loss_global: 0.0789, stage2_loss_mask: 0.5310, stage3_loss_cls: 0.2299, stage3_pos_acc: 96.7500, stage3_loss_bbox: 0.2178, stage3_loss_iou: 0.3818, stage3_loss_global: 0.0799, stage3_loss_mask: 0.5857, stage4_loss_cls: 0.2254, stage4_pos_acc: 96.2500, stage4_loss_bbox: 0.2112, stage4_loss_iou: 0.3707, stage4_loss_global: 0.0830, stage4_loss_mask: 0.5261, stage5_loss_cls: 0.2194, stage5_pos_acc: 95.7500, stage5_loss_bbox: 0.2111, stage5_loss_iou: 0.3733, stage5_loss_global: 0.0817, stage5_loss_mask: 0.5614, loss: 9.7019, grad_norm: 193.8616
2021-12-29 14:52:08,115 - mmdet - INFO - Saving checkpoint at 18 epochs
2021-12-29 14:53:23,571 - mmdet - INFO - Epoch [19][50/52]	lr: 2.463e-05, eta: 0:19:04, time: 1.340, data_time: 0.221, memory: 8635, stage0_loss_cls: 0.6000, stage0_pos_acc: 93.5000, stage0_loss_bbox: 0.3191, stage0_loss_iou: 0.5621, stage0_loss_global: 0.1056, stage0_loss_mask: 0.5789, stage1_loss_cls: 0.4117, stage1_pos_acc: 96.0000, stage1_loss_bbox: 0.2257, stage1_loss_iou: 0.3976, stage1_loss_global: 0.1102, stage1_loss_mask: 0.5512, stage2_loss_cls: 0.2700, stage2_pos_acc: 95.2500, stage2_loss_bbox: 0.2277, stage2_loss_iou: 0.3985, stage2_loss_global: 0.1092, stage2_loss_mask: 0.5443, stage3_loss_cls: 0.2363, stage3_pos_acc: 94.0000, stage3_loss_bbox: 0.2265, stage3_loss_iou: 0.3966, stage3_loss_global: 0.1131, stage3_loss_mask: 0.5986, stage4_loss_cls: 0.1984, stage4_pos_acc: 94.0000, stage4_loss_bbox: 0.2297, stage4_loss_iou: 0.3996, stage4_loss_global: 0.1145, stage4_loss_mask: 0.5696, stage5_loss_cls: 0.1831, stage5_pos_acc: 94.2500, stage5_loss_bbox: 0.2323, stage5_loss_iou: 0.4019, stage5_loss_global: 0.1209, stage5_loss_mask: 0.5896, loss: 10.0227, grad_norm: 284.2618
2021-12-29 14:53:26,211 - mmdet - INFO - Saving checkpoint at 19 epochs
2021-12-29 14:54:40,994 - mmdet - INFO - Epoch [20][50/52]	lr: 2.500e-05, eta: 0:17:56, time: 1.329, data_time: 0.220, memory: 8635, stage0_loss_cls: 0.5542, stage0_pos_acc: 94.2500, stage0_loss_bbox: 0.3342, stage0_loss_iou: 0.5843, stage0_loss_global: 0.0735, stage0_loss_mask: 0.5968, stage1_loss_cls: 0.3747, stage1_pos_acc: 95.2500, stage1_loss_bbox: 0.2524, stage1_loss_iou: 0.4371, stage1_loss_global: 0.0732, stage1_loss_mask: 0.5649, stage2_loss_cls: 0.2392, stage2_pos_acc: 96.2500, stage2_loss_bbox: 0.2333, stage2_loss_iou: 0.4070, stage2_loss_global: 0.0742, stage2_loss_mask: 0.5462, stage3_loss_cls: 0.1915, stage3_pos_acc: 96.5000, stage3_loss_bbox: 0.2265, stage3_loss_iou: 0.3964, stage3_loss_global: 0.0791, stage3_loss_mask: 0.5689, stage4_loss_cls: 0.1734, stage4_pos_acc: 96.7500, stage4_loss_bbox: 0.2264, stage4_loss_iou: 0.3952, stage4_loss_global: 0.0781, stage4_loss_mask: 0.5451, stage5_loss_cls: 0.1644, stage5_pos_acc: 96.2500, stage5_loss_bbox: 0.2272, stage5_loss_iou: 0.3976, stage5_loss_global: 0.0773, stage5_loss_mask: 0.5867, loss: 9.6787, grad_norm: 218.9054
2021-12-29 14:54:43,775 - mmdet - INFO - Saving checkpoint at 20 epochs
2021-12-29 14:55:59,626 - mmdet - INFO - Epoch [21][50/52]	lr: 2.500e-05, eta: 0:16:49, time: 1.348, data_time: 0.214, memory: 8635, stage0_loss_cls: 0.5821, stage0_pos_acc: 94.2500, stage0_loss_bbox: 0.3214, stage0_loss_iou: 0.5638, stage0_loss_global: 0.0746, stage0_loss_mask: 0.5129, stage1_loss_cls: 0.3562, stage1_pos_acc: 96.0000, stage1_loss_bbox: 0.2416, stage1_loss_iou: 0.4076, stage1_loss_global: 0.0764, stage1_loss_mask: 0.5257, stage2_loss_cls: 0.2123, stage2_pos_acc: 96.5000, stage2_loss_bbox: 0.2353, stage2_loss_iou: 0.3942, stage2_loss_global: 0.0720, stage2_loss_mask: 0.5252, stage3_loss_cls: 0.1955, stage3_pos_acc: 96.2500, stage3_loss_bbox: 0.2320, stage3_loss_iou: 0.3897, stage3_loss_global: 0.0720, stage3_loss_mask: 0.5538, stage4_loss_cls: 0.1689, stage4_pos_acc: 97.5000, stage4_loss_bbox: 0.2302, stage4_loss_iou: 0.3862, stage4_loss_global: 0.0693, stage4_loss_mask: 0.5185, stage5_loss_cls: 0.1597, stage5_pos_acc: 97.7500, stage5_loss_bbox: 0.2298, stage5_loss_iou: 0.3864, stage5_loss_global: 0.0718, stage5_loss_mask: 0.5402, loss: 9.3051, grad_norm: 231.8438
2021-12-29 14:56:02,358 - mmdet - INFO - Saving checkpoint at 21 epochs
2021-12-29 14:57:18,128 - mmdet - INFO - Epoch [22][50/52]	lr: 2.500e-05, eta: 0:15:42, time: 1.341, data_time: 0.223, memory: 8635, stage0_loss_cls: 0.5360, stage0_pos_acc: 95.5000, stage0_loss_bbox: 0.3231, stage0_loss_iou: 0.5728, stage0_loss_global: 0.1127, stage0_loss_mask: 0.5738, stage1_loss_cls: 0.3396, stage1_pos_acc: 95.2500, stage1_loss_bbox: 0.2353, stage1_loss_iou: 0.4126, stage1_loss_global: 0.1183, stage1_loss_mask: 0.5378, stage2_loss_cls: 0.2312, stage2_pos_acc: 95.2500, stage2_loss_bbox: 0.2401, stage2_loss_iou: 0.4120, stage2_loss_global: 0.1173, stage2_loss_mask: 0.5452, stage3_loss_cls: 0.2126, stage3_pos_acc: 95.0000, stage3_loss_bbox: 0.2372, stage3_loss_iou: 0.4086, stage3_loss_global: 0.1225, stage3_loss_mask: 0.5680, stage4_loss_cls: 0.1807, stage4_pos_acc: 95.5000, stage4_loss_bbox: 0.2374, stage4_loss_iou: 0.4069, stage4_loss_global: 0.1223, stage4_loss_mask: 0.5745, stage5_loss_cls: 0.1696, stage5_pos_acc: 95.2500, stage5_loss_bbox: 0.2406, stage5_loss_iou: 0.4121, stage5_loss_global: 0.1374, stage5_loss_mask: 0.5948, loss: 9.9330, grad_norm: 640.0570
2021-12-29 14:57:20,807 - mmdet - INFO - Saving checkpoint at 22 epochs
2021-12-29 14:58:35,966 - mmdet - INFO - Epoch [23][50/52]	lr: 2.500e-05, eta: 0:14:35, time: 1.335, data_time: 0.220, memory: 8635, stage0_loss_cls: 0.5046, stage0_pos_acc: 96.0000, stage0_loss_bbox: 0.3264, stage0_loss_iou: 0.5719, stage0_loss_global: 0.0938, stage0_loss_mask: 0.5141, stage1_loss_cls: 0.3455, stage1_pos_acc: 96.7500, stage1_loss_bbox: 0.2234, stage1_loss_iou: 0.3955, stage1_loss_global: 0.0936, stage1_loss_mask: 0.4990, stage2_loss_cls: 0.2182, stage2_pos_acc: 97.2500, stage2_loss_bbox: 0.2202, stage2_loss_iou: 0.3846, stage2_loss_global: 0.0877, stage2_loss_mask: 0.5015, stage3_loss_cls: 0.1852, stage3_pos_acc: 96.7500, stage3_loss_bbox: 0.2153, stage3_loss_iou: 0.3750, stage3_loss_global: 0.0817, stage3_loss_mask: 0.5148, stage4_loss_cls: 0.1570, stage4_pos_acc: 96.5000, stage4_loss_bbox: 0.2222, stage4_loss_iou: 0.3820, stage4_loss_global: 0.0827, stage4_loss_mask: 0.5174, stage5_loss_cls: 0.1542, stage5_pos_acc: 97.2500, stage5_loss_bbox: 0.2182, stage5_loss_iou: 0.3791, stage5_loss_global: 0.0856, stage5_loss_mask: 0.5318, loss: 9.0822, grad_norm: 442.6565
2021-12-29 14:58:38,674 - mmdet - INFO - Saving checkpoint at 23 epochs
2021-12-29 14:59:53,408 - mmdet - INFO - Epoch [24][50/52]	lr: 2.500e-05, eta: 0:13:27, time: 1.326, data_time: 0.219, memory: 8635, stage0_loss_cls: 0.4792, stage0_pos_acc: 95.2500, stage0_loss_bbox: 0.3356, stage0_loss_iou: 0.5923, stage0_loss_global: 0.0867, stage0_loss_mask: 0.5466, stage1_loss_cls: 0.3471, stage1_pos_acc: 96.7500, stage1_loss_bbox: 0.2162, stage1_loss_iou: 0.3835, stage1_loss_global: 0.0864, stage1_loss_mask: 0.4898, stage2_loss_cls: 0.1598, stage2_pos_acc: 96.7500, stage2_loss_bbox: 0.2229, stage2_loss_iou: 0.3842, stage2_loss_global: 0.0788, stage2_loss_mask: 0.5070, stage3_loss_cls: 0.1291, stage3_pos_acc: 97.0000, stage3_loss_bbox: 0.2173, stage3_loss_iou: 0.3765, stage3_loss_global: 0.0756, stage3_loss_mask: 0.5208, stage4_loss_cls: 0.1272, stage4_pos_acc: 96.7500, stage4_loss_bbox: 0.2147, stage4_loss_iou: 0.3722, stage4_loss_global: 0.0706, stage4_loss_mask: 0.4970, stage5_loss_cls: 0.1191, stage5_pos_acc: 96.2500, stage5_loss_bbox: 0.2160, stage5_loss_iou: 0.3735, stage5_loss_global: 0.0707, stage5_loss_mask: 0.5093, loss: 8.8058, grad_norm: 322.7458
2021-12-29 14:59:55,994 - mmdet - INFO - Saving checkpoint at 24 epochs
2021-12-29 15:01:11,046 - mmdet - INFO - Epoch [25][50/52]	lr: 2.500e-05, eta: 0:12:20, time: 1.335, data_time: 0.223, memory: 8635, stage0_loss_cls: 0.4311, stage0_pos_acc: 94.7500, stage0_loss_bbox: 0.3121, stage0_loss_iou: 0.5390, stage0_loss_global: 0.0660, stage0_loss_mask: 0.5279, stage1_loss_cls: 0.2688, stage1_pos_acc: 97.2500, stage1_loss_bbox: 0.2308, stage1_loss_iou: 0.3905, stage1_loss_global: 0.0654, stage1_loss_mask: 0.4990, stage2_loss_cls: 0.1817, stage2_pos_acc: 96.2500, stage2_loss_bbox: 0.2193, stage2_loss_iou: 0.3750, stage2_loss_global: 0.0680, stage2_loss_mask: 0.4949, stage3_loss_cls: 0.1361, stage3_pos_acc: 96.7500, stage3_loss_bbox: 0.2173, stage3_loss_iou: 0.3709, stage3_loss_global: 0.0663, stage3_loss_mask: 0.5122, stage4_loss_cls: 0.1207, stage4_pos_acc: 97.2500, stage4_loss_bbox: 0.2171, stage4_loss_iou: 0.3698, stage4_loss_global: 0.0720, stage4_loss_mask: 0.4922, stage5_loss_cls: 0.1186, stage5_pos_acc: 97.0000, stage5_loss_bbox: 0.2185, stage5_loss_iou: 0.3698, stage5_loss_global: 0.0737, stage5_loss_mask: 0.5057, loss: 8.5304, grad_norm: 215.7316
2021-12-29 15:01:13,751 - mmdet - INFO - Saving checkpoint at 25 epochs
2021-12-29 15:02:29,849 - mmdet - INFO - Epoch [26][50/52]	lr: 2.500e-05, eta: 0:11:13, time: 1.349, data_time: 0.218, memory: 8635, stage0_loss_cls: 0.4162, stage0_pos_acc: 94.0000, stage0_loss_bbox: 0.3364, stage0_loss_iou: 0.5919, stage0_loss_global: 0.0773, stage0_loss_mask: 0.5411, stage1_loss_cls: 0.2710, stage1_pos_acc: 98.0000, stage1_loss_bbox: 0.2338, stage1_loss_iou: 0.4029, stage1_loss_global: 0.0783, stage1_loss_mask: 0.5332, stage2_loss_cls: 0.1730, stage2_pos_acc: 98.0000, stage2_loss_bbox: 0.2227, stage2_loss_iou: 0.3846, stage2_loss_global: 0.0787, stage2_loss_mask: 0.5141, stage3_loss_cls: 0.1356, stage3_pos_acc: 97.5000, stage3_loss_bbox: 0.2249, stage3_loss_iou: 0.3876, stage3_loss_global: 0.0764, stage3_loss_mask: 0.5411, stage4_loss_cls: 0.1240, stage4_pos_acc: 97.5000, stage4_loss_bbox: 0.2245, stage4_loss_iou: 0.3889, stage4_loss_global: 0.0775, stage4_loss_mask: 0.5205, stage5_loss_cls: 0.1253, stage5_pos_acc: 97.7500, stage5_loss_bbox: 0.2227, stage5_loss_iou: 0.3879, stage5_loss_global: 0.0803, stage5_loss_mask: 0.5255, loss: 8.8977, grad_norm: 183.8044
2021-12-29 15:02:32,695 - mmdet - INFO - Saving checkpoint at 26 epochs
2021-12-29 15:03:47,681 - mmdet - INFO - Epoch [27][50/52]	lr: 2.500e-05, eta: 0:10:06, time: 1.326, data_time: 0.216, memory: 8635, stage0_loss_cls: 0.3862, stage0_pos_acc: 93.0000, stage0_loss_bbox: 0.3235, stage0_loss_iou: 0.5843, stage0_loss_global: 0.1061, stage0_loss_mask: 0.5284, stage1_loss_cls: 0.2531, stage1_pos_acc: 95.2500, stage1_loss_bbox: 0.2212, stage1_loss_iou: 0.3906, stage1_loss_global: 0.1048, stage1_loss_mask: 0.5093, stage2_loss_cls: 0.1639, stage2_pos_acc: 95.5000, stage2_loss_bbox: 0.2144, stage2_loss_iou: 0.3719, stage2_loss_global: 0.1022, stage2_loss_mask: 0.4902, stage3_loss_cls: 0.1486, stage3_pos_acc: 96.2500, stage3_loss_bbox: 0.2161, stage3_loss_iou: 0.3744, stage3_loss_global: 0.0964, stage3_loss_mask: 0.4997, stage4_loss_cls: 0.1183, stage4_pos_acc: 95.2500, stage4_loss_bbox: 0.2216, stage4_loss_iou: 0.3785, stage4_loss_global: 0.0917, stage4_loss_mask: 0.4898, stage5_loss_cls: 0.1252, stage5_pos_acc: 96.0000, stage5_loss_bbox: 0.2201, stage5_loss_iou: 0.3760, stage5_loss_global: 0.0927, stage5_loss_mask: 0.5002, loss: 8.6995, grad_norm: 503.9233
2021-12-29 15:03:50,405 - mmdet - INFO - Saving checkpoint at 27 epochs
2021-12-29 15:05:04,494 - mmdet - INFO - Epoch [28][50/52]	lr: 2.500e-06, eta: 0:08:58, time: 1.322, data_time: 0.218, memory: 8635, stage0_loss_cls: 0.3101, stage0_pos_acc: 97.5000, stage0_loss_bbox: 0.3104, stage0_loss_iou: 0.5522, stage0_loss_global: 0.0424, stage0_loss_mask: 0.5138, stage1_loss_cls: 0.2203, stage1_pos_acc: 98.0000, stage1_loss_bbox: 0.2215, stage1_loss_iou: 0.3800, stage1_loss_global: 0.0454, stage1_loss_mask: 0.5070, stage2_loss_cls: 0.1357, stage2_pos_acc: 97.0000, stage2_loss_bbox: 0.2104, stage2_loss_iou: 0.3624, stage2_loss_global: 0.0430, stage2_loss_mask: 0.4838, stage3_loss_cls: 0.0970, stage3_pos_acc: 98.2500, stage3_loss_bbox: 0.2065, stage3_loss_iou: 0.3548, stage3_loss_global: 0.0410, stage3_loss_mask: 0.4876, stage4_loss_cls: 0.0756, stage4_pos_acc: 98.2500, stage4_loss_bbox: 0.2093, stage4_loss_iou: 0.3567, stage4_loss_global: 0.0399, stage4_loss_mask: 0.4886, stage5_loss_cls: 0.0724, stage5_pos_acc: 98.5000, stage5_loss_bbox: 0.2110, stage5_loss_iou: 0.3570, stage5_loss_global: 0.0413, stage5_loss_mask: 0.4937, loss: 7.8708, grad_norm: 127.5905
2021-12-29 15:05:07,159 - mmdet - INFO - Saving checkpoint at 28 epochs
2021-12-29 15:06:21,958 - mmdet - INFO - Epoch [29][50/52]	lr: 2.500e-06, eta: 0:07:51, time: 1.332, data_time: 0.221, memory: 8635, stage0_loss_cls: 0.3249, stage0_pos_acc: 97.0000, stage0_loss_bbox: 0.2883, stage0_loss_iou: 0.5216, stage0_loss_global: 0.0437, stage0_loss_mask: 0.4984, stage1_loss_cls: 0.2127, stage1_pos_acc: 98.2500, stage1_loss_bbox: 0.2079, stage1_loss_iou: 0.3696, stage1_loss_global: 0.0429, stage1_loss_mask: 0.4880, stage2_loss_cls: 0.1343, stage2_pos_acc: 98.2500, stage2_loss_bbox: 0.1957, stage2_loss_iou: 0.3485, stage2_loss_global: 0.0382, stage2_loss_mask: 0.4689, stage3_loss_cls: 0.0978, stage3_pos_acc: 98.7500, stage3_loss_bbox: 0.1945, stage3_loss_iou: 0.3446, stage3_loss_global: 0.0381, stage3_loss_mask: 0.4815, stage4_loss_cls: 0.0905, stage4_pos_acc: 98.5000, stage4_loss_bbox: 0.1909, stage4_loss_iou: 0.3403, stage4_loss_global: 0.0361, stage4_loss_mask: 0.4637, stage5_loss_cls: 0.0762, stage5_pos_acc: 98.5000, stage5_loss_bbox: 0.1940, stage5_loss_iou: 0.3417, stage5_loss_global: 0.0381, stage5_loss_mask: 0.4789, loss: 7.5908, grad_norm: 169.6262
2021-12-29 15:06:24,619 - mmdet - INFO - Saving checkpoint at 29 epochs
2021-12-29 15:07:39,764 - mmdet - INFO - Epoch [30][50/52]	lr: 2.500e-06, eta: 0:06:44, time: 1.341, data_time: 0.219, memory: 8635, stage0_loss_cls: 0.2914, stage0_pos_acc: 99.0000, stage0_loss_bbox: 0.2859, stage0_loss_iou: 0.5139, stage0_loss_global: 0.0456, stage0_loss_mask: 0.5221, stage1_loss_cls: 0.1944, stage1_pos_acc: 98.2500, stage1_loss_bbox: 0.2135, stage1_loss_iou: 0.3786, stage1_loss_global: 0.0423, stage1_loss_mask: 0.4965, stage2_loss_cls: 0.1113, stage2_pos_acc: 98.2500, stage2_loss_bbox: 0.1958, stage2_loss_iou: 0.3541, stage2_loss_global: 0.0384, stage2_loss_mask: 0.4745, stage3_loss_cls: 0.0858, stage3_pos_acc: 98.7500, stage3_loss_bbox: 0.1964, stage3_loss_iou: 0.3528, stage3_loss_global: 0.0327, stage3_loss_mask: 0.4850, stage4_loss_cls: 0.0672, stage4_pos_acc: 98.7500, stage4_loss_bbox: 0.1963, stage4_loss_iou: 0.3516, stage4_loss_global: 0.0285, stage4_loss_mask: 0.4758, stage5_loss_cls: 0.0622, stage5_pos_acc: 99.0000, stage5_loss_bbox: 0.1968, stage5_loss_iou: 0.3515, stage5_loss_global: 0.0270, stage5_loss_mask: 0.4892, loss: 7.5573, grad_norm: 118.1148
2021-12-29 15:07:42,450 - mmdet - INFO - Saving checkpoint at 30 epochs
2021-12-29 15:08:58,207 - mmdet - INFO - Epoch [31][50/52]	lr: 2.500e-06, eta: 0:05:37, time: 1.349, data_time: 0.214, memory: 8635, stage0_loss_cls: 0.3054, stage0_pos_acc: 97.7500, stage0_loss_bbox: 0.2720, stage0_loss_iou: 0.4960, stage0_loss_global: 0.0334, stage0_loss_mask: 0.4853, stage1_loss_cls: 0.1817, stage1_pos_acc: 99.0000, stage1_loss_bbox: 0.2123, stage1_loss_iou: 0.3680, stage1_loss_global: 0.0314, stage1_loss_mask: 0.4846, stage2_loss_cls: 0.0912, stage2_pos_acc: 99.0000, stage2_loss_bbox: 0.2046, stage2_loss_iou: 0.3524, stage2_loss_global: 0.0290, stage2_loss_mask: 0.4724, stage3_loss_cls: 0.0612, stage3_pos_acc: 99.0000, stage3_loss_bbox: 0.2047, stage3_loss_iou: 0.3481, stage3_loss_global: 0.0251, stage3_loss_mask: 0.4858, stage4_loss_cls: 0.0507, stage4_pos_acc: 99.0000, stage4_loss_bbox: 0.2009, stage4_loss_iou: 0.3437, stage4_loss_global: 0.0228, stage4_loss_mask: 0.4759, stage5_loss_cls: 0.0416, stage5_pos_acc: 99.2500, stage5_loss_bbox: 0.2024, stage5_loss_iou: 0.3443, stage5_loss_global: 0.0220, stage5_loss_mask: 0.4889, loss: 7.3378, grad_norm: 116.2938
2021-12-29 15:09:00,844 - mmdet - INFO - Saving checkpoint at 31 epochs
2021-12-29 15:10:15,605 - mmdet - INFO - Epoch [32][50/52]	lr: 2.500e-06, eta: 0:04:30, time: 1.326, data_time: 0.219, memory: 8635, stage0_loss_cls: 0.3018, stage0_pos_acc: 97.7500, stage0_loss_bbox: 0.2809, stage0_loss_iou: 0.5107, stage0_loss_global: 0.0561, stage0_loss_mask: 0.5040, stage1_loss_cls: 0.1781, stage1_pos_acc: 98.7500, stage1_loss_bbox: 0.2178, stage1_loss_iou: 0.3812, stage1_loss_global: 0.0540, stage1_loss_mask: 0.5010, stage2_loss_cls: 0.1132, stage2_pos_acc: 98.5000, stage2_loss_bbox: 0.2015, stage2_loss_iou: 0.3558, stage2_loss_global: 0.0468, stage2_loss_mask: 0.4833, stage3_loss_cls: 0.0744, stage3_pos_acc: 99.0000, stage3_loss_bbox: 0.2075, stage3_loss_iou: 0.3589, stage3_loss_global: 0.0366, stage3_loss_mask: 0.4886, stage4_loss_cls: 0.0529, stage4_pos_acc: 98.7500, stage4_loss_bbox: 0.2076, stage4_loss_iou: 0.3633, stage4_loss_global: 0.0318, stage4_loss_mask: 0.5044, stage5_loss_cls: 0.0494, stage5_pos_acc: 99.2500, stage5_loss_bbox: 0.2075, stage5_loss_iou: 0.3645, stage5_loss_global: 0.0316, stage5_loss_mask: 0.5149, loss: 7.6801, grad_norm: 122.7394
2021-12-29 15:10:18,276 - mmdet - INFO - Saving checkpoint at 32 epochs
2021-12-29 15:11:32,653 - mmdet - INFO - Epoch [33][50/52]	lr: 2.500e-06, eta: 0:03:23, time: 1.325, data_time: 0.219, memory: 8635, stage0_loss_cls: 0.2711, stage0_pos_acc: 98.5000, stage0_loss_bbox: 0.2674, stage0_loss_iou: 0.4827, stage0_loss_global: 0.0519, stage0_loss_mask: 0.4779, stage1_loss_cls: 0.1710, stage1_pos_acc: 98.7500, stage1_loss_bbox: 0.2044, stage1_loss_iou: 0.3597, stage1_loss_global: 0.0514, stage1_loss_mask: 0.4733, stage2_loss_cls: 0.1008, stage2_pos_acc: 98.5000, stage2_loss_bbox: 0.1897, stage2_loss_iou: 0.3383, stage2_loss_global: 0.0466, stage2_loss_mask: 0.4645, stage3_loss_cls: 0.0728, stage3_pos_acc: 98.5000, stage3_loss_bbox: 0.1885, stage3_loss_iou: 0.3359, stage3_loss_global: 0.0431, stage3_loss_mask: 0.4768, stage4_loss_cls: 0.0544, stage4_pos_acc: 98.5000, stage4_loss_bbox: 0.1901, stage4_loss_iou: 0.3375, stage4_loss_global: 0.0407, stage4_loss_mask: 0.4701, stage5_loss_cls: 0.0429, stage5_pos_acc: 98.5000, stage5_loss_bbox: 0.1916, stage5_loss_iou: 0.3396, stage5_loss_global: 0.0398, stage5_loss_mask: 0.4896, loss: 7.2641, grad_norm: 119.2530
2021-12-29 15:11:35,321 - mmdet - INFO - Saving checkpoint at 33 epochs
2021-12-29 15:12:50,620 - mmdet - INFO - Epoch [34][50/52]	lr: 2.500e-07, eta: 0:02:16, time: 1.347, data_time: 0.220, memory: 8635, stage0_loss_cls: 0.2614, stage0_pos_acc: 98.5000, stage0_loss_bbox: 0.2674, stage0_loss_iou: 0.4941, stage0_loss_global: 0.0277, stage0_loss_mask: 0.4865, stage1_loss_cls: 0.1641, stage1_pos_acc: 99.2500, stage1_loss_bbox: 0.2005, stage1_loss_iou: 0.3601, stage1_loss_global: 0.0276, stage1_loss_mask: 0.4740, stage2_loss_cls: 0.0891, stage2_pos_acc: 99.2500, stage2_loss_bbox: 0.1892, stage2_loss_iou: 0.3403, stage2_loss_global: 0.0249, stage2_loss_mask: 0.4652, stage3_loss_cls: 0.0555, stage3_pos_acc: 99.5000, stage3_loss_bbox: 0.1898, stage3_loss_iou: 0.3393, stage3_loss_global: 0.0209, stage3_loss_mask: 0.4751, stage4_loss_cls: 0.0439, stage4_pos_acc: 99.2500, stage4_loss_bbox: 0.1882, stage4_loss_iou: 0.3370, stage4_loss_global: 0.0188, stage4_loss_mask: 0.4593, stage5_loss_cls: 0.0362, stage5_pos_acc: 99.5000, stage5_loss_bbox: 0.1871, stage5_loss_iou: 0.3350, stage5_loss_global: 0.0177, stage5_loss_mask: 0.4722, loss: 7.0482, grad_norm: 111.1948
2021-12-29 15:12:53,208 - mmdet - INFO - Saving checkpoint at 34 epochs
2021-12-29 15:14:07,000 - mmdet - INFO - Epoch [35][50/52]	lr: 2.500e-07, eta: 0:01:09, time: 1.317, data_time: 0.214, memory: 8635, stage0_loss_cls: 0.2687, stage0_pos_acc: 99.0000, stage0_loss_bbox: 0.2678, stage0_loss_iou: 0.4921, stage0_loss_global: 0.0321, stage0_loss_mask: 0.4833, stage1_loss_cls: 0.1735, stage1_pos_acc: 99.0000, stage1_loss_bbox: 0.1942, stage1_loss_iou: 0.3457, stage1_loss_global: 0.0295, stage1_loss_mask: 0.4648, stage2_loss_cls: 0.0992, stage2_pos_acc: 98.7500, stage2_loss_bbox: 0.1894, stage2_loss_iou: 0.3359, stage2_loss_global: 0.0273, stage2_loss_mask: 0.4499, stage3_loss_cls: 0.0689, stage3_pos_acc: 99.2500, stage3_loss_bbox: 0.1902, stage3_loss_iou: 0.3353, stage3_loss_global: 0.0221, stage3_loss_mask: 0.4658, stage4_loss_cls: 0.0546, stage4_pos_acc: 99.2500, stage4_loss_bbox: 0.1908, stage4_loss_iou: 0.3340, stage4_loss_global: 0.0217, stage4_loss_mask: 0.4610, stage5_loss_cls: 0.0410, stage5_pos_acc: 99.2500, stage5_loss_bbox: 0.1947, stage5_loss_iou: 0.3392, stage5_loss_global: 0.0208, stage5_loss_mask: 0.4836, loss: 7.0768, grad_norm: 286.2275
2021-12-29 15:14:09,738 - mmdet - INFO - Saving checkpoint at 35 epochs
2021-12-29 15:15:23,821 - mmdet - INFO - Epoch [36][50/52]	lr: 2.500e-07, eta: 0:00:02, time: 1.327, data_time: 0.219, memory: 8635, stage0_loss_cls: 0.2732, stage0_pos_acc: 96.7500, stage0_loss_bbox: 0.2628, stage0_loss_iou: 0.4791, stage0_loss_global: 0.0352, stage0_loss_mask: 0.4688, stage1_loss_cls: 0.1512, stage1_pos_acc: 99.2500, stage1_loss_bbox: 0.2096, stage1_loss_iou: 0.3625, stage1_loss_global: 0.0326, stage1_loss_mask: 0.4859, stage2_loss_cls: 0.0983, stage2_pos_acc: 99.0000, stage2_loss_bbox: 0.1908, stage2_loss_iou: 0.3353, stage2_loss_global: 0.0288, stage2_loss_mask: 0.4639, stage3_loss_cls: 0.0588, stage3_pos_acc: 99.2500, stage3_loss_bbox: 0.1934, stage3_loss_iou: 0.3374, stage3_loss_global: 0.0244, stage3_loss_mask: 0.4739, stage4_loss_cls: 0.0482, stage4_pos_acc: 99.0000, stage4_loss_bbox: 0.1922, stage4_loss_iou: 0.3360, stage4_loss_global: 0.0236, stage4_loss_mask: 0.4677, stage5_loss_cls: 0.0402, stage5_pos_acc: 99.0000, stage5_loss_bbox: 0.1911, stage5_loss_iou: 0.3345, stage5_loss_global: 0.0227, stage5_loss_mask: 0.4750, loss: 7.0972, grad_norm: 109.2665
2021-12-29 15:15:26,443 - mmdet - INFO - Saving checkpoint at 36 epochs
