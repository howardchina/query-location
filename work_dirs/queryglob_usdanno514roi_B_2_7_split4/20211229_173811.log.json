{"env_info": "sys.platform: linux\nPython: 3.8.10 (default, Jun  4 2021, 15:09:15) [GCC 7.5.0]\nCUDA available: True\nGPU 0,1,2,3: NVIDIA TITAN Xp\nCUDA_HOME: /usr/local/cuda\nNVCC: Cuda compilation tools, release 10.2, V10.2.89\nGCC: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609\nPyTorch: 1.7.0\nPyTorch compiling details: PyTorch built with:\n  - GCC 7.3\n  - C++ Version: 201402\n  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 10.2\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75\n  - CuDNN 7.6.5\n  - Magma 2.5.2\n  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n\nTorchVision: 0.8.1\nOpenCV: 4.5.3\nMMCV: 1.3.18\nMMCV Compiler: GCC 7.3\nMMCV CUDA Compiler: 10.2\nMMDetection: 2.12.0+170db93", "config": "dataset_type = 'AnatomyDataset'\ndata_root = '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi'\nsplit = 'split_4'\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\nalbu_train_transforms = [\n    dict(\n        type='OneOf',\n        transforms=[\n            dict(\n                type='Affine',\n                translate_percent=0.0,\n                rotate=90,\n                fit_output=True,\n                p=0.25),\n            dict(\n                type='Affine',\n                translate_percent=0.0,\n                rotate=180,\n                fit_output=True,\n                p=0.25),\n            dict(\n                type='Affine',\n                translate_percent=0.0,\n                rotate=270,\n                fit_output=True,\n                p=0.25)\n        ],\n        p=0.75)\n]\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n    dict(type='LoadAnatomy'),\n    dict(type='RandomFlip', flip_ratio=0.5),\n    dict(\n        type='Albu',\n        transforms=[\n            dict(\n                type='OneOf',\n                transforms=[\n                    dict(\n                        type='Affine',\n                        translate_percent=0.0,\n                        rotate=90,\n                        fit_output=True,\n                        p=0.25),\n                    dict(\n                        type='Affine',\n                        translate_percent=0.0,\n                        rotate=180,\n                        fit_output=True,\n                        p=0.25),\n                    dict(\n                        type='Affine',\n                        translate_percent=0.0,\n                        rotate=270,\n                        fit_output=True,\n                        p=0.25)\n                ],\n                p=0.75)\n        ],\n        bbox_params=dict(\n            type='BboxParams',\n            format='pascal_voc',\n            label_fields=['gt_labels'],\n            min_visibility=0.0,\n            filter_lost_elements=True),\n        keymap=dict(img='image', gt_masks='masks', gt_bboxes='bboxes'),\n        update_pad_shape=False,\n        skip_img_without_anno=True),\n    dict(\n        type='Resize',\n        img_scale=[(1333, 480), (1333, 512), (1333, 544), (1333, 576),\n                   (1333, 608), (1333, 640), (1333, 672), (1333, 704),\n                   (1333, 736), (1333, 768), (1333, 800)],\n        multiscale_mode='value',\n        keep_ratio=True),\n    dict(\n        type='Normalize',\n        mean=[123.675, 116.28, 103.53],\n        std=[58.395, 57.12, 57.375],\n        to_rgb=True),\n    dict(type='Pad', size_divisor=32),\n    dict(type='DefaultFormatBundle'),\n    dict(type='FormatAnatomyBundle'),\n    dict(\n        type='Collect',\n        keys=['img', 'anatomy', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnatomy'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(1333, 800),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='FormatAnatomyBundle'),\n            dict(type='Collect', keys=['img', 'anatomy'])\n        ])\n]\ndata = dict(\n    samples_per_gpu=2,\n    workers_per_gpu=2,\n    train=dict(\n        type='AnatomyDataset',\n        ann_file=\n        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/annotations/train_anno_crop_split_4.json',\n        img_prefix=\n        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/images/',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n            dict(type='LoadAnatomy'),\n            dict(type='RandomFlip', flip_ratio=0.5),\n            dict(\n                type='Albu',\n                transforms=[\n                    dict(\n                        type='OneOf',\n                        transforms=[\n                            dict(\n                                type='Affine',\n                                translate_percent=0.0,\n                                rotate=90,\n                                fit_output=True,\n                                p=0.25),\n                            dict(\n                                type='Affine',\n                                translate_percent=0.0,\n                                rotate=180,\n                                fit_output=True,\n                                p=0.25),\n                            dict(\n                                type='Affine',\n                                translate_percent=0.0,\n                                rotate=270,\n                                fit_output=True,\n                                p=0.25)\n                        ],\n                        p=0.75)\n                ],\n                bbox_params=dict(\n                    type='BboxParams',\n                    format='pascal_voc',\n                    label_fields=['gt_labels'],\n                    min_visibility=0.0,\n                    filter_lost_elements=True),\n                keymap=dict(img='image', gt_masks='masks', gt_bboxes='bboxes'),\n                update_pad_shape=False,\n                skip_img_without_anno=True),\n            dict(\n                type='Resize',\n                img_scale=[(1333, 480), (1333, 512), (1333, 544), (1333, 576),\n                           (1333, 608), (1333, 640), (1333, 672), (1333, 704),\n                           (1333, 736), (1333, 768), (1333, 800)],\n                multiscale_mode='value',\n                keep_ratio=True),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='DefaultFormatBundle'),\n            dict(type='FormatAnatomyBundle'),\n            dict(\n                type='Collect',\n                keys=['img', 'anatomy', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n        ],\n        classes=('lmym', 'GIST')),\n    val=dict(\n        type='AnatomyDataset',\n        ann_file=\n        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/annotations/val_anno_crop_split_4.json',\n        img_prefix=\n        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/images/',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnatomy'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(1333, 800),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='Pad', size_divisor=32),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='FormatAnatomyBundle'),\n                    dict(type='Collect', keys=['img', 'anatomy'])\n                ])\n        ],\n        classes=('lmym', 'GIST')),\n    test=dict(\n        type='AnatomyDataset',\n        ann_file=\n        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/annotations/val_anno_crop_split_4.json',\n        img_prefix=\n        '/mnt/home1/workspace2/QueryInst/data/usd514_jpeg_roi/images/',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnatomy'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(1333, 800),\n                flip=False,\n                transforms=[\n                    dict(type='Resize', keep_ratio=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='Pad', size_divisor=32),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='FormatAnatomyBundle'),\n                    dict(type='Collect', keys=['img', 'anatomy'])\n                ])\n        ],\n        classes=('lmym', 'GIST')))\nevaluation = dict(metric=['bbox', 'segm', 'glob'])\noptimizer = dict(type='AdamW', lr=2.5e-05, weight_decay=0.0001)\noptimizer_config = dict(grad_clip=dict(max_norm=1, norm_type=2))\nlr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=1000,\n    warmup_ratio=0.001,\n    step=[27, 33])\nrunner = dict(type='EpochBasedRunner', max_epochs=36)\ncheckpoint_config = dict(interval=1)\nlog_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\ncustom_hooks = [dict(type='NumClassCheckHook')]\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = 'work_dirs/pretrained/queryInst/queryinst_r101_300_queries-860dc5d5.pth'\nresume_from = None\nworkflow = [('train', 1)]\nnum_stages = 6\nnum_proposals = 300\nmodel = dict(\n    type='QueryGlob',\n    pretrained='torchvision://resnet101',\n    backbone=dict(\n        type='ResNet',\n        depth=101,\n        num_stages=4,\n        out_indices=(0, 1, 2, 3),\n        frozen_stages=1,\n        norm_cfg=dict(type='BN', requires_grad=True),\n        norm_eval=True,\n        style='pytorch'),\n    neck=dict(\n        type='FPN',\n        in_channels=[256, 512, 1024, 2048],\n        out_channels=256,\n        start_level=0,\n        add_extra_convs='on_input',\n        num_outs=4),\n    rpn_head=dict(\n        type='GlobalEmbeddingRPNHead',\n        num_proposals=300,\n        dim_global=7,\n        proposal_feature_channel=256),\n    roi_head=dict(\n        type='QueryGlobRoIHead',\n        num_stages=6,\n        stage_loss_weights=[1, 1, 1, 1, 1, 1],\n        proposal_feature_channel=256,\n        bbox_roi_extractor=dict(\n            type='SingleRoIExtractor',\n            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=2),\n            out_channels=256,\n            featmap_strides=[4, 8, 16, 32]),\n        mask_roi_extractor=dict(\n            type='SingleRoIExtractor',\n            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=2),\n            out_channels=256,\n            featmap_strides=[4, 8, 16, 32]),\n        bbox_head=[\n            dict(\n                type='GlobDIIHead',\n                num_classes=2,\n                num_ffn_fcs=2,\n                num_heads=8,\n                num_cls_fcs=2,\n                num_glb_fcs=2,\n                num_reg_fcs=3,\n                feedforward_channels=2048,\n                in_channels=256,\n                dropout=0.0,\n                ffn_act_cfg=dict(type='ReLU', inplace=True),\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=7,\n                    with_proj=True,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n                loss_cls=dict(\n                    type='FocalLoss',\n                    use_sigmoid=True,\n                    gamma=2.0,\n                    alpha=0.25,\n                    loss_weight=2.0),\n                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    clip_border=False,\n                    target_means=[0.0, 0.0, 0.0, 0.0],\n                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n            dict(\n                type='GlobDIIHead',\n                num_classes=2,\n                num_ffn_fcs=2,\n                num_heads=8,\n                num_cls_fcs=2,\n                num_glb_fcs=2,\n                num_reg_fcs=3,\n                feedforward_channels=2048,\n                in_channels=256,\n                dropout=0.0,\n                ffn_act_cfg=dict(type='ReLU', inplace=True),\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=7,\n                    with_proj=True,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n                loss_cls=dict(\n                    type='FocalLoss',\n                    use_sigmoid=True,\n                    gamma=2.0,\n                    alpha=0.25,\n                    loss_weight=2.0),\n                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    clip_border=False,\n                    target_means=[0.0, 0.0, 0.0, 0.0],\n                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n            dict(\n                type='GlobDIIHead',\n                num_classes=2,\n                num_ffn_fcs=2,\n                num_heads=8,\n                num_cls_fcs=2,\n                num_glb_fcs=2,\n                num_reg_fcs=3,\n                feedforward_channels=2048,\n                in_channels=256,\n                dropout=0.0,\n                ffn_act_cfg=dict(type='ReLU', inplace=True),\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=7,\n                    with_proj=True,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n                loss_cls=dict(\n                    type='FocalLoss',\n                    use_sigmoid=True,\n                    gamma=2.0,\n                    alpha=0.25,\n                    loss_weight=2.0),\n                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    clip_border=False,\n                    target_means=[0.0, 0.0, 0.0, 0.0],\n                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n            dict(\n                type='GlobDIIHead',\n                num_classes=2,\n                num_ffn_fcs=2,\n                num_heads=8,\n                num_cls_fcs=2,\n                num_glb_fcs=2,\n                num_reg_fcs=3,\n                feedforward_channels=2048,\n                in_channels=256,\n                dropout=0.0,\n                ffn_act_cfg=dict(type='ReLU', inplace=True),\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=7,\n                    with_proj=True,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n                loss_cls=dict(\n                    type='FocalLoss',\n                    use_sigmoid=True,\n                    gamma=2.0,\n                    alpha=0.25,\n                    loss_weight=2.0),\n                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    clip_border=False,\n                    target_means=[0.0, 0.0, 0.0, 0.0],\n                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n            dict(\n                type='GlobDIIHead',\n                num_classes=2,\n                num_ffn_fcs=2,\n                num_heads=8,\n                num_cls_fcs=2,\n                num_glb_fcs=2,\n                num_reg_fcs=3,\n                feedforward_channels=2048,\n                in_channels=256,\n                dropout=0.0,\n                ffn_act_cfg=dict(type='ReLU', inplace=True),\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=7,\n                    with_proj=True,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n                loss_cls=dict(\n                    type='FocalLoss',\n                    use_sigmoid=True,\n                    gamma=2.0,\n                    alpha=0.25,\n                    loss_weight=2.0),\n                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    clip_border=False,\n                    target_means=[0.0, 0.0, 0.0, 0.0],\n                    target_stds=[0.5, 0.5, 1.0, 1.0])),\n            dict(\n                type='GlobDIIHead',\n                num_classes=2,\n                num_ffn_fcs=2,\n                num_heads=8,\n                num_cls_fcs=2,\n                num_glb_fcs=2,\n                num_reg_fcs=3,\n                feedforward_channels=2048,\n                in_channels=256,\n                dropout=0.0,\n                ffn_act_cfg=dict(type='ReLU', inplace=True),\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=7,\n                    with_proj=True,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                loss_bbox=dict(type='L1Loss', loss_weight=5.0),\n                loss_iou=dict(type='GIoULoss', loss_weight=2.0),\n                loss_cls=dict(\n                    type='FocalLoss',\n                    use_sigmoid=True,\n                    gamma=2.0,\n                    alpha=0.25,\n                    loss_weight=2.0),\n                loss_global=dict(type='CrossEntropyLoss', loss_weight=1.0),\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    clip_border=False,\n                    target_means=[0.0, 0.0, 0.0, 0.0],\n                    target_stds=[0.5, 0.5, 1.0, 1.0]))\n        ],\n        mask_head=[\n            dict(\n                type='DynamicMaskHead',\n                num_classes=2,\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=14,\n                    with_proj=False,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                dropout=0.0,\n                num_convs=4,\n                roi_feat_size=14,\n                in_channels=256,\n                conv_kernel_size=3,\n                conv_out_channels=256,\n                class_agnostic=False,\n                norm_cfg=dict(type='BN'),\n                upsample_cfg=dict(type='deconv', scale_factor=2),\n                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n            dict(\n                type='DynamicMaskHead',\n                num_classes=2,\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=14,\n                    with_proj=False,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                dropout=0.0,\n                num_convs=4,\n                roi_feat_size=14,\n                in_channels=256,\n                conv_kernel_size=3,\n                conv_out_channels=256,\n                class_agnostic=False,\n                norm_cfg=dict(type='BN'),\n                upsample_cfg=dict(type='deconv', scale_factor=2),\n                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n            dict(\n                type='DynamicMaskHead',\n                num_classes=2,\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=14,\n                    with_proj=False,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                dropout=0.0,\n                num_convs=4,\n                roi_feat_size=14,\n                in_channels=256,\n                conv_kernel_size=3,\n                conv_out_channels=256,\n                class_agnostic=False,\n                norm_cfg=dict(type='BN'),\n                upsample_cfg=dict(type='deconv', scale_factor=2),\n                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n            dict(\n                type='DynamicMaskHead',\n                num_classes=2,\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=14,\n                    with_proj=False,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                dropout=0.0,\n                num_convs=4,\n                roi_feat_size=14,\n                in_channels=256,\n                conv_kernel_size=3,\n                conv_out_channels=256,\n                class_agnostic=False,\n                norm_cfg=dict(type='BN'),\n                upsample_cfg=dict(type='deconv', scale_factor=2),\n                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n            dict(\n                type='DynamicMaskHead',\n                num_classes=2,\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=14,\n                    with_proj=False,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                dropout=0.0,\n                num_convs=4,\n                roi_feat_size=14,\n                in_channels=256,\n                conv_kernel_size=3,\n                conv_out_channels=256,\n                class_agnostic=False,\n                norm_cfg=dict(type='BN'),\n                upsample_cfg=dict(type='deconv', scale_factor=2),\n                loss_dice=dict(type='DiceLoss', loss_weight=8.0)),\n            dict(\n                type='DynamicMaskHead',\n                num_classes=2,\n                dynamic_conv_cfg=dict(\n                    type='DynamicConv',\n                    in_channels=256,\n                    feat_channels=64,\n                    out_channels=256,\n                    input_feat_shape=14,\n                    with_proj=False,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    norm_cfg=dict(type='LN')),\n                dropout=0.0,\n                num_convs=4,\n                roi_feat_size=14,\n                in_channels=256,\n                conv_kernel_size=3,\n                conv_out_channels=256,\n                class_agnostic=False,\n                norm_cfg=dict(type='BN'),\n                upsample_cfg=dict(type='deconv', scale_factor=2),\n                loss_dice=dict(type='DiceLoss', loss_weight=8.0))\n        ]),\n    train_cfg=dict(\n        rpn=None,\n        rcnn=[\n            dict(\n                assigner=dict(\n                    type='HungarianAssigner',\n                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n                                  weight=2.0)),\n                sampler=dict(type='PseudoSampler'),\n                pos_weight=1,\n                mask_size=28,\n                debug=False),\n            dict(\n                assigner=dict(\n                    type='HungarianAssigner',\n                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n                                  weight=2.0)),\n                sampler=dict(type='PseudoSampler'),\n                pos_weight=1,\n                mask_size=28,\n                debug=False),\n            dict(\n                assigner=dict(\n                    type='HungarianAssigner',\n                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n                                  weight=2.0)),\n                sampler=dict(type='PseudoSampler'),\n                pos_weight=1,\n                mask_size=28,\n                debug=False),\n            dict(\n                assigner=dict(\n                    type='HungarianAssigner',\n                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n                                  weight=2.0)),\n                sampler=dict(type='PseudoSampler'),\n                pos_weight=1,\n                mask_size=28,\n                debug=False),\n            dict(\n                assigner=dict(\n                    type='HungarianAssigner',\n                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n                                  weight=2.0)),\n                sampler=dict(type='PseudoSampler'),\n                pos_weight=1,\n                mask_size=28,\n                debug=False),\n            dict(\n                assigner=dict(\n                    type='HungarianAssigner',\n                    cls_cost=dict(type='FocalLossCost', weight=2.0),\n                    reg_cost=dict(type='BBoxL1Cost', weight=5.0),\n                    iou_cost=dict(type='IoUCost', iou_mode='giou',\n                                  weight=2.0)),\n                sampler=dict(type='PseudoSampler'),\n                pos_weight=1,\n                mask_size=28,\n                debug=False)\n        ]),\n    test_cfg=dict(\n        rpn=None,\n        rcnn=dict(\n            max_per_img=300,\n            mask_thr_binary=0.5,\n            nms=dict(type='nms', iou_threshold=0.7))))\ntotal_epochs = 36\nmin_values = (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)\nclasses = ('lmym', 'GIST')\ngpu_ids = range(0, 4)\nwork_dir = './work_dirs/queryglob_usdanno514roi_B_2_7_split4'\n", "seed": null, "exp_name": "queryglob_usdanno514roi_B_2_7_split4.py"}
{"mode": "train", "epoch": 1, "iter": 50, "lr": 0.0, "memory": 8153, "data_time": 0.21873, "stage0_loss_cls": 2.82809, "stage0_pos_acc": 52.0, "stage0_loss_bbox": 0.65961, "stage0_loss_iou": 1.02382, "stage0_loss_global": 1.24034, "stage0_loss_mask": 2.54937, "stage1_loss_cls": 1.98234, "stage1_pos_acc": 51.25, "stage1_loss_bbox": 0.56002, "stage1_loss_iou": 0.92519, "stage1_loss_global": 0.7587, "stage1_loss_mask": 2.60305, "stage2_loss_cls": 2.2991, "stage2_pos_acc": 49.75, "stage2_loss_bbox": 0.57624, "stage2_loss_iou": 0.92196, "stage2_loss_global": 0.66948, "stage2_loss_mask": 2.58246, "stage3_loss_cls": 2.25012, "stage3_pos_acc": 55.75, "stage3_loss_bbox": 0.59255, "stage3_loss_iou": 0.93478, "stage3_loss_global": 0.78854, "stage3_loss_mask": 3.02902, "stage4_loss_cls": 2.18593, "stage4_pos_acc": 50.5, "stage4_loss_bbox": 0.6022, "stage4_loss_iou": 0.94192, "stage4_loss_global": 0.85523, "stage4_loss_mask": 2.87988, "stage5_loss_cls": 1.80537, "stage5_pos_acc": 51.25, "stage5_loss_bbox": 0.59957, "stage5_loss_iou": 0.94318, "stage5_loss_global": 0.73561, "stage5_loss_mask": 2.59661, "loss": 43.92027, "grad_norm": 208.58021, "time": 1.33149}
{"mode": "train", "epoch": 2, "iter": 50, "lr": 0.0, "memory": 8153, "data_time": 0.21359, "stage0_loss_cls": 2.74019, "stage0_pos_acc": 51.25, "stage0_loss_bbox": 0.59614, "stage0_loss_iou": 0.93766, "stage0_loss_global": 0.91963, "stage0_loss_mask": 2.43785, "stage1_loss_cls": 1.93532, "stage1_pos_acc": 48.5, "stage1_loss_bbox": 0.472, "stage1_loss_iou": 0.79081, "stage1_loss_global": 0.62702, "stage1_loss_mask": 2.34949, "stage2_loss_cls": 2.14257, "stage2_pos_acc": 47.25, "stage2_loss_bbox": 0.4749, "stage2_loss_iou": 0.77998, "stage2_loss_global": 0.57694, "stage2_loss_mask": 2.38407, "stage3_loss_cls": 2.14485, "stage3_pos_acc": 51.75, "stage3_loss_bbox": 0.47728, "stage3_loss_iou": 0.78472, "stage3_loss_global": 0.57752, "stage3_loss_mask": 2.76909, "stage4_loss_cls": 1.85278, "stage4_pos_acc": 48.75, "stage4_loss_bbox": 0.46594, "stage4_loss_iou": 0.76624, "stage4_loss_global": 0.58359, "stage4_loss_mask": 2.59907, "stage5_loss_cls": 1.61289, "stage5_pos_acc": 54.5, "stage5_loss_bbox": 0.46729, "stage5_loss_iou": 0.7639, "stage5_loss_global": 0.62094, "stage5_loss_mask": 2.29226, "loss": 38.94291, "grad_norm": 189.61328, "time": 1.29939}
{"mode": "train", "epoch": 3, "iter": 50, "lr": 0.0, "memory": 8245, "data_time": 0.21836, "stage0_loss_cls": 2.49109, "stage0_pos_acc": 45.25, "stage0_loss_bbox": 0.572, "stage0_loss_iou": 0.92133, "stage0_loss_global": 0.56171, "stage0_loss_mask": 2.29725, "stage1_loss_cls": 1.69801, "stage1_pos_acc": 50.75, "stage1_loss_bbox": 0.43066, "stage1_loss_iou": 0.73571, "stage1_loss_global": 0.5098, "stage1_loss_mask": 2.10758, "stage2_loss_cls": 1.78277, "stage2_pos_acc": 48.75, "stage2_loss_bbox": 0.40321, "stage2_loss_iou": 0.68027, "stage2_loss_global": 0.5075, "stage2_loss_mask": 2.13035, "stage3_loss_cls": 1.72422, "stage3_pos_acc": 53.0, "stage3_loss_bbox": 0.39514, "stage3_loss_iou": 0.66324, "stage3_loss_global": 0.50232, "stage3_loss_mask": 2.41131, "stage4_loss_cls": 1.36031, "stage4_pos_acc": 65.0, "stage4_loss_bbox": 0.38824, "stage4_loss_iou": 0.65754, "stage4_loss_global": 0.50453, "stage4_loss_mask": 2.18537, "stage5_loss_cls": 1.37563, "stage5_pos_acc": 59.0, "stage5_loss_bbox": 0.37185, "stage5_loss_iou": 0.64527, "stage5_loss_global": 0.50547, "stage5_loss_mask": 1.89292, "loss": 33.41259, "grad_norm": 176.52491, "time": 1.34311}
{"mode": "train", "epoch": 4, "iter": 50, "lr": 1e-05, "memory": 8245, "data_time": 0.21701, "stage0_loss_cls": 2.09466, "stage0_pos_acc": 51.5, "stage0_loss_bbox": 0.52821, "stage0_loss_iou": 0.86137, "stage0_loss_global": 0.51833, "stage0_loss_mask": 2.10598, "stage1_loss_cls": 1.48332, "stage1_pos_acc": 56.5, "stage1_loss_bbox": 0.35993, "stage1_loss_iou": 0.63556, "stage1_loss_global": 0.48425, "stage1_loss_mask": 1.74194, "stage2_loss_cls": 1.40605, "stage2_pos_acc": 56.25, "stage2_loss_bbox": 0.33494, "stage2_loss_iou": 0.58938, "stage2_loss_global": 0.49269, "stage2_loss_mask": 1.74385, "stage3_loss_cls": 1.33679, "stage3_pos_acc": 59.5, "stage3_loss_bbox": 0.31383, "stage3_loss_iou": 0.56022, "stage3_loss_global": 0.49427, "stage3_loss_mask": 1.97646, "stage4_loss_cls": 1.14308, "stage4_pos_acc": 67.0, "stage4_loss_bbox": 0.31215, "stage4_loss_iou": 0.55914, "stage4_loss_global": 0.48855, "stage4_loss_mask": 1.6724, "stage5_loss_cls": 1.14872, "stage5_pos_acc": 64.5, "stage5_loss_bbox": 0.30466, "stage5_loss_iou": 0.54262, "stage5_loss_global": 0.48764, "stage5_loss_mask": 1.52857, "loss": 28.24954, "grad_norm": 141.40525, "time": 1.34629}
{"mode": "train", "epoch": 5, "iter": 50, "lr": 1e-05, "memory": 8246, "data_time": 0.21363, "stage0_loss_cls": 1.63197, "stage0_pos_acc": 54.25, "stage0_loss_bbox": 0.47639, "stage0_loss_iou": 0.80403, "stage0_loss_global": 0.50343, "stage0_loss_mask": 1.82578, "stage1_loss_cls": 1.36966, "stage1_pos_acc": 59.5, "stage1_loss_bbox": 0.30452, "stage1_loss_iou": 0.55668, "stage1_loss_global": 0.48479, "stage1_loss_mask": 1.45769, "stage2_loss_cls": 1.24627, "stage2_pos_acc": 54.25, "stage2_loss_bbox": 0.27881, "stage2_loss_iou": 0.5097, "stage2_loss_global": 0.48733, "stage2_loss_mask": 1.46436, "stage3_loss_cls": 1.13048, "stage3_pos_acc": 58.25, "stage3_loss_bbox": 0.26805, "stage3_loss_iou": 0.49417, "stage3_loss_global": 0.49168, "stage3_loss_mask": 1.63633, "stage4_loss_cls": 0.94026, "stage4_pos_acc": 65.0, "stage4_loss_bbox": 0.26745, "stage4_loss_iou": 0.48883, "stage4_loss_global": 0.48525, "stage4_loss_mask": 1.41313, "stage5_loss_cls": 0.89109, "stage5_pos_acc": 68.25, "stage5_loss_bbox": 0.26725, "stage5_loss_iou": 0.49363, "stage5_loss_global": 0.48482, "stage5_loss_mask": 1.26871, "loss": 24.42254, "grad_norm": 140.45955, "time": 1.32675}
{"mode": "train", "epoch": 6, "iter": 50, "lr": 1e-05, "memory": 8246, "data_time": 0.21485, "stage0_loss_cls": 1.36978, "stage0_pos_acc": 53.0, "stage0_loss_bbox": 0.45761, "stage0_loss_iou": 0.76315, "stage0_loss_global": 0.48686, "stage0_loss_mask": 1.54475, "stage1_loss_cls": 1.22779, "stage1_pos_acc": 71.5, "stage1_loss_bbox": 0.25901, "stage1_loss_iou": 0.46592, "stage1_loss_global": 0.47304, "stage1_loss_mask": 1.19672, "stage2_loss_cls": 1.05636, "stage2_pos_acc": 60.0, "stage2_loss_bbox": 0.23691, "stage2_loss_iou": 0.42828, "stage2_loss_global": 0.4694, "stage2_loss_mask": 1.19821, "stage3_loss_cls": 0.90965, "stage3_pos_acc": 61.75, "stage3_loss_bbox": 0.24364, "stage3_loss_iou": 0.43395, "stage3_loss_global": 0.46819, "stage3_loss_mask": 1.3063, "stage4_loss_cls": 0.73876, "stage4_pos_acc": 65.5, "stage4_loss_bbox": 0.24906, "stage4_loss_iou": 0.44047, "stage4_loss_global": 0.4702, "stage4_loss_mask": 1.14424, "stage5_loss_cls": 0.66575, "stage5_pos_acc": 67.5, "stage5_loss_bbox": 0.26133, "stage5_loss_iou": 0.45675, "stage5_loss_global": 0.46313, "stage5_loss_mask": 1.10003, "loss": 20.98526, "grad_norm": 147.17822, "time": 1.33942}
{"mode": "train", "epoch": 7, "iter": 50, "lr": 1e-05, "memory": 8500, "data_time": 0.21415, "stage0_loss_cls": 1.2974, "stage0_pos_acc": 55.75, "stage0_loss_bbox": 0.39361, "stage0_loss_iou": 0.68717, "stage0_loss_global": 0.4912, "stage0_loss_mask": 1.33513, "stage1_loss_cls": 1.0653, "stage1_pos_acc": 74.0, "stage1_loss_bbox": 0.23133, "stage1_loss_iou": 0.43207, "stage1_loss_global": 0.48656, "stage1_loss_mask": 1.02713, "stage2_loss_cls": 0.89078, "stage2_pos_acc": 58.25, "stage2_loss_bbox": 0.22, "stage2_loss_iou": 0.41206, "stage2_loss_global": 0.48518, "stage2_loss_mask": 1.08567, "stage3_loss_cls": 0.68887, "stage3_pos_acc": 58.25, "stage3_loss_bbox": 0.25072, "stage3_loss_iou": 0.45542, "stage3_loss_global": 0.47251, "stage3_loss_mask": 1.12427, "stage4_loss_cls": 0.60127, "stage4_pos_acc": 63.5, "stage4_loss_bbox": 0.25795, "stage4_loss_iou": 0.4617, "stage4_loss_global": 0.47437, "stage4_loss_mask": 1.01857, "stage5_loss_cls": 0.56178, "stage5_pos_acc": 65.25, "stage5_loss_bbox": 0.26178, "stage5_loss_iou": 0.46461, "stage5_loss_global": 0.45929, "stage5_loss_mask": 0.99429, "loss": 19.08798, "grad_norm": 175.61518, "time": 1.32272}
{"mode": "train", "epoch": 8, "iter": 50, "lr": 1e-05, "memory": 8500, "data_time": 0.21537, "stage0_loss_cls": 1.19646, "stage0_pos_acc": 62.5, "stage0_loss_bbox": 0.34953, "stage0_loss_iou": 0.62779, "stage0_loss_global": 0.47087, "stage0_loss_mask": 1.14543, "stage1_loss_cls": 0.93578, "stage1_pos_acc": 75.0, "stage1_loss_bbox": 0.22732, "stage1_loss_iou": 0.41708, "stage1_loss_global": 0.4634, "stage1_loss_mask": 0.89738, "stage2_loss_cls": 0.72028, "stage2_pos_acc": 59.75, "stage2_loss_bbox": 0.23292, "stage2_loss_iou": 0.42627, "stage2_loss_global": 0.46579, "stage2_loss_mask": 0.99144, "stage3_loss_cls": 0.58755, "stage3_pos_acc": 61.0, "stage3_loss_bbox": 0.24084, "stage3_loss_iou": 0.43902, "stage3_loss_global": 0.45689, "stage3_loss_mask": 0.97714, "stage4_loss_cls": 0.52485, "stage4_pos_acc": 67.25, "stage4_loss_bbox": 0.24199, "stage4_loss_iou": 0.43816, "stage4_loss_global": 0.45741, "stage4_loss_mask": 0.9243, "stage5_loss_cls": 0.48477, "stage5_pos_acc": 70.0, "stage5_loss_bbox": 0.24851, "stage5_loss_iou": 0.44295, "stage5_loss_global": 0.44257, "stage5_loss_mask": 0.92809, "loss": 17.40277, "grad_norm": 129.75352, "time": 1.31342}
{"mode": "train", "epoch": 9, "iter": 50, "lr": 1e-05, "memory": 8608, "data_time": 0.21067, "stage0_loss_cls": 1.0764, "stage0_pos_acc": 65.75, "stage0_loss_bbox": 0.33345, "stage0_loss_iou": 0.58745, "stage0_loss_global": 0.45629, "stage0_loss_mask": 0.96924, "stage1_loss_cls": 0.82041, "stage1_pos_acc": 80.0, "stage1_loss_bbox": 0.22819, "stage1_loss_iou": 0.40945, "stage1_loss_global": 0.45872, "stage1_loss_mask": 0.77516, "stage2_loss_cls": 0.60546, "stage2_pos_acc": 54.75, "stage2_loss_bbox": 0.24146, "stage2_loss_iou": 0.42767, "stage2_loss_global": 0.45162, "stage2_loss_mask": 0.95426, "stage3_loss_cls": 0.54126, "stage3_pos_acc": 61.25, "stage3_loss_bbox": 0.23549, "stage3_loss_iou": 0.42312, "stage3_loss_global": 0.44469, "stage3_loss_mask": 0.84953, "stage4_loss_cls": 0.46853, "stage4_pos_acc": 67.75, "stage4_loss_bbox": 0.24656, "stage4_loss_iou": 0.43487, "stage4_loss_global": 0.43402, "stage4_loss_mask": 0.827, "stage5_loss_cls": 0.4466, "stage5_pos_acc": 73.75, "stage5_loss_bbox": 0.2423, "stage5_loss_iou": 0.43073, "stage5_loss_global": 0.44355, "stage5_loss_mask": 0.83175, "loss": 16.09522, "grad_norm": 134.76418, "time": 1.31108}
{"mode": "train", "epoch": 10, "iter": 50, "lr": 1e-05, "memory": 8608, "data_time": 0.21547, "stage0_loss_cls": 0.98952, "stage0_pos_acc": 69.75, "stage0_loss_bbox": 0.32337, "stage0_loss_iou": 0.57285, "stage0_loss_global": 0.44402, "stage0_loss_mask": 0.83827, "stage1_loss_cls": 0.74458, "stage1_pos_acc": 79.0, "stage1_loss_bbox": 0.23175, "stage1_loss_iou": 0.40944, "stage1_loss_global": 0.4479, "stage1_loss_mask": 0.6962, "stage2_loss_cls": 0.5517, "stage2_pos_acc": 63.5, "stage2_loss_bbox": 0.22644, "stage2_loss_iou": 0.4016, "stage2_loss_global": 0.44033, "stage2_loss_mask": 0.87256, "stage3_loss_cls": 0.47664, "stage3_pos_acc": 72.0, "stage3_loss_bbox": 0.22367, "stage3_loss_iou": 0.39626, "stage3_loss_global": 0.43564, "stage3_loss_mask": 0.73373, "stage4_loss_cls": 0.40189, "stage4_pos_acc": 71.75, "stage4_loss_bbox": 0.23416, "stage4_loss_iou": 0.41284, "stage4_loss_global": 0.42345, "stage4_loss_mask": 0.73002, "stage5_loss_cls": 0.3747, "stage5_pos_acc": 75.5, "stage5_loss_bbox": 0.23599, "stage5_loss_iou": 0.41432, "stage5_loss_global": 0.41819, "stage5_loss_mask": 0.76353, "loss": 14.86557, "grad_norm": 137.70168, "time": 1.32344}
{"mode": "train", "epoch": 11, "iter": 50, "lr": 1e-05, "memory": 8608, "data_time": 0.21482, "stage0_loss_cls": 0.9114, "stage0_pos_acc": 72.5, "stage0_loss_bbox": 0.32476, "stage0_loss_iou": 0.57765, "stage0_loss_global": 0.45838, "stage0_loss_mask": 0.78311, "stage1_loss_cls": 0.70912, "stage1_pos_acc": 77.0, "stage1_loss_bbox": 0.21751, "stage1_loss_iou": 0.40062, "stage1_loss_global": 0.4605, "stage1_loss_mask": 0.64911, "stage2_loss_cls": 0.51287, "stage2_pos_acc": 68.5, "stage2_loss_bbox": 0.2218, "stage2_loss_iou": 0.40844, "stage2_loss_global": 0.46922, "stage2_loss_mask": 0.85105, "stage3_loss_cls": 0.44833, "stage3_pos_acc": 71.25, "stage3_loss_bbox": 0.21995, "stage3_loss_iou": 0.40259, "stage3_loss_global": 0.48876, "stage3_loss_mask": 0.68741, "stage4_loss_cls": 0.40096, "stage4_pos_acc": 74.5, "stage4_loss_bbox": 0.2214, "stage4_loss_iou": 0.4055, "stage4_loss_global": 0.48317, "stage4_loss_mask": 0.67796, "stage5_loss_cls": 0.38169, "stage5_pos_acc": 77.5, "stage5_loss_bbox": 0.22418, "stage5_loss_iou": 0.40627, "stage5_loss_global": 0.50616, "stage5_loss_mask": 0.69359, "loss": 14.60347, "grad_norm": 174.50771, "time": 1.32898}
{"mode": "train", "epoch": 12, "iter": 50, "lr": 2e-05, "memory": 8608, "data_time": 0.21628, "stage0_loss_cls": 0.86026, "stage0_pos_acc": 74.25, "stage0_loss_bbox": 0.31237, "stage0_loss_iou": 0.56026, "stage0_loss_global": 0.40025, "stage0_loss_mask": 0.72847, "stage1_loss_cls": 0.64112, "stage1_pos_acc": 83.5, "stage1_loss_bbox": 0.2145, "stage1_loss_iou": 0.38206, "stage1_loss_global": 0.38608, "stage1_loss_mask": 0.59568, "stage2_loss_cls": 0.4567, "stage2_pos_acc": 75.5, "stage2_loss_bbox": 0.21619, "stage2_loss_iou": 0.38897, "stage2_loss_global": 0.35984, "stage2_loss_mask": 0.82146, "stage3_loss_cls": 0.39155, "stage3_pos_acc": 80.0, "stage3_loss_bbox": 0.22098, "stage3_loss_iou": 0.39615, "stage3_loss_global": 0.35038, "stage3_loss_mask": 0.65995, "stage4_loss_cls": 0.33541, "stage4_pos_acc": 81.0, "stage4_loss_bbox": 0.23014, "stage4_loss_iou": 0.40523, "stage4_loss_global": 0.33527, "stage4_loss_mask": 0.63829, "stage5_loss_cls": 0.33881, "stage5_pos_acc": 82.25, "stage5_loss_bbox": 0.23041, "stage5_loss_iou": 0.4033, "stage5_loss_global": 0.33236, "stage5_loss_mask": 0.64403, "loss": 13.23646, "grad_norm": 171.14034, "time": 1.32253}
{"mode": "train", "epoch": 13, "iter": 50, "lr": 2e-05, "memory": 8608, "data_time": 0.21952, "stage0_loss_cls": 0.83587, "stage0_pos_acc": 74.25, "stage0_loss_bbox": 0.31687, "stage0_loss_iou": 0.56804, "stage0_loss_global": 0.38971, "stage0_loss_mask": 0.68078, "stage1_loss_cls": 0.63884, "stage1_pos_acc": 81.75, "stage1_loss_bbox": 0.23162, "stage1_loss_iou": 0.40576, "stage1_loss_global": 0.39005, "stage1_loss_mask": 0.59872, "stage2_loss_cls": 0.4584, "stage2_pos_acc": 78.75, "stage2_loss_bbox": 0.22611, "stage2_loss_iou": 0.40422, "stage2_loss_global": 0.37196, "stage2_loss_mask": 0.79038, "stage3_loss_cls": 0.42143, "stage3_pos_acc": 76.5, "stage3_loss_bbox": 0.22216, "stage3_loss_iou": 0.39816, "stage3_loss_global": 0.37187, "stage3_loss_mask": 0.60385, "stage4_loss_cls": 0.35294, "stage4_pos_acc": 80.75, "stage4_loss_bbox": 0.23457, "stage4_loss_iou": 0.41268, "stage4_loss_global": 0.35558, "stage4_loss_mask": 0.60693, "stage5_loss_cls": 0.33576, "stage5_pos_acc": 79.75, "stage5_loss_bbox": 0.23503, "stage5_loss_iou": 0.41297, "stage5_loss_global": 0.35927, "stage5_loss_mask": 0.60133, "loss": 13.23186, "grad_norm": 255.78623, "time": 1.35}
{"mode": "train", "epoch": 14, "iter": 50, "lr": 2e-05, "memory": 8608, "data_time": 0.22119, "stage0_loss_cls": 0.76917, "stage0_pos_acc": 85.0, "stage0_loss_bbox": 0.33474, "stage0_loss_iou": 0.6033, "stage0_loss_global": 0.28654, "stage0_loss_mask": 0.67773, "stage1_loss_cls": 0.58816, "stage1_pos_acc": 85.25, "stage1_loss_bbox": 0.2196, "stage1_loss_iou": 0.39702, "stage1_loss_global": 0.26973, "stage1_loss_mask": 0.57359, "stage2_loss_cls": 0.41329, "stage2_pos_acc": 86.0, "stage2_loss_bbox": 0.21248, "stage2_loss_iou": 0.38345, "stage2_loss_global": 0.25798, "stage2_loss_mask": 0.77033, "stage3_loss_cls": 0.36872, "stage3_pos_acc": 86.5, "stage3_loss_bbox": 0.20859, "stage3_loss_iou": 0.3788, "stage3_loss_global": 0.25242, "stage3_loss_mask": 0.60544, "stage4_loss_cls": 0.30285, "stage4_pos_acc": 86.5, "stage4_loss_bbox": 0.22073, "stage4_loss_iou": 0.3921, "stage4_loss_global": 0.25534, "stage4_loss_mask": 0.60364, "stage5_loss_cls": 0.29798, "stage5_pos_acc": 86.25, "stage5_loss_bbox": 0.22318, "stage5_loss_iou": 0.39243, "stage5_loss_global": 0.2499, "stage5_loss_mask": 0.61071, "loss": 12.11994, "grad_norm": 232.05509, "time": 1.32333}
{"mode": "train", "epoch": 15, "iter": 50, "lr": 2e-05, "memory": 8608, "data_time": 0.21942, "stage0_loss_cls": 0.70189, "stage0_pos_acc": 86.25, "stage0_loss_bbox": 0.32766, "stage0_loss_iou": 0.58525, "stage0_loss_global": 0.23001, "stage0_loss_mask": 0.66877, "stage1_loss_cls": 0.5078, "stage1_pos_acc": 89.0, "stage1_loss_bbox": 0.22527, "stage1_loss_iou": 0.40269, "stage1_loss_global": 0.21889, "stage1_loss_mask": 0.59527, "stage2_loss_cls": 0.34179, "stage2_pos_acc": 86.75, "stage2_loss_bbox": 0.22674, "stage2_loss_iou": 0.4053, "stage2_loss_global": 0.21458, "stage2_loss_mask": 0.80307, "stage3_loss_cls": 0.29961, "stage3_pos_acc": 87.25, "stage3_loss_bbox": 0.22477, "stage3_loss_iou": 0.39963, "stage3_loss_global": 0.21953, "stage3_loss_mask": 0.61567, "stage4_loss_cls": 0.25203, "stage4_pos_acc": 89.25, "stage4_loss_bbox": 0.22928, "stage4_loss_iou": 0.40339, "stage4_loss_global": 0.21653, "stage4_loss_mask": 0.62171, "stage5_loss_cls": 0.24246, "stage5_pos_acc": 89.5, "stage5_loss_bbox": 0.2339, "stage5_loss_iou": 0.40522, "stage5_loss_global": 0.21939, "stage5_loss_mask": 0.62867, "loss": 11.66679, "grad_norm": 323.78005, "time": 1.33447}
{"mode": "train", "epoch": 16, "iter": 50, "lr": 2e-05, "memory": 8608, "data_time": 0.22203, "stage0_loss_cls": 0.66809, "stage0_pos_acc": 87.5, "stage0_loss_bbox": 0.32679, "stage0_loss_iou": 0.57886, "stage0_loss_global": 0.21577, "stage0_loss_mask": 0.63842, "stage1_loss_cls": 0.50201, "stage1_pos_acc": 90.5, "stage1_loss_bbox": 0.22048, "stage1_loss_iou": 0.39232, "stage1_loss_global": 0.20352, "stage1_loss_mask": 0.57232, "stage2_loss_cls": 0.32563, "stage2_pos_acc": 90.5, "stage2_loss_bbox": 0.22339, "stage2_loss_iou": 0.38898, "stage2_loss_global": 0.19936, "stage2_loss_mask": 0.78388, "stage3_loss_cls": 0.27734, "stage3_pos_acc": 89.75, "stage3_loss_bbox": 0.2216, "stage3_loss_iou": 0.38827, "stage3_loss_global": 0.20662, "stage3_loss_mask": 0.60211, "stage4_loss_cls": 0.24115, "stage4_pos_acc": 89.0, "stage4_loss_bbox": 0.22267, "stage4_loss_iou": 0.39172, "stage4_loss_global": 0.20001, "stage4_loss_mask": 0.60594, "stage5_loss_cls": 0.22673, "stage5_pos_acc": 90.5, "stage5_loss_bbox": 0.22556, "stage5_loss_iou": 0.39514, "stage5_loss_global": 0.19709, "stage5_loss_mask": 0.60293, "loss": 11.24471, "grad_norm": 210.79589, "time": 1.32859}
{"mode": "train", "epoch": 17, "iter": 50, "lr": 2e-05, "memory": 8608, "data_time": 0.21798, "stage0_loss_cls": 0.6276, "stage0_pos_acc": 88.0, "stage0_loss_bbox": 0.34002, "stage0_loss_iou": 0.59568, "stage0_loss_global": 0.20092, "stage0_loss_mask": 0.60584, "stage1_loss_cls": 0.46304, "stage1_pos_acc": 89.75, "stage1_loss_bbox": 0.22462, "stage1_loss_iou": 0.38834, "stage1_loss_global": 0.20349, "stage1_loss_mask": 0.55435, "stage2_loss_cls": 0.31037, "stage2_pos_acc": 90.0, "stage2_loss_bbox": 0.22028, "stage2_loss_iou": 0.38211, "stage2_loss_global": 0.20537, "stage2_loss_mask": 0.73199, "stage3_loss_cls": 0.29717, "stage3_pos_acc": 89.25, "stage3_loss_bbox": 0.21319, "stage3_loss_iou": 0.37229, "stage3_loss_global": 0.20422, "stage3_loss_mask": 0.5591, "stage4_loss_cls": 0.24739, "stage4_pos_acc": 90.75, "stage4_loss_bbox": 0.21862, "stage4_loss_iou": 0.37941, "stage4_loss_global": 0.2065, "stage4_loss_mask": 0.56771, "stage5_loss_cls": 0.25668, "stage5_pos_acc": 88.75, "stage5_loss_bbox": 0.21949, "stage5_loss_iou": 0.37961, "stage5_loss_global": 0.20933, "stage5_loss_mask": 0.55779, "loss": 10.94251, "grad_norm": 215.73425, "time": 1.32418}
{"mode": "train", "epoch": 18, "iter": 50, "lr": 2e-05, "memory": 8608, "data_time": 0.22272, "stage0_loss_cls": 0.60167, "stage0_pos_acc": 88.25, "stage0_loss_bbox": 0.31489, "stage0_loss_iou": 0.56551, "stage0_loss_global": 0.17304, "stage0_loss_mask": 0.57634, "stage1_loss_cls": 0.41139, "stage1_pos_acc": 90.75, "stage1_loss_bbox": 0.2173, "stage1_loss_iou": 0.38113, "stage1_loss_global": 0.16832, "stage1_loss_mask": 0.53947, "stage2_loss_cls": 0.30595, "stage2_pos_acc": 92.25, "stage2_loss_bbox": 0.20306, "stage2_loss_iou": 0.35945, "stage2_loss_global": 0.17011, "stage2_loss_mask": 0.66772, "stage3_loss_cls": 0.24168, "stage3_pos_acc": 92.25, "stage3_loss_bbox": 0.20896, "stage3_loss_iou": 0.36522, "stage3_loss_global": 0.16767, "stage3_loss_mask": 0.53081, "stage4_loss_cls": 0.22179, "stage4_pos_acc": 92.5, "stage4_loss_bbox": 0.21328, "stage4_loss_iou": 0.37133, "stage4_loss_global": 0.16803, "stage4_loss_mask": 0.53693, "stage5_loss_cls": 0.19957, "stage5_pos_acc": 91.5, "stage5_loss_bbox": 0.21915, "stage5_loss_iou": 0.37826, "stage5_loss_global": 0.16998, "stage5_loss_mask": 0.53482, "loss": 10.18285, "grad_norm": 248.28453, "time": 1.32381}
{"mode": "train", "epoch": 19, "iter": 50, "lr": 3e-05, "memory": 8613, "data_time": 0.22102, "stage0_loss_cls": 0.57447, "stage0_pos_acc": 91.75, "stage0_loss_bbox": 0.33179, "stage0_loss_iou": 0.58238, "stage0_loss_global": 0.15974, "stage0_loss_mask": 0.58018, "stage1_loss_cls": 0.38086, "stage1_pos_acc": 93.0, "stage1_loss_bbox": 0.23545, "stage1_loss_iou": 0.40454, "stage1_loss_global": 0.14973, "stage1_loss_mask": 0.5478, "stage2_loss_cls": 0.23313, "stage2_pos_acc": 93.75, "stage2_loss_bbox": 0.22142, "stage2_loss_iou": 0.38671, "stage2_loss_global": 0.14419, "stage2_loss_mask": 0.6675, "stage3_loss_cls": 0.19463, "stage3_pos_acc": 93.25, "stage3_loss_bbox": 0.21895, "stage3_loss_iou": 0.37947, "stage3_loss_global": 0.14555, "stage3_loss_mask": 0.55601, "stage4_loss_cls": 0.17022, "stage4_pos_acc": 93.5, "stage4_loss_bbox": 0.2207, "stage4_loss_iou": 0.38244, "stage4_loss_global": 0.14288, "stage4_loss_mask": 0.55761, "stage5_loss_cls": 0.161, "stage5_pos_acc": 94.0, "stage5_loss_bbox": 0.22127, "stage5_loss_iou": 0.38305, "stage5_loss_global": 0.14159, "stage5_loss_mask": 0.54571, "loss": 10.02097, "grad_norm": 192.40033, "time": 1.32617}
{"mode": "train", "epoch": 20, "iter": 50, "lr": 3e-05, "memory": 8613, "data_time": 0.22194, "stage0_loss_cls": 0.57201, "stage0_pos_acc": 86.5, "stage0_loss_bbox": 0.31832, "stage0_loss_iou": 0.5719, "stage0_loss_global": 0.18719, "stage0_loss_mask": 0.58904, "stage1_loss_cls": 0.38341, "stage1_pos_acc": 88.75, "stage1_loss_bbox": 0.21491, "stage1_loss_iou": 0.38154, "stage1_loss_global": 0.18205, "stage1_loss_mask": 0.53924, "stage2_loss_cls": 0.27266, "stage2_pos_acc": 90.5, "stage2_loss_bbox": 0.20494, "stage2_loss_iou": 0.36617, "stage2_loss_global": 0.17939, "stage2_loss_mask": 0.61664, "stage3_loss_cls": 0.2433, "stage3_pos_acc": 90.0, "stage3_loss_bbox": 0.2051, "stage3_loss_iou": 0.36402, "stage3_loss_global": 0.18295, "stage3_loss_mask": 0.53546, "stage4_loss_cls": 0.20517, "stage4_pos_acc": 89.75, "stage4_loss_bbox": 0.21122, "stage4_loss_iou": 0.37003, "stage4_loss_global": 0.18089, "stage4_loss_mask": 0.53651, "stage5_loss_cls": 0.19992, "stage5_pos_acc": 90.0, "stage5_loss_bbox": 0.20987, "stage5_loss_iou": 0.36917, "stage5_loss_global": 0.1815, "stage5_loss_mask": 0.53359, "loss": 10.10809, "grad_norm": 294.40411, "time": 1.33339}
{"mode": "train", "epoch": 21, "iter": 50, "lr": 3e-05, "memory": 8613, "data_time": 0.21593, "stage0_loss_cls": 0.53339, "stage0_pos_acc": 90.75, "stage0_loss_bbox": 0.35241, "stage0_loss_iou": 0.61292, "stage0_loss_global": 0.17237, "stage0_loss_mask": 0.59285, "stage1_loss_cls": 0.3434, "stage1_pos_acc": 93.25, "stage1_loss_bbox": 0.24314, "stage1_loss_iou": 0.42418, "stage1_loss_global": 0.17215, "stage1_loss_mask": 0.56022, "stage2_loss_cls": 0.24196, "stage2_pos_acc": 92.75, "stage2_loss_bbox": 0.22379, "stage2_loss_iou": 0.39532, "stage2_loss_global": 0.17295, "stage2_loss_mask": 0.64302, "stage3_loss_cls": 0.20878, "stage3_pos_acc": 93.0, "stage3_loss_bbox": 0.21697, "stage3_loss_iou": 0.38339, "stage3_loss_global": 0.17365, "stage3_loss_mask": 0.56613, "stage4_loss_cls": 0.1818, "stage4_pos_acc": 92.75, "stage4_loss_bbox": 0.22314, "stage4_loss_iou": 0.38703, "stage4_loss_global": 0.17016, "stage4_loss_mask": 0.57275, "stage5_loss_cls": 0.16316, "stage5_pos_acc": 92.5, "stage5_loss_bbox": 0.22901, "stage5_loss_iou": 0.39553, "stage5_loss_global": 0.17178, "stage5_loss_mask": 0.57661, "loss": 10.30396, "grad_norm": 223.22896, "time": 1.31607}
{"mode": "train", "epoch": 22, "iter": 50, "lr": 3e-05, "memory": 8613, "data_time": 0.22024, "stage0_loss_cls": 0.54673, "stage0_pos_acc": 86.25, "stage0_loss_bbox": 0.313, "stage0_loss_iou": 0.57692, "stage0_loss_global": 0.17368, "stage0_loss_mask": 0.55542, "stage1_loss_cls": 0.33935, "stage1_pos_acc": 90.75, "stage1_loss_bbox": 0.22453, "stage1_loss_iou": 0.39809, "stage1_loss_global": 0.16597, "stage1_loss_mask": 0.51893, "stage2_loss_cls": 0.2369, "stage2_pos_acc": 90.25, "stage2_loss_bbox": 0.21164, "stage2_loss_iou": 0.37431, "stage2_loss_global": 0.16532, "stage2_loss_mask": 0.58559, "stage3_loss_cls": 0.20138, "stage3_pos_acc": 91.25, "stage3_loss_bbox": 0.21038, "stage3_loss_iou": 0.37456, "stage3_loss_global": 0.16349, "stage3_loss_mask": 0.53343, "stage4_loss_cls": 0.1846, "stage4_pos_acc": 90.75, "stage4_loss_bbox": 0.21019, "stage4_loss_iou": 0.37122, "stage4_loss_global": 0.16606, "stage4_loss_mask": 0.52978, "stage5_loss_cls": 0.17762, "stage5_pos_acc": 90.75, "stage5_loss_bbox": 0.20766, "stage5_loss_iou": 0.36749, "stage5_loss_global": 0.1666, "stage5_loss_mask": 0.52237, "loss": 9.77324, "grad_norm": 315.0343, "time": 1.31675}
{"mode": "train", "epoch": 23, "iter": 50, "lr": 3e-05, "memory": 8613, "data_time": 0.21853, "stage0_loss_cls": 0.51117, "stage0_pos_acc": 92.5, "stage0_loss_bbox": 0.30765, "stage0_loss_iou": 0.56528, "stage0_loss_global": 0.15843, "stage0_loss_mask": 0.51351, "stage1_loss_cls": 0.29989, "stage1_pos_acc": 93.5, "stage1_loss_bbox": 0.21355, "stage1_loss_iou": 0.38874, "stage1_loss_global": 0.16091, "stage1_loss_mask": 0.50508, "stage2_loss_cls": 0.18585, "stage2_pos_acc": 94.75, "stage2_loss_bbox": 0.20985, "stage2_loss_iou": 0.38029, "stage2_loss_global": 0.17178, "stage2_loss_mask": 0.55128, "stage3_loss_cls": 0.15143, "stage3_pos_acc": 93.25, "stage3_loss_bbox": 0.21174, "stage3_loss_iou": 0.37874, "stage3_loss_global": 0.17379, "stage3_loss_mask": 0.50445, "stage4_loss_cls": 0.13562, "stage4_pos_acc": 93.0, "stage4_loss_bbox": 0.21471, "stage4_loss_iou": 0.38041, "stage4_loss_global": 0.17394, "stage4_loss_mask": 0.5138, "stage5_loss_cls": 0.11632, "stage5_pos_acc": 93.25, "stage5_loss_bbox": 0.21764, "stage5_loss_iou": 0.3837, "stage5_loss_global": 0.16877, "stage5_loss_mask": 0.51322, "loss": 9.36156, "grad_norm": 368.44243, "time": 1.30854}
{"mode": "train", "epoch": 24, "iter": 50, "lr": 3e-05, "memory": 8613, "data_time": 0.22015, "stage0_loss_cls": 0.49497, "stage0_pos_acc": 90.0, "stage0_loss_bbox": 0.33224, "stage0_loss_iou": 0.5894, "stage0_loss_global": 0.1432, "stage0_loss_mask": 0.56798, "stage1_loss_cls": 0.31438, "stage1_pos_acc": 94.5, "stage1_loss_bbox": 0.22302, "stage1_loss_iou": 0.39706, "stage1_loss_global": 0.14236, "stage1_loss_mask": 0.52623, "stage2_loss_cls": 0.19591, "stage2_pos_acc": 94.25, "stage2_loss_bbox": 0.22578, "stage2_loss_iou": 0.39218, "stage2_loss_global": 0.14797, "stage2_loss_mask": 0.57802, "stage3_loss_cls": 0.18371, "stage3_pos_acc": 93.5, "stage3_loss_bbox": 0.21544, "stage3_loss_iou": 0.3817, "stage3_loss_global": 0.15185, "stage3_loss_mask": 0.52788, "stage4_loss_cls": 0.16292, "stage4_pos_acc": 94.0, "stage4_loss_bbox": 0.21502, "stage4_loss_iou": 0.3795, "stage4_loss_global": 0.14564, "stage4_loss_mask": 0.53077, "stage5_loss_cls": 0.1525, "stage5_pos_acc": 94.75, "stage5_loss_bbox": 0.21707, "stage5_loss_iou": 0.3829, "stage5_loss_global": 0.14498, "stage5_loss_mask": 0.51757, "loss": 9.58014, "grad_norm": 287.76561, "time": 1.31423}
{"mode": "train", "epoch": 25, "iter": 50, "lr": 3e-05, "memory": 8613, "data_time": 0.21797, "stage0_loss_cls": 0.49705, "stage0_pos_acc": 92.0, "stage0_loss_bbox": 0.34225, "stage0_loss_iou": 0.61256, "stage0_loss_global": 0.18226, "stage0_loss_mask": 0.53296, "stage1_loss_cls": 0.31821, "stage1_pos_acc": 93.25, "stage1_loss_bbox": 0.22321, "stage1_loss_iou": 0.39861, "stage1_loss_global": 0.18444, "stage1_loss_mask": 0.51196, "stage2_loss_cls": 0.23196, "stage2_pos_acc": 92.0, "stage2_loss_bbox": 0.21033, "stage2_loss_iou": 0.37559, "stage2_loss_global": 0.17962, "stage2_loss_mask": 0.54997, "stage3_loss_cls": 0.19373, "stage3_pos_acc": 91.25, "stage3_loss_bbox": 0.21596, "stage3_loss_iou": 0.38034, "stage3_loss_global": 0.17535, "stage3_loss_mask": 0.52297, "stage4_loss_cls": 0.17256, "stage4_pos_acc": 92.5, "stage4_loss_bbox": 0.21553, "stage4_loss_iou": 0.37936, "stage4_loss_global": 0.17332, "stage4_loss_mask": 0.52745, "stage5_loss_cls": 0.17231, "stage5_pos_acc": 93.0, "stage5_loss_bbox": 0.21321, "stage5_loss_iou": 0.37671, "stage5_loss_global": 0.17821, "stage5_loss_mask": 0.52119, "loss": 9.76921, "grad_norm": 238.9602, "time": 1.31686}
{"mode": "train", "epoch": 26, "iter": 50, "lr": 3e-05, "memory": 8613, "data_time": 0.21899, "stage0_loss_cls": 0.47547, "stage0_pos_acc": 90.5, "stage0_loss_bbox": 0.32821, "stage0_loss_iou": 0.58872, "stage0_loss_global": 0.14399, "stage0_loss_mask": 0.49822, "stage1_loss_cls": 0.29208, "stage1_pos_acc": 92.25, "stage1_loss_bbox": 0.22301, "stage1_loss_iou": 0.38578, "stage1_loss_global": 0.15129, "stage1_loss_mask": 0.5067, "stage2_loss_cls": 0.21854, "stage2_pos_acc": 94.25, "stage2_loss_bbox": 0.20201, "stage2_loss_iou": 0.35566, "stage2_loss_global": 0.15028, "stage2_loss_mask": 0.52322, "stage3_loss_cls": 0.1651, "stage3_pos_acc": 93.5, "stage3_loss_bbox": 0.20538, "stage3_loss_iou": 0.35603, "stage3_loss_global": 0.15614, "stage3_loss_mask": 0.49539, "stage4_loss_cls": 0.14216, "stage4_pos_acc": 94.0, "stage4_loss_bbox": 0.21095, "stage4_loss_iou": 0.36063, "stage4_loss_global": 0.16296, "stage4_loss_mask": 0.5104, "stage5_loss_cls": 0.13455, "stage5_pos_acc": 93.25, "stage5_loss_bbox": 0.21342, "stage5_loss_iou": 0.36061, "stage5_loss_global": 0.16627, "stage5_loss_mask": 0.50629, "loss": 9.18948, "grad_norm": 305.40322, "time": 1.33016}
{"mode": "train", "epoch": 27, "iter": 50, "lr": 3e-05, "memory": 8613, "data_time": 0.21338, "stage0_loss_cls": 0.51555, "stage0_pos_acc": 87.5, "stage0_loss_bbox": 0.31596, "stage0_loss_iou": 0.5634, "stage0_loss_global": 0.3067, "stage0_loss_mask": 0.5245, "stage1_loss_cls": 0.36375, "stage1_pos_acc": 88.75, "stage1_loss_bbox": 0.21091, "stage1_loss_iou": 0.37776, "stage1_loss_global": 0.33337, "stage1_loss_mask": 0.50289, "stage2_loss_cls": 0.27451, "stage2_pos_acc": 87.75, "stage2_loss_bbox": 0.20058, "stage2_loss_iou": 0.36356, "stage2_loss_global": 0.34487, "stage2_loss_mask": 0.51732, "stage3_loss_cls": 0.25459, "stage3_pos_acc": 89.0, "stage3_loss_bbox": 0.20043, "stage3_loss_iou": 0.36513, "stage3_loss_global": 0.33809, "stage3_loss_mask": 0.49468, "stage4_loss_cls": 0.24564, "stage4_pos_acc": 88.25, "stage4_loss_bbox": 0.20719, "stage4_loss_iou": 0.37173, "stage4_loss_global": 0.32894, "stage4_loss_mask": 0.50228, "stage5_loss_cls": 0.22901, "stage5_pos_acc": 89.25, "stage5_loss_bbox": 0.20958, "stage5_loss_iou": 0.3729, "stage5_loss_global": 0.35019, "stage5_loss_mask": 0.49457, "loss": 10.68059, "grad_norm": 440.00694, "time": 1.30575}
{"mode": "train", "epoch": 28, "iter": 50, "lr": 0.0, "memory": 8613, "data_time": 0.21934, "stage0_loss_cls": 0.40082, "stage0_pos_acc": 94.5, "stage0_loss_bbox": 0.31671, "stage0_loss_iou": 0.57694, "stage0_loss_global": 0.11348, "stage0_loss_mask": 0.52034, "stage1_loss_cls": 0.26568, "stage1_pos_acc": 95.0, "stage1_loss_bbox": 0.21859, "stage1_loss_iou": 0.38641, "stage1_loss_global": 0.10834, "stage1_loss_mask": 0.5037, "stage2_loss_cls": 0.16457, "stage2_pos_acc": 94.75, "stage2_loss_bbox": 0.19755, "stage2_loss_iou": 0.35496, "stage2_loss_global": 0.10509, "stage2_loss_mask": 0.51858, "stage3_loss_cls": 0.13461, "stage3_pos_acc": 95.5, "stage3_loss_bbox": 0.19519, "stage3_loss_iou": 0.35134, "stage3_loss_global": 0.10355, "stage3_loss_mask": 0.50914, "stage4_loss_cls": 0.1215, "stage4_pos_acc": 96.5, "stage4_loss_bbox": 0.19957, "stage4_loss_iou": 0.35286, "stage4_loss_global": 0.09674, "stage4_loss_mask": 0.5208, "stage5_loss_cls": 0.12181, "stage5_pos_acc": 96.25, "stage5_loss_bbox": 0.19428, "stage5_loss_iou": 0.34661, "stage5_loss_global": 0.09795, "stage5_loss_mask": 0.50677, "loss": 8.60445, "grad_norm": 142.41854, "time": 1.31668}
{"mode": "train", "epoch": 29, "iter": 50, "lr": 0.0, "memory": 8613, "data_time": 0.22264, "stage0_loss_cls": 0.36903, "stage0_pos_acc": 95.25, "stage0_loss_bbox": 0.29659, "stage0_loss_iou": 0.53354, "stage0_loss_global": 0.10506, "stage0_loss_mask": 0.50754, "stage1_loss_cls": 0.21475, "stage1_pos_acc": 96.25, "stage1_loss_bbox": 0.20368, "stage1_loss_iou": 0.36288, "stage1_loss_global": 0.09789, "stage1_loss_mask": 0.4746, "stage2_loss_cls": 0.13129, "stage2_pos_acc": 95.75, "stage2_loss_bbox": 0.19192, "stage2_loss_iou": 0.34348, "stage2_loss_global": 0.09481, "stage2_loss_mask": 0.48556, "stage3_loss_cls": 0.09592, "stage3_pos_acc": 96.25, "stage3_loss_bbox": 0.19135, "stage3_loss_iou": 0.34186, "stage3_loss_global": 0.0923, "stage3_loss_mask": 0.46975, "stage4_loss_cls": 0.07665, "stage4_pos_acc": 96.25, "stage4_loss_bbox": 0.19404, "stage4_loss_iou": 0.34615, "stage4_loss_global": 0.08829, "stage4_loss_mask": 0.47161, "stage5_loss_cls": 0.07646, "stage5_pos_acc": 96.0, "stage5_loss_bbox": 0.19173, "stage5_loss_iou": 0.34243, "stage5_loss_global": 0.08836, "stage5_loss_mask": 0.45854, "loss": 7.93806, "grad_norm": 265.47831, "time": 1.33005}
{"mode": "train", "epoch": 30, "iter": 50, "lr": 0.0, "memory": 8613, "data_time": 0.22537, "stage0_loss_cls": 0.3738, "stage0_pos_acc": 96.25, "stage0_loss_bbox": 0.28139, "stage0_loss_iou": 0.51554, "stage0_loss_global": 0.10186, "stage0_loss_mask": 0.50048, "stage1_loss_cls": 0.21412, "stage1_pos_acc": 96.5, "stage1_loss_bbox": 0.1999, "stage1_loss_iou": 0.36237, "stage1_loss_global": 0.09804, "stage1_loss_mask": 0.49095, "stage2_loss_cls": 0.1203, "stage2_pos_acc": 96.25, "stage2_loss_bbox": 0.19301, "stage2_loss_iou": 0.34917, "stage2_loss_global": 0.09491, "stage2_loss_mask": 0.50463, "stage3_loss_cls": 0.09433, "stage3_pos_acc": 96.75, "stage3_loss_bbox": 0.19269, "stage3_loss_iou": 0.34417, "stage3_loss_global": 0.08988, "stage3_loss_mask": 0.48343, "stage4_loss_cls": 0.07951, "stage4_pos_acc": 96.75, "stage4_loss_bbox": 0.19027, "stage4_loss_iou": 0.34208, "stage4_loss_global": 0.08619, "stage4_loss_mask": 0.47998, "stage5_loss_cls": 0.07856, "stage5_pos_acc": 96.5, "stage5_loss_bbox": 0.18944, "stage5_loss_iou": 0.33916, "stage5_loss_global": 0.08442, "stage5_loss_mask": 0.47305, "loss": 7.94763, "grad_norm": 233.91648, "time": 1.33315}
{"mode": "train", "epoch": 31, "iter": 50, "lr": 0.0, "memory": 8613, "data_time": 0.21877, "stage0_loss_cls": 0.34868, "stage0_pos_acc": 95.0, "stage0_loss_bbox": 0.28021, "stage0_loss_iou": 0.50629, "stage0_loss_global": 0.10473, "stage0_loss_mask": 0.48715, "stage1_loss_cls": 0.21169, "stage1_pos_acc": 97.0, "stage1_loss_bbox": 0.20185, "stage1_loss_iou": 0.35813, "stage1_loss_global": 0.09817, "stage1_loss_mask": 0.48712, "stage2_loss_cls": 0.10687, "stage2_pos_acc": 97.25, "stage2_loss_bbox": 0.19426, "stage2_loss_iou": 0.34445, "stage2_loss_global": 0.09389, "stage2_loss_mask": 0.49303, "stage3_loss_cls": 0.08866, "stage3_pos_acc": 96.5, "stage3_loss_bbox": 0.18875, "stage3_loss_iou": 0.33649, "stage3_loss_global": 0.0898, "stage3_loss_mask": 0.47173, "stage4_loss_cls": 0.07913, "stage4_pos_acc": 96.5, "stage4_loss_bbox": 0.18916, "stage4_loss_iou": 0.33412, "stage4_loss_global": 0.08196, "stage4_loss_mask": 0.47169, "stage5_loss_cls": 0.07563, "stage5_pos_acc": 96.25, "stage5_loss_bbox": 0.19149, "stage5_loss_iou": 0.3362, "stage5_loss_global": 0.08218, "stage5_loss_mask": 0.45691, "loss": 7.79044, "grad_norm": 155.08648, "time": 1.33545}
{"mode": "train", "epoch": 32, "iter": 50, "lr": 0.0, "memory": 8613, "data_time": 0.22024, "stage0_loss_cls": 0.36352, "stage0_pos_acc": 95.0, "stage0_loss_bbox": 0.28169, "stage0_loss_iou": 0.51664, "stage0_loss_global": 0.10315, "stage0_loss_mask": 0.48687, "stage1_loss_cls": 0.19292, "stage1_pos_acc": 97.75, "stage1_loss_bbox": 0.19902, "stage1_loss_iou": 0.36124, "stage1_loss_global": 0.09612, "stage1_loss_mask": 0.46996, "stage2_loss_cls": 0.11121, "stage2_pos_acc": 97.5, "stage2_loss_bbox": 0.19073, "stage2_loss_iou": 0.34692, "stage2_loss_global": 0.08733, "stage2_loss_mask": 0.48148, "stage3_loss_cls": 0.08346, "stage3_pos_acc": 98.0, "stage3_loss_bbox": 0.19065, "stage3_loss_iou": 0.34293, "stage3_loss_global": 0.08348, "stage3_loss_mask": 0.46731, "stage4_loss_cls": 0.0724, "stage4_pos_acc": 98.25, "stage4_loss_bbox": 0.1881, "stage4_loss_iou": 0.33802, "stage4_loss_global": 0.07415, "stage4_loss_mask": 0.46362, "stage5_loss_cls": 0.07219, "stage5_pos_acc": 98.25, "stage5_loss_bbox": 0.18824, "stage5_loss_iou": 0.33659, "stage5_loss_global": 0.0723, "stage5_loss_mask": 0.45701, "loss": 7.71927, "grad_norm": 332.31456, "time": 1.3258}
{"mode": "train", "epoch": 33, "iter": 50, "lr": 0.0, "memory": 8613, "data_time": 0.22311, "stage0_loss_cls": 0.33298, "stage0_pos_acc": 95.75, "stage0_loss_bbox": 0.28146, "stage0_loss_iou": 0.51668, "stage0_loss_global": 0.09905, "stage0_loss_mask": 0.48433, "stage1_loss_cls": 0.19342, "stage1_pos_acc": 96.25, "stage1_loss_bbox": 0.20387, "stage1_loss_iou": 0.36574, "stage1_loss_global": 0.09154, "stage1_loss_mask": 0.50075, "stage2_loss_cls": 0.11307, "stage2_pos_acc": 97.75, "stage2_loss_bbox": 0.1953, "stage2_loss_iou": 0.35308, "stage2_loss_global": 0.08835, "stage2_loss_mask": 0.5068, "stage3_loss_cls": 0.08535, "stage3_pos_acc": 97.5, "stage3_loss_bbox": 0.19466, "stage3_loss_iou": 0.35066, "stage3_loss_global": 0.08354, "stage3_loss_mask": 0.49135, "stage4_loss_cls": 0.06638, "stage4_pos_acc": 98.0, "stage4_loss_bbox": 0.19645, "stage4_loss_iou": 0.35105, "stage4_loss_global": 0.07566, "stage4_loss_mask": 0.49808, "stage5_loss_cls": 0.05793, "stage5_pos_acc": 98.25, "stage5_loss_bbox": 0.20058, "stage5_loss_iou": 0.35424, "stage5_loss_global": 0.07288, "stage5_loss_mask": 0.49075, "loss": 7.89598, "grad_norm": 151.19263, "time": 1.32524}
{"mode": "train", "epoch": 34, "iter": 50, "lr": 0.0, "memory": 8613, "data_time": 0.22342, "stage0_loss_cls": 0.33066, "stage0_pos_acc": 95.75, "stage0_loss_bbox": 0.27126, "stage0_loss_iou": 0.49388, "stage0_loss_global": 0.10025, "stage0_loss_mask": 0.50462, "stage1_loss_cls": 0.1793, "stage1_pos_acc": 96.25, "stage1_loss_bbox": 0.19185, "stage1_loss_iou": 0.35299, "stage1_loss_global": 0.09456, "stage1_loss_mask": 0.47604, "stage2_loss_cls": 0.10135, "stage2_pos_acc": 96.25, "stage2_loss_bbox": 0.18382, "stage2_loss_iou": 0.33677, "stage2_loss_global": 0.0883, "stage2_loss_mask": 0.49244, "stage3_loss_cls": 0.08484, "stage3_pos_acc": 96.75, "stage3_loss_bbox": 0.18132, "stage3_loss_iou": 0.33156, "stage3_loss_global": 0.08418, "stage3_loss_mask": 0.47015, "stage4_loss_cls": 0.07166, "stage4_pos_acc": 96.25, "stage4_loss_bbox": 0.1842, "stage4_loss_iou": 0.33368, "stage4_loss_global": 0.07362, "stage4_loss_mask": 0.47301, "stage5_loss_cls": 0.06882, "stage5_pos_acc": 96.5, "stage5_loss_bbox": 0.18524, "stage5_loss_iou": 0.33316, "stage5_loss_global": 0.074, "stage5_loss_mask": 0.46568, "loss": 7.61318, "grad_norm": 159.11712, "time": 1.3406}
{"mode": "train", "epoch": 35, "iter": 50, "lr": 0.0, "memory": 8613, "data_time": 0.22285, "stage0_loss_cls": 0.34893, "stage0_pos_acc": 95.5, "stage0_loss_bbox": 0.27198, "stage0_loss_iou": 0.50001, "stage0_loss_global": 0.09977, "stage0_loss_mask": 0.50867, "stage1_loss_cls": 0.20709, "stage1_pos_acc": 96.5, "stage1_loss_bbox": 0.19235, "stage1_loss_iou": 0.35723, "stage1_loss_global": 0.09345, "stage1_loss_mask": 0.46835, "stage2_loss_cls": 0.12202, "stage2_pos_acc": 97.0, "stage2_loss_bbox": 0.18499, "stage2_loss_iou": 0.34274, "stage2_loss_global": 0.08948, "stage2_loss_mask": 0.48669, "stage3_loss_cls": 0.08957, "stage3_pos_acc": 97.0, "stage3_loss_bbox": 0.18332, "stage3_loss_iou": 0.3382, "stage3_loss_global": 0.08543, "stage3_loss_mask": 0.46874, "stage4_loss_cls": 0.07593, "stage4_pos_acc": 97.75, "stage4_loss_bbox": 0.18256, "stage4_loss_iou": 0.33573, "stage4_loss_global": 0.07967, "stage4_loss_mask": 0.47276, "stage5_loss_cls": 0.07401, "stage5_pos_acc": 96.75, "stage5_loss_bbox": 0.18138, "stage5_loss_iou": 0.33406, "stage5_loss_global": 0.07979, "stage5_loss_mask": 0.45998, "loss": 7.7149, "grad_norm": 151.82799, "time": 1.32805}
{"mode": "train", "epoch": 36, "iter": 50, "lr": 0.0, "memory": 8613, "data_time": 0.21874, "stage0_loss_cls": 0.32331, "stage0_pos_acc": 96.5, "stage0_loss_bbox": 0.26513, "stage0_loss_iou": 0.48562, "stage0_loss_global": 0.08258, "stage0_loss_mask": 0.49059, "stage1_loss_cls": 0.19609, "stage1_pos_acc": 96.5, "stage1_loss_bbox": 0.19819, "stage1_loss_iou": 0.3595, "stage1_loss_global": 0.07551, "stage1_loss_mask": 0.47258, "stage2_loss_cls": 0.1074, "stage2_pos_acc": 96.5, "stage2_loss_bbox": 0.19128, "stage2_loss_iou": 0.34239, "stage2_loss_global": 0.07414, "stage2_loss_mask": 0.48459, "stage3_loss_cls": 0.0769, "stage3_pos_acc": 96.5, "stage3_loss_bbox": 0.19141, "stage3_loss_iou": 0.3407, "stage3_loss_global": 0.071, "stage3_loss_mask": 0.46837, "stage4_loss_cls": 0.06749, "stage4_pos_acc": 97.0, "stage4_loss_bbox": 0.18769, "stage4_loss_iou": 0.33458, "stage4_loss_global": 0.06667, "stage4_loss_mask": 0.46569, "stage5_loss_cls": 0.06674, "stage5_pos_acc": 96.75, "stage5_loss_bbox": 0.18619, "stage5_loss_iou": 0.33194, "stage5_loss_global": 0.06266, "stage5_loss_mask": 0.45892, "loss": 7.52587, "grad_norm": 186.19411, "time": 1.33568}
